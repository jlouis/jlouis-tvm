\documentclass[a4paper, oneside, 10pt, draft]{memoir}

\chapterstyle{culver}
\RequirePackage[english]{jlouis}

\author{Jesper Louis
  Andersen\\jesper.louis.andersen@gmail.com\\140280-2029}
\title{Formalizing a Virtual Machine}
\date{\today}

\newlength{\drop}
\newcommand*{\titleM}{\begingroup% Misericords, T&H p 153
  \drop = 0.08\textheight
  \centering
  {\Huge\bfseries Lambda}\\[\baselineskip]
  {\scshape IR of exsml}\\[\baselineskip]
  {\scshape by}\\[\baselineskip]
  {\large\scshape Jesper Louis Andersen\\jesper.louis.andersen@gmail.com}\par
  \endgroup}

\newcommand{\clang}{\textsc{Clang}}
\newcommand{\twelf}{\textsc{Twelf}}
\newcommand{\coq}{\textsc{Coq}}
\newcommand{\agda}{\textsc{Agda}}
\newcommand{\haskell}{\textsc{Haskell}}

\newcommand{\bottom}{\perp}
\bibliographystyle{plain}

\begin{document}
\listoffixmes{}
\maketitle{}
\newpage{}
\tableofcontents{}
\newpage{}
\chapter{Introduction}

\fixme{Mention something about $\alpha$-conversion and
  contexts. Particularly that it comes for free in \twelf{}}
\fixme{We need to find a place to describe the development process}
It is well known in compiler construction, that intermediate languages
are a useful and beneficial abstraction\cite{appel:1998:modern,
  mogensen:2008:basics}. Rather than targeting the instruction set
architecture directly, the compiler constructor first targets an
intermediate language (IL). Then the IL and is afterwards compiled to
the target machines instruction set\footnote{Sans
  optimizations. Optimization is usually carried out on the IL as
  well}. Schematically, the phases can be described as:
\begin{equation*}
  L ->^{fe} IL ->^{be} Q
\end{equation*}
where $L$ is the source language; the arrow marked by $fe$ the
front-end compilation; and the arrow marked by $be$ is the back-end
compilation onto the machine language $Q$. The construction is
advantageous because the compiler writer can share either the
front-end among several back-ends or the back-end among several
front-ends.

A popular extension of this strategy is to stage the compilation
in two parts: the front-end delivers IL code which is then typically
encoded in a binary format for transport. Arriving at the target
machine, this \emph{bytecode} is either interpreted, compiled or a
mixture of both. Usually, the run-time responsible for executing the
back-ends part is named a \emph{Virtual Machine} (VM) because the IL is
regarded as a machine abstraction.

ILs are usually designed to make front-end construction easier. The IL
can specifically factor out details of the underlying machine thus
simplifying compiler implementation. As an example most VMs carries
out register allocation and the programmer is given an abstraction:
either a stack or an infinite set of registers. Some VMs are designed
with a fairly broad IL intended to capture many different language
types while others are more constrained, often tied to a single
intended language. Examples of the former are the Java JVM
runtime\cite{lindholm.frank:1999:jvm} and the .NET
CLR/CIL\cite{ecma:2006:335}, while an example of the latter is the
Erlang Runtime System (a register machine with a built-in novel set of
concurrency primitives).

\section{LLVM}

This report concerns itself with a virtual machine named LLVM, the Low
Level Virtual Machine. It adopted this name because the LLVM IL is
close to an idealized assembly language with several convenient
differences of which we list some:
\begin{itemize}
\item All LLVM IL programs are statically typed. This rules out many
  common programming errors and fits well into compilation schemes
  where intermediate stage transforms are type-checked.
\item There is an infinite amount of registers and register allocation
  is carried out by the LLVM system.
\item Correct LLVM IL programs have the SSA-property: A variable has
  only one (static/syntactic) point in the program where it is
  \emph{defined}. All \emph{uses} of a variable must then be from this
  single static assignment. The usual $\phi$-node method is used to
  handle the case where control flow joins in the CFG.
\item LLVM has a built-in exception primitive.
\item LLVM is expected to carry out a large number of advanced
  optimizations on its IL with the intent of simplifying work for
  compiler writers.
\end{itemize}

However, one Achilles heel of the LLVM IL is the total lack of
formality. There is no EBNF of its grammar available and thus no
attempts have been made to define its semantics operationally.

In this report, we aim for a subset of the LLVM IL language and
provide a syntax description, an operational (small-step) semantics and a type
system. We seek to prove the system fulfills the usual meta-theoretical
properties of \emph{progress} and \emph{preservation} as well as
\emph{determinism}.

The state-of-the-art emphasized by for example the PoPLMark
challenge\cite{aydemir:2005:mechanizedmetatheory}, is the encoding of
syntax, semantics and proofs into a proof assistant or logical
framework. The goal is that every computer scientific report is
accompanied by a formal proof written such that the computer can
verify its correctness. In this report, every description has been
encoded into the logical framework of
\twelf{}\cite{schurmann.pfenning:twelf} for verification.

\section{Report structure}

The report first introduces some preliminaries and then presents the
real work made in the following chapters: syntax, semantics and
meta-theory of our Mini-LLVM language is presented. It is expected
that the reader is familiar with operational semantics, proof theory
and machine verifiable proofs; in particular the \twelf{} logical
framework. It is also expected that the reader is familiar with
SSA-form and its implications.

\chapter{Design considerations}

\fixme{This whole chapter needs more work as well}
In this section, we limit the scope of the formalization and present
the main design considerations before attempting to formalize the work.

\begin{figure}
\begin{verbatim}
if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return
return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0

\end{verbatim}
  \caption{An example LLVM fragment}
  \label{fig:llvm-example-1}
\end{figure}

Figure \ref{fig:llvm-example-1} contains an example of a typical LLVM
basic blocks. It begins with a label, identifying the block. Then a
series of instructions follow and the block ends in an unconditional
branch to the label '\texttt{\%return}'. Local definitions in LLVM are
prefixed by a '\%' marker and global (top-level) names by an '@'
marker. The instructions \texttt{sub, call, } and \texttt{add}
informally acts like one would expect. The LLVM type system can be
seen in the type designation \texttt{i32}, a 32-bit integer and
finally, the '\texttt{nsw}' designation makes the result underdefined,
should signed overflow occur.

In the basic block for the return, we first do a $\phi$-node
assignment. These assignment are required to be at the very top of a
basic block and transfers the value from the appropriate basic block
depending on the control flow. The '\texttt{ret}' instruction
returns. Note that this fragment has the SSA property.

Since we would like to represent LLVM in a machine checkable form in
\twelf{}, we utilize a result formulated explicitly by
Appel\cite{appel:1998:modern, appel:1998:ssa}: every SSA program has
an equivalent functional program. Thus our first design choice is to
represent the LLVM subset as a functional first order program to ease
its encoding in \twelf{}. As we shall see, the SSA-property of LLVM
programs greatly simplifies a number of otherwise complex interactions
in the semantics. Informally, we can transform a fragment
\label{llvm-consideration-let}
\begin{verbatim}
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  ...
\end{verbatim}
of two instructions following each other into the functional fragment:
\begin{verbatim}
  let %sub = sub i32 %n, 1
  in let %call = call i32 @tri(i32 %sub)
     in ...
\end{verbatim}

Note how the lexical scoping rules binds the '\texttt{\%sub}' value
in the correct scope.

We handle the basic blocks as Appel: each basic block becomes a
function with formal parameters the $\phi$-node variables. A branch to
a basic-block then tail-calls the function with the variables needing
transfer as parameters. In the example, we would have a function
\begin{verbatim}
return (%retval) =
   ret %retval
\end{verbatim}
for the return-basic-block. And the branch to it would be
\begin{verbatim}
if.else (...) =
  ...
    br %return (%add)
\end{verbatim}
to designate that the value of '\texttt{\%add}' is the one that should
go to the first $\phi$-node.

\section{Extent of the formalization}

We limit the extent of the formalization to a small subset of
LLVM. First, we note the complete lack of any formal grammar for
the language means we have to begin from a clean slate. Thus,
establishing a small subset is more important as a first step towards
the goal.

We cut any heap-interaction. Specifically, we cut the ability to
load and store data to a heap. LLVM allows pointer arithmetic in the
heap which is hard to handle meta-theoretically. We also cut a large
number of operations that would be easy to add but does not provide
any further insight. Conversion operations are not going to be
considered, as they contain a potentially unsafe '\texttt{bitcast}'
operation. ``Aggregate'' and ``Vector'' operations are not going to be
considered (these include structs and arrays). Finally, we won't be
considering instructions handling exceptions.

While the list seems extensive, it is important to stress that part of
the task is to understand the subset that is left to a level where it
can be put into a formal system.

Under the course of development, we will use LLVM version 2.x. We
mention this because LLVM is only supposed to change in a backwards
compatible way as long as it remains a version 2.x.

\chapter{Syntax of Mini-LLVM}

\newcommand{\variables}{\mathrm{Variables}}
\newcommand{\BBlabels}{\mathrm{BB Labels}}
\newcommand{\tnat}{\mathbf{nat}}
\newcommand{\tbool}{\mathbf{bool}}
\newcommand{\types}{\mathrm{Types}}
\newcommand{\typelist}{\mathrm{Type lists}}
\newcommand{\bbtype}{\mathrm{BB Type}}
\newcommand{\ftype}{\mathrm{Fun Contexts}}
\newcommand{\tpenv}{\mathrm{Var Contexts}}
\newcommand{\bbenv}{\mathrm{BB Contexts}}
\newcommand{\bor}{\; \vert \;}

\begin{figure}
  \begin{align*}
    \types \ni \tau & ::= \tnat \bor \tbool \\
    \typelist \ni [\tau] & ::= \cdot \bor \tau -> [\tau] \\
    \bbtype \ni Bb \tau   & ::= \tau_1 -> \dotsc -> \tau_n -> \tau\\
    \ftype \ni D & ::= \cdot \bor (f \mapsto (\tau_1 -> \dotsc ->
    \tau_n), D) \\
    \tpenv \ni \Gamma & ::= \cdot \bor (x \mapsto \tau),\Gamma\\
    \bbenv \ni \Psi   & ::= \cdot \bor (bb \mapsto (Bb \tau_1, \dotsc Bb
    \tau_n)),\Psi
  \end{align*}
  \caption{Type system}
  \label{fig:type-system}
\end{figure}

In this section, we present the syntax of Mini-LLVM in a formal BNF
grammar. We also describe the type system as well as the basic domains
from which we draw values.

\section{Types and domains}

\paragraph{Types} The language employs a simple type system as in
figure \ref{fig:type-system}. There are two primitive base types,
natural numbers and boolean values. For handling passing of parameters
between basic blocks via $\phi$-nodes, there is a $\bbtype$
designation stating a (possibly empty) list of formal parameters. We
notate such lists as $\tau -> \dotsc \tau' -> \cdot$ where the last
``$\cdot$'' states that it is a function but without return type.

The choice of two primitive types is deliberate. It is the simplest
non-trivial choice of types possible. Had there only been one base
type, all typing degenerates into questions on type arity in basic
block definitions.

\newcommand{\numbers}{\mathrm{Numbers}}
\newcommand{\booleans}{\mathrm{Booleans}}
\newcommand{\funlabels}{\mathrm{Function\; labels}}
\newcommand{\nat}{n}
\newcommand{\bool}{b}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\btrue}{\mathbf{True}}
\newcommand{\bfalse}{\mathbf{False}}

\paragraph{Domains}

Our language will be using several syntactic domains, the existence of
which we assume (figure \ref{fig:syntactic-domains}). We have
variables, $x_1, x_2, \dotsc$ used for naming and discriminating
registers from each others. For simplicity we restrict the language to
natural numbers only. This restriction is due to \twelf{}: we need to
encode the system of numbers and Peano-style natural numbers are
fairly simple to work with and handle. Verification in other systems
might have chosen another domain. We only utilize basic properties of
arithmetic in our verification, hence it might be possible to change
this later on.
\begin{figure}
  \begin{align*}
    \variables \ni V & ::= x_1, x_2, \dotsc \\
    \numbers \ni \NN, \nat & ::= 0 \bor 1 \bor 2 \bor \dotsc\\
    \booleans \ni \BB, \bool & ::= \btrue \bor \bfalse \\
    \BBlabels \ni bb & ::= bb_1, bb_2, bb_3, \dotsc \\
    \funlabels \ni f,g & ::= f,g,h,\dotsc
  \end{align*}
  \caption{Syntactic domains}
  \label{fig:syntactic-domains}
\end{figure}

Boolean values are either the true value or the false
value. Internally these are encoded as the natural numbers $0$ and
$1$, but the type system is intended to restrict the use to these
values only. Finally, we assume a set of Basic Block names. These are used to refer
to groups of basic blocks.

The LLVM IL severely limits extent where one is allowed to use a
specific syntactic class. This is probably due to the ILs heritage; it
is essentially an imperative, typed assembly language. In the course
of development, we started with a language more closely resembling a
functional language and then gradually stratified the syntactic
classes until it matched that of LLVM as much as possible.

Of course, since LLVM has no formal description and the informal
description lacks precision\cite{lattner.ea:2009:llvm-ref}, we run the
risk of having mistaken something in the definition.

\newcommand{\registers}{\mathrm{Registers}}
\newcommand{\constants}{\mathrm{Constants}}
\newcommand{\operations}{\mathrm{Operations}}
\newcommand{\instructions}{\mathrm{Instructions}}
\newcommand{\programs}{\mathrm{Programs}}
\newcommand{\definitions}{\mathrm{Definitions}}
\newcommand{\basicblocks}{\mathrm{Basic Blocks}}
\newcommand{\iret}[1]{\mathbf{ret} \; #1}

\newcommand{\ibr}[2]{\mathbf{br} \; #1 \; #2}
\newcommand{\ibrc}[5]{\mathbf{brc} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\ilet}[3]{\mathbf{let} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\iletrec}[3]{\mathbf{letrec} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\ido}[3]{\mathbf{do} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\icall}[4]{\mathbf{call} \; #1 = #2 #3\; \mathbf{in} \;
  #4}
\newcommand{\ipgm}[2]{\mathbf{Def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{align*}
    \registers \ni r & ::= x_1, x_2, x_3, \dotsc\\
    \constants \ni c & ::= \; r \bor \nat \bor \bool \\
    \operations \ni op & ::= c \\
                       & \bor \quad c + c \\
                       & \bor \quad c - c \\
                       & \bor \quad c < c \\
   \basicblocks \ni d  & ::= \lambda (x_1, x_2, \cdots, x_n) . i\\
   \instructions \ni i & ::= \iret{c} \\
                       & \bor \quad \ibr{bb^n}{(c_1, \dotsc, c_n)} \\
                       & \bor \quad \ibrc{c}{bb^n}{(c_1, \dotsc, c_n)}{bb^n}{(c'_1, \dotsc, c'_n)}\\
                       & \bor \quad \ilet{r}{op}{i} \\
                       & \bor \quad \iletrec{bb}{(d_1, d_2, \dotsc, d_n)}{i} \\
                       & \bor \quad \ido{r}{i_1}{i_2} &
                       (\text{Internal})\\
                       & \bor \quad \icall{r}{f}{(c_1, \dotsc,
                         c_n)}{i}\\
    \definitions \ni \Phi & ::= \cdot \bor (f(x_1, \dotsc, x_n) = i, \Phi)\\
    \programs \ni p & ::= \ipgm{\Phi}{i}
  \end{align*}
  \caption{Syntax}
  \label{fig:syntax}
\end{figure}

\section{Main syntax}

In figure \ref{fig:syntax} we present the complete syntax for the
Mini-LLVM language. An LLVM register '\%x' is mapped onto a set of
registers $x_1, \dotsc$. The constants of the language are exactly
registers, natural numbers and boolean values. The language has three
primitive operations, namely $c + c$, $c - c$ and $c < c$. Of these,
the latter returns a boolean value, whereas the first two return
natural numbers. The '$-$' operation is defined such that if $y \geq x$
then $x - y = 0$.

The main part of Mini-LLVM are the instructions. The instruction
$\iret{v}$ represents returning a value from a function. It models the
LLVM '\texttt{ret}' instruction. The instruction $\ibr{bb^k}{(c_1,
  \dotsc, c_n)}$ designates an unconditional branch to the $k$th
projection in the basic block bundle represented by the name $bb$. The
parameters $c_1$ through $c_n$ are formal $\phi$-node parameters to
the given basic block. In LLVM, the projections are named explicitly
by identifier names, but we felt that a projection is easier to handle
from a formal viewpoint.

The $\ibrc{x}{bb^k}{Ps}{bb^{k'}}{Ps'}$ represents a conditional
branch. It will, depending on the value of $x$ transfer control to
either the first or second basic block projection, injecting the
corresponding set of $\phi$-node parameters. In LLVM both
branch-instructions are called '\texttt{br}' -- the syntactical
difference discriminates them.

As noted in the design considerations, we represent a sequential chain
of operations as a chain of let-style-bindings. Thus the
$\ilet{x}{op}{i}$ instruction represents sequential execution. An
operation is executed and its result is placed into the register
$x$. The register is then available in the $i$ instruction.

Basic blocks are introduced with the $\iletrec{bb}{(d_1, \dotsc,
  d_n)}{i}$ notation. This simultaneously binds the definitions $d_1$
through $d_n$ of basic blocks to the name $bb$. Note each definition will
take formal parameters for its $\phi$-nodes. The name $bb$ will be
available in the context of the instruction $i$.

The $\ido{x}{i_1}{i_2}$ instruction is not meant to be present in
initial Mini-LLVM programs. It is used internally to keep the context
of a function call around. This has to do with the fact that the
formalization lacks a stack and thus uses the current continuation
context to keep track of where the computation came from. Function
calls utilize the instruction while they are executing.

Finally the $\icall{r}{f}{(c_1, \dotsc, c_n)}{i}$ instruction
represents an LLVM '\texttt{call}' instruction in a very simplified
way. In LLVM it is possible to annotate the call-instruction with a
large number of hints. These hints are used to handle calling
conventions, tall-call applicability, etc., but we omit them in our
formalization because we do not attempt to formalize these aspects of
LLVM. The instruction will call the $f$ function with parameters $c_1$
through $c_n$ returning the result in the $r$ register. The result
will be available in the $i$ instruction. Thus a function call acts
like a special variant of a let-binding.

\paragraph{Programs}

A Mini-LLVM program is a list of definitions $\Phi$ together with an
initial instruction $i$. The notation is $\ipgm{\Phi}{i}$. Usually, we
expect the program to begin by calling a main-function in the list of
definitions, but we have chosen to deviate from LLVM here and allow
the execution of an arbitrary instruction rather a call to main. We
can simply limit valid programs to begin by a forced instruction
call to a function ``\texttt{main}'', should we so desire.

\chapter{Mini-LLVM type sytem}

In this chapter we describe a type system for our Mini-LLVM
language. There are several examples of syntactical problems in the
syntax alone. It is for example possible to use a natural number as a
constant $c$ in $\ibrc{c}{...}{}{}{}$, which is obviously incorrect as
per our semantics, we define later. Another problem might be that
$\ilet{r}{op}{i}$ has a type $\tau$ for the register $r$ but its use
in $i$ is of type $\tau'$ different from $\tau$.

\newcommand{\tpr}{|-_{r}}
\newcommand{\tpc}{|-_{c}}
\newcommand{\tpop}{|-_{o}}
\newcommand{\tpb}{|-_{b}}

To take care of these problems, we need a type system ruling out these
possibilities in the syntax. In figure \ref{fig:type-judgement-1}, we
present typing relations for registers, constants and
operations. Register typing is simply handled by a judgment form
$\boxed{\Gamma \tpr x}$ with a single rule, TpR, for lookup into the
environment. The judgement form $\boxed{\Gamma \tpc c : \tau}$ states
that in the environment of $\Gamma$ the constant $c$ has type
$\tau$. There are 3 different cases, one for register lookup, and two
for each of the constant types. It is implicitly the case that the $n$
and $b$ are a natural number and boolean value respectively.

The judgment form for operations is $\boxed{\Gamma \tpop op :
  \tau}$. Under the environment of $\Gamma$ the operation $op$ has
type $\tau$. These rules are somewhat straightforward for most
part. The only special case is that the less-than comparison operator
has boolean type.

Basic blocks are typed by checking that each of the formal parameters
have the stated type as a parameter and in the instruction body. Note
that we do not consider the return type of the instruction as we
handle it later on when type checking functions.

\begin{figure}
  \begin{gather*}
    \text{Registers:} \quad \boxed{\Gamma \tpr x : \tau}\\
    \inference[TpR]{\Gamma(x) = \tau}{\Gamma \tpr x : \tau}
  \end{gather*}
  \begin{gather*}
    \text{Constants:} \quad \boxed{\Gamma \tpc c : \tau}\\
    \inference[TpC-Var]{\Gamma \tpr x}{\Gamma \tpc x : \tau}\\
    \inference[TpC-Nat]{}{\Gamma \tpc n : \tnat} \quad
    \inference[TpC-Bool]{}{\Gamma \tpc b : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{\Gamma \tpop op : \tau} \\
    \inference[TpOp-Cst]{\Gamma \tpc c : \tau}{\Gamma |- c : \tau}\\\\
    \inference[TpOp-Plus]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 + o_2 : \tnat} \quad
    \inference[TpOp-Mone]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 - o_2 : \tnat}\\\\
    \inference[TpOp-Let]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 < o_2 : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Basic block Definitions:} \quad \boxed{D;\Psi;\Gamma \tpb d
      : \tau}\\
    \inference[BB-Def]{D;\Psi;\Gamma[x_1 \mapsto \tau_1 \dotsb x_n \mapsto \tau_n] |- i :
  \tau}{D;\Psi;\Gamma \tpb \lambda(x_1, x_2, \dotsc,
      x_n).i : \tau_1 -> \tau_2 -> \dotsc -> \tau_n -> \tau}
  \end{gather*}
  \caption{Typing 1}
  \label{fig:type-judgement-1}
\end{figure}

\fixme{Let a tau be shared among a set of basic blocks perhaps?}
In figure \ref{fig:type-judgement-2} we present the typing relations
for instructions. The general judgment for these is
$\boxed{D;\Psi;\Gamma |- i : \tau}$. This specifies that the
instruction $i$ has a type of $\tau$ in the environment of
$D;\Psi;\Gamma$. The domain $D$ here is the domain of function
contexts (see figure \ref{fig:type-system}) mapping a function name
$f$ to its function type. The domain $\Psi$ maps basic blocks: for
each basic block there is a mapping from the basic block name to a
tuple of basic block types. Finally, the domain $\Gamma$ maps
registers to their types.

An instruction of the form $\iret{c}$ has type $\tau$ if the constant
it returns has. Correct typing of an $\ilet{x}{op}{i}$ instruction
requires that the operation $op$ returns the same type as is used for
the register $x$ in the body $i$.

The rule Tp-do defines a typing of a $\ido{x}{i_1}{i_2}$
instruction. The type of $i_1$ must the the same type as used in
$i_2$. Note the similarity between this instruction and the
let-binding above.\fixme{Decide if we should kill $\Psi$ here}.

Unconditional branches are handled by the Tp-br rule. It states that a
well-typed branch can look up the basic block in the environment of
basic blocks and then take the $k$th projection of this to obtain the
type $\tau_1 -> \dotsc -> \tau$.

Conditional branches are well-typed if each path regarded as
unconditional branches are. Furthermore we require the branch variable
to be a boolean value.

The Tp-letrec rule introduces basic blocks. It first checks that each
basic block definition is well-typed. Then it type checks the body $i$
under an augmented environment where a mapping to the basic block
identifier has been made.

Finally, function calls are well-typed if we can look up the function
identifier in the function environment $D$; and can show the
passed arguments obeys the type scheme.

\begin{figure}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{D ; \Psi ; \Gamma |- i : \tau}\\\\
    \inference[Tp-ret]{\Gamma \tpc c : \tau}{D ; \Psi ;
      \Gamma |- \iret{c} : \tau} \quad
    \inference[Tp-let]{\Gamma \tpop op : \tau_1 \quad D ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- i : \tau}{D ; \Psi ; \Gamma |-
      \ilet{x}{op}{i} : \tau}\\\\
    \inference[Tp-do]{D;\Psi;\Gamma |- i_1 : \tau_1 \quad
      D;\Psi;\Gamma[x \mapsto \tau_1] |- i_2 : \tau} {D;\Psi;\Gamma |-
      \ido{x}{i_1}{i_2} : \tau}\\\\
    \inference[Tp-br]{\Psi(bb) = BB\tau{}s \quad BB\tau{}s(k) : \tau_1 -> \tau_2 -> \dotsc ->
      \tau_n -> \tau\\
      c_1 : \tau_1 \quad c_2 : \tau_2 \quad \dotsb \quad c_n : \tau_n}
    {D;\Psi;\Gamma |- \ibr{bb^k}(c_1, c_2, \dotsc, c_n) : \tau}\\\\
    \inference[Tp-brc]{\Gamma \tpc x : \tbool \\ D;\Psi;\Gamma |-
      \ibr{bb^k}{(c_1, \dotsc c_n)} : \tau \\
    D;\Psi;\Gamma |- \ibr{bb^{k'}}{(c'_1, \dotsc, c'_{n'})} : \tau}{D;\Psi;\Gamma |- \ibrc{x}{bb^k}{(c_1, \dotsc,
        c_n)}{bb^{k'}}{(c'_1, \dotsc, c'_{n'})} : \tau} \\\\
    \inference[Tp-letrec]{D;\Psi;\Gamma \tpb d_1 : Bb \tau_1 \quad
      \dotsb \quad D;\Psi;\Gamma \tpb d_n : Bb
      \tau_n \\
      D;\Psi[bb \mapsto (Bb \tau_1, \dotsc, Bb
      \tau_n)];\Gamma |- i : \tau}{D;\Psi;\Gamma |- \iletrec{bb}{(d1,
        \dotsc, d_n)}{i} : \tau}\\\\
    \inference[Tp-call]{D(f) = \tau_1 -> \dotsc -> \tau_n -> \tau\\
    c_1 : \tau_1 \quad \dotsb \quad c_n : \tau_n}{D;\Psi;\Gamma |- \icall{f}{(c_1, \dotsc,
        c_n)} : \tau}
  \end{gather*}
  \caption{Typing 2}
  \label{fig:type-judgement-2}
\end{figure}

\section{Programs}

A program is well-formed (figure \ref{fig:type-judgement-3}) if it
obeys a wellformedness criterion $\boxed{D |- \Phi : D}$ on its
definitions $\Phi$ and that the body is wellformed in empty Basic
block and variable environments. We write $\boxed{|- P}$ for
well-formed programs.

The criterion for definition blocks examines wellformedness of the
list of definitions. If the definition list is empty, then the
function environment has to be as well. Each function must be
wellformed with respect to its formal parameters and the full
environment $D$. We furthermore require that the function identifier
does not occur twice with the rule $f \not \in D'$.

Note that the rule $D |- \Phi : D$ ties the knot on function
definitions. The function environment $D$ is being examined while it
is being built at the same time.

\begin{figure}
  \begin{gather*}
    \text{Definition Wellformedness:} \quad \boxed{D |- \Phi : D}\\\\
    \inference[Wf-defs/z]{}{D |- \cdot : \cdot}\\\\
    \inference[Wf-defs/s]{D |- \Phi' : D' \quad D;\cdot;[x_1 \mapsto
      \tau_1 \; \dotsb \; x_n \mapsto \tau_n] |- i :
      \tau \quad f \not \in D'}{D |- (f(x_1, \dotsc, x_n) = i, \Phi') : (f
      \mapsto \tau_1 -> \dotsc -> \tau_n -> \tau, D')}
  \end{gather*}
  \begin{gather*}
    \text{Program Wellformedness:} \quad \quad \boxed{|- P}\\\\
    \inference[WF-Pgm]{D |- \Phi : D \quad D;\cdot;\cdot |- i}{|- \ipgm{\Phi}{i}}
  \end{gather*}
  \caption{Typing 3}
  \label{fig:type-judgement-3}
\end{figure}

\chapter{Mini-LLVM Semantics}

In this chapter we present the Mini-LLVM semantics (see figure
\ref{fig:semantics}). Since \twelf{} is partial to operational
semantics, we need to decide between a big-step operational semantics
and a small-step operational semantics.

The semantics in Pierce's seminal work \cite{pierce:2002:types} on
type systems are mostly given in small step semantics. Focusing our
effort on a small-step semantics thus gives us a framework in which
the meta-theory will follow the work of Pierce. A big-step semantics
is also possible, but then we need to work with a separate notion of
when terms terminate.

The small-step semantics -- however -- is \emph{inefficient}: we need
considerably more inference rule applications in order to reduce a
term to canonical form. On the other hand it is \emph{precise}:
certain details (like short-circuiting operators) are more easily
handled by a small step semantics.

We choose a small-step semantics for this work. Mostly to follow the
structural ideas from Pierce's book ``Types and Programming
Languages''.

\paragraph{Step relation for operations}

\newcommand{\eop}{=>_{o}}
For operations, $\boxed{|- op \eop n}$ is the judgement form. The form
states the operation $op$ evaluate to a value of $n$. This
might look like a big-step semantics, but note that all operations are
\emph{primitive} in Mini-LLVM: An operation is limited by the syntax
such that it cannot be a tree.

For each possible operator, there is a corresponding inference
rule. All of these simply unwraps underlying integers and then applies
the proper mathematical arithmetic operation.

\begin{figure}
  \begin{gather*}
    \text{Operations:} \quad \boxed{|- op \eop n}\\
    \inference[E-Cst]{}{|- c \eop n} \quad
    \inference[E-Plus]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 + n_2 = n}{|- c_1 + c_2 \eop n}\\\\
    \inference[E-Mone]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 - n_2 = n}{|- c_1 - c_2 \eop n}\\\\
    \inference[E-Lt]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 < n_2 = b}{|- c_1  < c_2 \eop b}
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{\Phi;BB |- i -> i'}\\
    \inference[S-let]{|- o \eop v}{\Phi;BB |- \ilet{x}{o}{i} ->
      i[v/x]}\\\\
    \inference[S-letrec-v]{}{\Phi;BB |- \iletrec{bb}{(d_1, \dotsc,
        d_n)}{\iret{v}} -> \iret{v}}\\\\
    \inference[S-letrec-s]{\Phi;BB[bb \mapsto Dt] |- i -> i'}
    {\Phi;BB |- \iletrec{bb}{Dt}{i} -> \iletrec{bb}{Dt}{i'}}\\\\
    \inference[S-brc-t]{}{\Phi;BB |-
      \ibrc{\btrue}{bb^k}{Ps}{bb^{k'}}{Ps'} -> \ibr{bb^k}{Ps}}\\\\
    \inference[S-brc-f]{}{\Phi;BB |-
      \ibrc{\bfalse}{bb^k}{Ps}{bb^{k'}}{Ps'} ->
      \ibr{bb^{k'}}{Ps'}}\\\\
    \inference[S-do-s]{\Phi;BB |- i_1 -> i'_1}{\Phi;BB |-
      \ido{x}{i_1}{i_2} -> \ido{x}{i'_1}{i_2}}\\\\
    \inference[S-do-v]{}{\Phi;BB |- \ido{x}{\iret v}{i_2} ->
      i_2[v/x]}\\\\
    \inference[S-call]{\Phi(f) = (\;f(x_1, x_2, \dotsc, x_n) = i'\;)}{\Phi;BB |-
      \icall{r}{f}{(c_1, c_2, \dotsc, c_n)}{i} -> \ido{r}{i'[c_1/x_1, c_2/x_2,
        \dotsc, c_n/x_n]}{i}}\\\\
    \inference[S-br]{BB(bb) = Ks \quad Ks(k) = \lambda(x_1, \dotsc, x_n).i}{\Phi;BB |- \ibr{bb^k}{(c_1, \dotsc, c_n)} ->
      i[c_1/x_1, \dotsc, c_n/x_n]}
 \end{gather*}
 \begin{gather*}
   \text{Programs:} \quad \boxed{|- P --> P'}\\
   \inference[SP]{\Phi;\cdot |- i -> i'}{\ipgm{\Phi}{i} --> \ipgm{\Phi}{i'}}
 \end{gather*}
  \caption{Semantics}
  \label{fig:semantics}
\end{figure}

\paragraph{Step relation for instructions}

Instructions is by far the most complex in this system. They have the
judgment form $\boxed{\Phi;BB |- i -> i'}$. The context $\Phi$
contains function definitions we can call. The context $BB$ contains
the basic blocks we have introduced and can branch to.

In the semantics, we use the notation $i[v/x]$. This means that you
substitute all occurrences of $x$ with $v$ in the syntax tree of
$i$. In other words, if $(\lambda x . i\; x)$ the higher order
abstraction of $i$ then $i[v/x] \equiv (\lambda x . i\; x) v$. We
use this fact extensively when encoding the semantics in \twelf{}.

The basic sequential operation in LLVM is handled by the
$\ilet{x}{op}{i}$ instruction in Mini-LLVM. As already noted in
\ref{llvm-consideration-let}, we translate sequences of instructions
into nested applications of $\mathbf{let}$s. To execute an operation,
$op$, is to know the contents of the register $x$. Since we have the
SSA-property and the SSA/FP correspondence, we can then just propagate
the value of $x$ to all its uses directly. This is done by
substituting the result for $x$ in the body of the let, $i$.

Evaluation of an instruction $\iletrec{bb}{Defs}{i}$ progresses
depending on the structure of $i$. If $i$ is of the form $\iret{c}$,
then there is no reference to the basic blocks, and we can get rid of
them. This is done with the S-letrec-v rule. Otherwise, the S-letrec-s
rule introduces all the basic blocks into the context at once;
followed by a step underneath.  In effect, the body of a
$\mathbf{letrec}$ can act as the scratch-pad for the execution of
basic blocks and be replaced with a new basic block from the context.

Conditional branches examine the boolean value and then step into an
unconditional branch of the right kind. Unconditional branches, the
S-br rule first look up the appropriate basic block in the
environment; then it applies the $k$th projection to get at the
correct basic block. Finally, it resolves the contents of the
$\phi$-nodes by substitution --- again exploiting the SSA/FP
correspondence.

The $\ido{x}{i_1}{i_2}$ instruction is equivalent to a normal
let-construction in an (extended) lambda-calculus. It reduces $i_1$ via the
rule S-do-s until it becomes a canonical value (i.e., a $\iret{c}$);
then applies the rule S-do-v to push down the value of $x$ into the
body $i_2$.

Finally, function calls are handled by the S-call inference rule. We
look up the definition of the function call in the function
context. Then we step into a $\mathbf{do}$ instruction. Thus, we will
use the $\mathbf{do}$ as a scratchpad for the function evaluation. It
is not particularly efficient, but it avoids the introduction of a
separate stack onto Mini-LLVM. Exploitation of the SSA-property leads
to a simple substitution of function parameters.

\paragraph{Step relation for programs}

A Program steps by the form $\boxed{|- P --> P'}$. It simply
introduces the definitions in the context so they are callable from
the body.

\chapter{Twelf encoding}

We now seek to encode the syntax and semantics in Twelf. When
encoding, we must make certain choices along the way. Almost any
operational semantics will omit specific parts --- in the name of
notational simplicity. The encoding needs to take care of this
explicitly, however.

\paragraph{Extrinsic vs. Intrinsic encoding}

When we specify a syntax as an abstract syntax tree in a language like
ML, we usually do so by virtue of a recursive sum type. This syntax
description allows us to write down some \emph{illegal} programs:
certain syntax trees will get stuck under evaluation. A typing
relation then constrain the syntax trees such that only well-typed
programs are allowed. When the typing relation stands next to the
syntax description, we say that the encoding is \emph{extrinsic}.

In contrast, if the programming language has access to Generalized
algebraic data-types (GADTs) or dependent types, we might define the
syntax in way that rejects ill-typed programs directly. This encoding
form, called \emph{intrinsic} encoding, is possible in \twelf{},
\coq{}, \agda{}, and to a certain extent \haskell{}.

Intrinsic encodings have their limitations however. The typing
relation must be static in the sense that it must be driven by the
syntactical rules alone. An extrinsic encoding on the contrary can use
any (Turing Machine-)computable function. This might make the
intrinsic encoding impossible for some typing relations.

In our work, we sought to achieve an intrinsic encoding of as much of
the semantics as possible. This we aimed for an intrinsic encoding of
instructions, but adopted an extrinsic encoding for function
definitions and programs.

\section{The Prelude}

\fixme{The prelude here is badly written currently}
The prelude contains various helper-relations for use in the real
formalization. In other proof systems (e.g., \coq{}\cite{team:coq*1}),
these are already present in a standard library, but for \twelf{} we
are forced to code them by hand.

We encode the boolean values and Peano style natural numbers along with
operations on these. As examples, we encode arithmetic operations and
predicates for equality and non-equality.

\paragraph{properties}

Since we want to use properties of the prelude in meta-theory, we must
prove that the properties are true. In the following, we present some
example properties from the prelude:
\begin{lem}
  Suppose we have two natural numbers $n_1, n_2 \in \NN$. Then there
  exists an $n_3 \in \NN$ such that $n_1 + n_2 = n_3$.
\end{lem}
\begin{proof}
  Induction on $n_1$: If $n_1$ is $0$ then take $n_3 =
  n_2$. Otherwise then by induction $(n_1 - 1) + n_2 = (n_3 - 1)$. To this
  we can add one to both sides to obtain the result.
\end{proof}

Lemmas of this form is very common in \twelf{} signatures. They are
called \emph{effectiveness} lemmas and are usually named with a
\texttt{can-} prefix as in \texttt{can-nat-plus} and
\texttt{can-step-op}. They build a bridge between a pure syntactical
object and an accompanying relation on the object.

Another very common \twelf{} proof is reasoning from false. We have a
special type family defined, \texttt{void}, with no constructors
whatsoever. This can be used to prove absurd statements. Our first
such statement is
\begin{lem}
  Let $n_1$ and $n_2$ be natural numbers. Then $n_1 = n_2 \land n_1
  \neq n_2 \implies \bottom$.
\end{lem}
\begin{proof}
  The proof relies on the fact that the premise is always false. In
  our formal encoding we can analyze the structure on $n_1
  \neq n_2$ to show this.
\end{proof}

We can reason anything from \texttt{void} because void has no valid
constructors. Thus the sentence $\forall v \in \texttt{void} \; . \; \exists
E$ for any $E$ is vacuously true since there is no way the $v$ can be
inhabited.

\section{Syntax encoding}

We would like to use an intrinsic encoding for as much of the syntax
as possible.
\fixme{Describe the ``Twelf Encoding''}
\fixme{Describe all the failed formalization attempts}
\fixme{Describe the toy language for function calls}

\section{Transformation of LLVM Programs to Mini-LLVM}

One rather important milestone in our work is to make sure a correct
LLVM IL program using a supported subset can be transformed into an
equivalent Mini-LLVM program. Our running first example will be the
calculation of triads:
\begin{equation}
  \label{eq:1}
  n? = 1 + 2 + \dotsb + n = \sum_{0 < i \leq n} i
\end{equation}

The notation $n?$ is due to Knuth\cite[section
1.2.5]{knuth:1997:taocp1}. We choose this example over the factorial
function since it is readily computable without the need for a
multiplication operator. Straightforward recursive implementation of
this in C yields:
\begin{verbatim}
int
tri (int n) {
    if (n == 0) { return 0; }
    else return (tri(n-1) + n);
}
\end{verbatim}
We can then use the \clang{} compiler from C to LLVM IL to
generate LLVM code for this C fragment. The \clang{} compiler
circumvents the need to produce SSA code by making all operations
stack movements. Thus the raw output from the compiler cannot be
used.

LLVM contains an optimization pass however, \texttt{mem2reg}, which
can transform stack references into register access. This effectively
eliminates the explicit allocation on the stack.

If we skip for us irrelevant parts about the LLVM data layout, we have
the following function body:
\begin{verbatim}
define i32 @tri(i32 %n) nounwind {
entry:
  %cmp = icmp eq i32 %n, 0
  br i1 %cmp, label %if.then, label %if.else

if.then:
  br label %return

if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return

return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0
}
\end{verbatim}
By hand-translation of this into Twelf, we obtain the following
twelf-function for the same fragment:
\fixme{Insert fragment}
\fixme{Note something about inverted phi-nodes}
\paragraph{Automatic translation}

A full treatment of translation ought to be automatic rather than
hand-written. It certainly looks possible automate the above
translations. If one parses LLVM IL into an abstract syntax tree,
output should be pretty straightforward --- save for the inversion of
$\phi$-nodes.

The inversion can be handled by a two-pass algorithm. In the first
pass we gather $\phi$-nodes for each basic block as well as what value
each branch into the basic block passed. In the second pass, we
replace all branch invocations with tail-calls such that the right
values are passed.

To establish the plausibility of a full isomorphism, an inverse parser
must also be created. This inverse parser should take a
\twelf{}-signature with a test definition and transform it into
equivalent full LLVM code. It has to invert the passing of
$\phi$-nodes as well. This can be done by a similar two-pass scan.
\fixme{Provide at least one more encoding example}

\chapter{Meta-theory}

\fixme{Describe the ``Meta-theory''}
\fixme{Progress}
\section{Lemmas}

To prove the usual meta-theoretic theorems we need some auxiliary
lemmas. For instructions, we need the presence of weakening lemmas for
instructions with respect to variable- and basic-block-contexts.

\begin{lem}
  \label{lem:weaken-gamma}
  Instruction typing admits weakening in the variable context: Suppose
  we have $D;\Psi;\Gamma |- i : \tau$ for contexts $D, \Psi$ and
  $\Gamma$. Further suppose $\Gamma \subseteq \Gamma'$ -- then
  $D;\Psi;\Gamma' |- i : \tau$.
\end{lem}
\begin{rem}
  The notation $\Gamma \subseteq \Gamma'$ warrants some
  explanation. We say that the environment $\Gamma'$ is an
  \emph{extension} or \emph{augmentation} of $\Gamma$: If $\Gamma(x) =
  \tau$ then also $\Gamma'(s) = \tau$ for all $x \in \Gamma$. In
  addition, $\Gamma'$ might have variables which are not in the
  original $\Gamma$, and these are required to not shadow any existing
  variables. We note this is an accordance with the SSA property of
  Mini-LLVM/LLVM.
\end{rem}
\begin{proof}(Sketch)
  Since we have $D;\Psi;\Gamma |- i : \tau$ we know that $i$ can't use
  any variable but those in $\Gamma$ and those introduced in the
  typing derivation. If we systematically use $\alpha$-conversion, we
  can avoid capture of a new variable $y \not \in \Gamma$. Thus we can
  use $y$ in $\Gamma'$ extending it with one new name.

  Continuing this process, we can extend to the full $\Gamma'$.
\end{proof}
\begin{lem}
  \label{lem:weaken-psi}
  Instruction typing admits Basic Block weakening: if $D;\Psi;\Gamma
  |- i : \tau$ and $\Psi \subseteq \Psi'$ then $D;\Psi';\Gamma |- i :
  \tau$.
\end{lem}
\begin{proof}
  I have no idea on how to do this yet.\fixme{Get an idea on the weakening!}
\end{proof}
\section{Progress}
\fixme{Progress}
\section{Preservation}

We would like to prove the following theorem:
\begin{thm}
  \label{thm:preservation}
  If $|- P$ and $|- P --> P'$ then $|- P'$.
\end{thm}
To do that, we need a lemma:
\begin{lem}
  \label{thm:preservation-i}
  Suppose $D |- \Phi : D \; \land \; D;\Psi;\Gamma |- i : \tau$ and $D;\Psi;\Gamma |- i ->
  i'$. Then we have $D;\Psi;\Gamma |- i' : \tau$
\end{lem}
\begin{proof}
  Induction on: $D;\Psi;\Gamma |- i -> i'$:
  \begin{itemize}
  \item (Branch) If the step is of the form
    \begin{equation*}
    \inference{BB(bb) = Ks \quad Ks(k) = \lambda(x_1, \dotsc, x_n).i}{\Phi;BB |- \ibr{bb^k}{(c_1, \dotsc, c_n)} ->
      i(c_1, \dotsc, c_n)}
    \end{equation*}
    then we must have the following type derivation
    \begin{equation*}
    \inference{\Psi(bb) = BB\tau{}s \quad BB\tau{}s(k) : \tau_1 -> \tau_2 -> \dotsc ->
      \tau_n -> \tau\\
      c_1 : \tau_1 \quad c_2 : \tau_2 \quad \dotsb \quad c_n : \tau_n}
    {D;\Psi;\Gamma |- \ibr{bb^k}(c_1, c_2, \dotsc, c_n) : \tau}
    \end{equation*}
    The type of the basic block $bb$ is then $BB\tau{}s$. The $k$th
    projection must have type $\tau_1 -> \dotsc -> \tau_n ->
    \tau$. Since the basic block $bb$ must have been introduced at a
    $\mathbf{letrec}$, we have that $D;\Psi';\Gamma' \tpb \lambda(x_1, \dotsc,
    x_n).i : \tau_1 -> \dotsc -> \tau_n -> \tau$. Note that the
    contexts of variables and basic block definitions are different
    than those we want. But as $\Gamma' \subseteq \Gamma$ and $\Psi'
    \subseteq \Psi$ we can utilize lemma \eqref{lem:weaken-gamma}
    and \eqref{lem:weaken-psi} to obtain a proof of $D;\Psi;\Gamma
    |- t : \tau$ as wanted.
  \end{itemize}
\end{proof}
\fixme{Rename ``Gamma'' in the Twelf code to something sensible}
\section{Determinism}
\fixme{Determinism}
\chapter{Development Process}

In this chapter, we describe the development process in the
project. Constructing formal semantics for an existing system by
discovering how it works contains several tripwires, booby traps and
some barbed wire. The crux of the problem is that syntax, types,
semantics and meta-theory fit together in an intricate network:
altering one of them may render the other parts invalid. Further
complication is added by LLVM: We cannot deviate too much from the
LLVM IL.

In practice, we needed to carry out several attempts in formalizing
Mini-LLVM before we arrived at the current formalization. In certain
ways even this formalization is incomplete; lacking any kind of memory
instructions and exceptions.

The formalization was built up from two simpler systems. The first
system was a first-order functionally inspired language with the
$\mathbf{letrec}$ as its most prominent feature. This system helped us
understand a way to formalize mutually recursive functions in
\twelf{}. We note that this already
exists\cite{twelfwiki:2007:mutually-recursive}, but we wanted to
discover if it was possible to define a variant based in intrinsic
typing and \twelf{}-contexts. It was then proven the system had the
properties of \emph{progress} and \emph{determinism}. The
preservation-property was obtained automatically by the intrinsic
encoding: the step-relation in \twelf{} was
\begin{verbatim}
step : tm T -> tm T -> type.
\end{verbatim}
stating that the step relation preserved the type directly.

The second system is presented in figure \ref{fig:func-call-lang}. It
is a small toy language for the function call semantics. It was
separately proven that this language has progress, preservation and
determinism as well.

The Mini-LLVM formalization was then built by stratifying the first
language from (functional) terms into registers, constants, operations
and instructions syntactically; and then adding the second language on
top of it. The result is the Mini-LLVM formalization presented in this
report.

\chapter{Conclusion}

\paragraph{Summary}
\paragraph{Further work}
\fixme{Write the conclusion}


\bibliography{biblio}
% State what the goals of this project is.
% State we focus on the operational semantics.
% State we will use Twelf where applicable if time allows.

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
