\documentclass[a4paper, oneside, 10pt, draft]{memoir}

\chapterstyle{culver}
\RequirePackage[english]{jlouis}

\author{Jesper Louis
  Andersen\\jesper.louis.andersen@gmail.com\\140280-2029}
\title{Formalizing a Virtual Machine}
\date{\today}

\newlength{\drop}
\newcommand*{\titleM}{\begingroup% Misericords, T&H p 153
  \drop = 0.08\textheight
  \centering
  {\Huge\bfseries Lambda}\\[\baselineskip]
  {\scshape IR of exsml}\\[\baselineskip]
  {\scshape by}\\[\baselineskip]
  {\large\scshape Jesper Louis Andersen\\jesper.louis.andersen@gmail.com}\par
  \endgroup}

\newcommand{\clang}{\textsc{Clang}}
\newcommand{\twelf}{\textsc{Twelf}}
\newcommand{\coq}{\textsc{Coq}}
\newcommand{\agda}{\textsc{Agda}}
\newcommand{\haskell}{\textsc{Haskell}}

\newcommand{\bottom}{\perp}
\bibliographystyle{plain}

\begin{document}
\listoffixmes{}
\maketitle{}
\begin{abstract}
  We present the language Mini-LLVM, an idealized subset of the IL
  language for the \emph{Low Level Virtual machine}(LLVM). From an
  informal LLVM-description, we give a formal account of the syntax,
  semantics types and meta-theoretic properties of Mini-LLVM. We thus
  establish the -- to our knowledge -- first partial formalization of
  LLVM. Our formalization exploits the SSA-form requirement of the
  LLVM IL in a novel way to transform the IL into a functional
  representation. The representation and its meta-theoretic properties
  are encoded into the \twelf{} logical framework and we provide proof
  of \emph{progress}, \emph{preservation} and \emph{determinism} for
  well-typed programs. Finally, we show how small
  LLVM IL programs can be translated to our Mini-LLVM language and
  show that they agree on certain inputs --- making it plausible our
  Mini-LLVM is adequate.
\end{abstract}
\newpage{}
\tableofcontents{}
\newpage{}
\section{Foreword}

This report is meant to be read by people interested in the LLVM
compiler infrastructure. The goal from the beginning was to shed
light on the informal approach of LLVM. The basic premise was that
``if their system works, then it can be formalized'' -- though it
might prove very hard to do so.

The work was produced by trying to formalize smaller systems and then
stitch them together. On the large scale, numerous ``full restarts''
happened when something new was discovered that affected the complete
formalization. This report attempts to convey the final result, but it
omits thorough treatment of all the intermediate steps. Production of
formal systems is partially a learning experience: you keep working
with the system until you can treat the whole system in your head and
understand each part. Then, and only then, can you
present the system in its complete form.

In retrospect, it would probably have been advantageous to let
\twelf{} enter later in the process. The logical framework was used
from the very beginning, and that might have hampered development. The
logic is that if you are struggling with a proof, you do not want to
be struggling with \twelf{} at the same time.

Of course, since this is a learning process as well as a presentation,
it is very possible that the treatment contains errors and
omissions --- they are all mine. I am of the belief that you learn
more by trying and failing than by standing on secure ground all the
way.\\

\begin{flushright}
  Jesper Louis Andersen, December 2009.
\end{flushright}

\newpage{}
\chapter{Introduction}

\fixme{Go through the whole encoding chapter. It needs some help!}
\fixme{Mention something about $\alpha$-conversion and
  contexts. Particularly that it comes for free in \twelf{}}
It is well known in compiler construction, that intermediate languages
are a useful and beneficial abstraction\cite{appel:1998:modern,
  mogensen:2008:basics}. Rather than targeting the instruction set
architecture directly, the compiler constructor first targets an
intermediate language (IL). Then the IL and is afterwards compiled to
the target machines instruction set\footnote{Sans
  optimizations. Optimization is usually carried out on the IL as
  well}. Schematically, the phases can be described as:
\begin{equation*}
  L ->^{fe} IL ->^{be} Q
\end{equation*}
where $L$ is the source language; the arrow marked by $fe$ the
front-end compilation; and the arrow marked by $be$ is the back-end
compilation onto the machine language $Q$. The construction is
advantageous because the compiler writer can share either the
front-end among several back-ends or the back-end among several
front-ends.

An interesting idea is to have a software program, the \emph{Virtual
  Machine} (VM), handle the work of the backend. The front-end
targets the IL and packs it up for transfer as a binary format. This
format is usually called \emph{bytecode}. The VM then either
interprets the IL or just-in-time compiles before execution. From the
eagles perspective, the VM software acts as a machine able to directly
execute the VM code.

ILs are usually designed to make front-end construction easier. The IL
can specifically factor out details of the underlying machine thus
simplifying compiler implementation. As an example, most VMs carry out
register allocation and the programmer is given an abstraction: either
a stack or an infinite set of registers. Some VMs are designed with a
fairly broad IL intended to capture many different language types
while others are more constrained, often tied to a single intended
language. Examples of the former are the the .NET
CLR/CIL\cite{ecma:2006:335} the C-\ - language\cite{http:cminmin} and
the LLVM infrastructure \cite{lattner.ea:2009:llvm-ref}, while an
example of the latter is the Warren abstract
machine\cite{warren:1983:prolog}.

\section{LLVM}

This report concerns itself with a virtual machine named LLVM, the Low
Level Virtual Machine. It adopted this name because the LLVM IL is
close to an idealized assembly language with several convenient
differences of which we list some:
\begin{itemize}
\item All LLVM IL programs are statically typed. This rules out many
  common programming errors and fits well into compilation schemes
  where intermediate stage transforms are type-checked.
\item There is an infinite amount of registers and register allocation
  is carried out by the LLVM system.
\item Correct LLVM IL programs have the SSA-property: A variable has
  only one (static/syntactic) point in the program where it is
  \emph{defined}. All \emph{uses} of a variable must then be from this
  single static assignment. The usual $\phi$-node method is used to
  handle the case where control flow joins in the CFG.
\item LLVM has a built-in exception primitive.
\item LLVM is expected to carry out a large number of advanced
  optimizations on its IL with the intent of simplifying work for
  compiler writers.
\end{itemize}

However, one Achilles heel of the LLVM IL is the total lack of
formality. There is not even an EBNF of its grammar available and no
attempts have been made to define its semantics operationally.

In this report, we aim for a subset of the LLVM IL language and
provide a syntax description, an operational (small-step) semantics and a type
system. We seek to prove the system fulfills the usual meta-theoretical
properties of \emph{progress} and \emph{preservation} as well as
\emph{determinism}.

The state-of-the-art emphasized by the poplmark
challenge\cite{aydemir:2005:mechanizedmetatheory} is the encoding of
syntax, semantics and proofs into a proof assistant or logical
framework. The goal is that every computer scientific report is
accompanied by a formal proof written such that the computer can
verify its correctness. In this report we aim for this goal: every
formal description has been encoded into the logical framework of
\twelf{}\cite{schurmann.pfenning:twelf} for verification.

\section{Report structure}

The report first introduces some preliminaries and then presents the
real work made in the following chapters: syntax, semantics and
meta-theory of our Mini-LLVM language is presented. It is expected
that the reader is familiar with operational semantics, proof theory
and machine verifiable proofs; in particular the \twelf{} logical
framework. It is also expected that the reader is familiar with
SSA-form and its implications (i.e., as found in
\cite[Chapter 19]{appel:1998:modern}).

\chapter{Design considerations}

\fixme{Read from ``Design considerations'' and onwards}
In this section, we limit the scope of the formalization and present
the main design considerations before attempting to formalize the work.

\begin{figure}
\begin{verbatim}
if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return
return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0

\end{verbatim}
  \caption{An example LLVM fragment}
  \label{fig:llvm-example-1}
\end{figure}

Figure \ref{fig:llvm-example-1} contains an example of a typical LLVM
basic block. The example is code generated by the \clang{} C frontend,
which compiles C code to LLVM IL. It begins with a label, identifying
the block. Then a series of instructions follow and the block ends in
an unconditional branch to the label '\texttt{\%return}'. Local
definitions in LLVM are prefixed by a '\%' marker and global
(top-level) names by an '@' marker. The instructions \texttt{sub,
  call, } and \texttt{add} informally act like one would expect. Note
that the result are stored in registers named \texttt{\%sub},
\texttt{\%add}, and \texttt{\%call}. This is somewhat confusing and
using $r_1, r_2, \dotsc$ would probably have been simpler to
understand. But we keep the output of the \clang{} compiler as we will
return to it later.

The LLVM type system can be seen in the type designation \texttt{i32},
a 32-bit integer and finally, the '\texttt{nsw}' designation is a
LLVM-specific flag for integer wrap-around, which can be ignored.

In the basic block for the return, we first do a $\phi$-node
assignment. These assignments are required to be at the very top of a
basic block and transfer the value from the appropriate basic block
depending on the control flow. The '\texttt{ret}' instruction
returns. Note that this fragment has the SSA property.

Since we would like to represent LLVM in a machine checkable form in
\twelf{}, we utilize a result formulated explicitly by
Appel\cite{appel:1998:modern, appel:1998:ssa}: every SSA program has
an equivalent functional program. Thus our first design choice is to
represent the LLVM subset as a functional first order program to ease
its encoding in \twelf{}. As we shall see, the SSA-property of LLVM
programs greatly simplifies a number of otherwise complex interactions
in the semantics. Informally, we can transform a fragment
\label{llvm-consideration-let}
\begin{verbatim}
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  ...
\end{verbatim}
of two instructions following each other into the functional fragment:
\begin{verbatim}
  let %sub = sub i32 %n, 1
  in let %call = call i32 @tri(i32 %sub)
     in ...
\end{verbatim}

Note how the lexical scoping rules binds the '\texttt{\%sub}' value
in the correct scope.

We handle the basic blocks as Appel: each basic block becomes a
function with formal parameters the $\phi$-node variables. A branch to
a basic-block then tail-calls the function with the variables needing
transfer as parameters. In the example, we would have a function
\begin{verbatim}
return (%retval) =
   ret %retval
\end{verbatim}
for the return-basic-block. And the branch to it would be
\begin{verbatim}
if.else (...) =
  ...
    br %return (%add)
\end{verbatim}
to designate that the value of '\texttt{\%add}' is the one that should
go to the first $\phi$-node.

In the paper of Appel\cite{appel:1998:ssa}, it is shown that a
lexically scoped functional form is superior to a more linear form in
which all basic blocks are introduced in the same scope. The lexical
scoping of basic blocks will let us represent programs in a more
convenient form, as is noted by the paper. We thus chose to deviate
from the LLVM IL in this respect, and follow the functional form more.

\section{Extent of the formalization}

We limit the extent of the formalization to a small subset of
LLVM. First, we note the complete lack of any formal grammar for
the language means we have to begin from a clean slate. Thus,
establishing a small subset is more important as a first step towards
the goal.

We cut any heap-interaction. Specifically, we cut the ability to
load and store data to a heap. LLVM allows pointer arithmetic in the
heap which is hard to handle meta-theoretically. We also cut a large
number of operations that would be easy to add but don't provide
any further insight. Conversion operations are not going to be
considered, as they contain a potentially unsafe '\texttt{bitcast}'
operation. ``Aggregate'' and ``Vector'' operations are not going to be
considered (these include structs and arrays). Finally, we won't be
considering instructions handling exceptions.

While the list of omissions seems extensive, it is important to stress
that part of the task is to understand the subset that is left to a
level where it can be put into a formal system.

Under the course of development, we will use LLVM version 2.x. We
mention this because LLVM is only supposed to change in a backwards
compatible way as long as it remains a version 2.x.

\chapter{Syntax of Mini-LLVM}

\newcommand{\variables}{\mathrm{Variables}}
\newcommand{\BBlabels}{\mathrm{Labels}}
\newcommand{\tnat}{\mathbf{nat}}
\newcommand{\tbool}{\mathbf{bool}}
\newcommand{\types}{\mathrm{Types}}
\newcommand{\typelist}{\mathrm{Type lists}}
\newcommand{\bbtype}{\mathrm{Label Type}}
\newcommand{\ftype}{\mathrm{Fun Contexts}}
\newcommand{\tpenv}{\mathrm{Var Contexts}}
\newcommand{\bbenv}{\mathrm{Label Contexts}}
\newcommand{\bor}{\; \vert \;}
\newcommand{\ntypes}{\tau_1 \times \tau_2 \times \dotsb \times \tau_n}
\newcommand{\ntypesp}{\tau'_1 \times \tau'_2 \times \dotsb \times
  \tau'_n}
\newcommand{\ntypespp}{\tau_1 \times \tau_2 \times \dotsb \times \tau_{n'}}
In this and the following sections, we present the language
Mini-LLVM. Mini-LLVM is a subset of the LLVM IL in functionality ---
it takes a different approach with respect to SSA-form: Mini-LLVM is a
first order functional language whereas the LLVM IL is an imperative
SSA-form. A functional form is expected to be easier to work with,
formally -- especially in the logical framework \twelf{}.

In the present section, we present the syntax of Mini-LLVM in a formal BNF
grammar. We also describe the type system as well as the basic domains
from which we draw values.

\section{Domains}


\newcommand{\numbers}{\mathrm{Numbers}}
\newcommand{\booleans}{\mathrm{Booleans}}
\newcommand{\funlabels}{\mathrm{Function\; labels}}
\newcommand{\nat}{n}
\newcommand{\bool}{b}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\btrue}{\mathbf{True}}
\newcommand{\bfalse}{\mathbf{False}}
\newcommand{\dbundle}{(d_1, d_2, \dotsc, d_m)}
\newcommand{\sbundle}{(\sigma_1, \sigma_2, \dotsc, \sigma_m)}
\newcommand{\bbtypes}{\sbundle}
Our language will be using several syntactic terminal domains, the
existence of which we assume (figure \ref{fig:syntactic-domains}). We
have variables, $x_1, x_2, \dotsc$ used for naming and discriminating
registers from each others. For simplicity we restrict the language to
natural numbers only. This restriction is due to \twelf{}: we need to
encode the system of numbers and Peano-style natural numbers are
fairly simple to work with and handle. Verification in other systems
might have chosen another domain. We only utilize basic properties of
arithmetic in our verification, hence it might be possible to change
this later on.
\begin{figure}
  \begin{align*}
    \numbers \ni \NN, \nat & ::= 0 \bor 1 \bor 2 \bor \dotsc\\
    \booleans \ni \BB, \bool & ::= \btrue \bor \bfalse \\
    \BBlabels \ni l & ::= l_1, l_2, l_3, \dotsc \\
    \funlabels \ni f & ::= f_1,f_2,f_3,\dotsc
  \end{align*}
  \caption{Syntactic domains}
  \label{fig:syntactic-domains}
\end{figure}

Boolean values are either the true value or the false
value. Internally these are encoded as the natural numbers $0$ and
$1$, but the type system is intended to restrict the use to these
values only. In the LLVM IL, an integer variable is typed as its
bit-size, so \texttt{i32} is a 32-bit integer. The special case
\texttt{i1} designate a boolean variable with values 0 or 1. Our
Mini-LLVM language model this by the above construction. Finally, we
assume a set of Basic Block label names and a set of function
names. These are used to refer to groups of basic blocks and
functions, respectively.

In the course of development, we started with a language more closely
resembling a functional language and then gradually stratified the
syntactic classes until it matched that of LLVM as much as
possible. Being an imperative language, LLVM resembles the usual
imperative construction with statements and expressions as stratified
syntactical classes.

Of course, since LLVM has no formal description and the informal
description lacks precision\cite{lattner.ea:2009:llvm-ref}, we run the
risk of having mistaken something in the definition. To mitigate this
risk somewhat, we also used the current LLVM system as a source by
studying and analyzing compiler output from various compilers
targeting LLVM; in particular, the \clang{}-project was used.

\newcommand{\registers}{\mathrm{Registers}}
\newcommand{\constants}{\mathrm{Constants}}
\newcommand{\operations}{\mathrm{Operations}}
\newcommand{\instructions}{\mathrm{Instructions}}
\newcommand{\programs}{\mathrm{Programs}}
\newcommand{\definitions}{\mathrm{Definitions}}
\newcommand{\basicblocks}{\mathrm{Basic Blocks}}
\newcommand{\iret}[1]{\mathbf{ret} \; #1}

\newcommand{\ibr}[2]{\mathbf{br} \; #1 \; #2}
\newcommand{\ibrc}[5]{\mathbf{brc} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\ilet}[3]{\mathbf{let} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\iletrec}[3]{\mathbf{letrec} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\ido}[3]{\mathbf{do} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\icall}[4]{\mathbf{call} \; #1 = #2 #3\; \mathbf{in} \;
  #4}
\newcommand{\ipgm}[2]{\mathbf{Def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{align*}
    \registers \ni r & ::= x_1, x_2, x_3, \dotsc\\
    \constants \ni c & ::= \; r \bor \nat \bor \bool \\
    \operations \ni op & ::= c \\
                       & \bor \quad c + c \\
                       & \bor \quad c - c \\
                       & \bor \quad c < c \\
   \basicblocks \ni d  & ::= \lambda (x_1, x_2, \cdots, x_n) . s\\
   \instructions \ni s & ::= \iret{c} \\
                       & \bor \quad \ibr{l^n}{(c_1, \dotsc, c_n)} \\
                       & \bor \quad \ibrc{c}{l^n}{(c_1, \dotsc, c_n)}{l^n}{(c'_1, \dotsc, c'_n)}\\
                       & \bor \quad \ilet{x}{op}{s} \\
                       & \bor \quad \iletrec{l}{\dbundle}{s} \\
                       & \bor \quad \ido{x}{s_1}{s_2} &
                       (\text{Internal})\\
                       & \bor \quad \icall{x}{f}{(c_1, \dotsc,
                         c_n)}{s}\\
    \definitions \ni D & ::= \cdot \bor (f(x_1, \dotsc, x_n) = s, D)\\
    \programs \ni p & ::= \ipgm{D}{s}
  \end{align*}
  \caption{Syntax}
  \label{fig:syntax}
\end{figure}

\section{Main syntax}

In figure \ref{fig:syntax} we present the complete syntax for the
Mini-LLVM language. The atomic expressions of the language are exactly
registers, natural numbers and boolean values. The language has three
primitive operations, namely $c + c$, $c - c$ and $c < c$. Of these,
the latter returns a boolean value, whereas the first two return
natural numbers. The '$-$' operation is defined such that if $y \geq
x$ then $x - y = 0$.

Instructions form the main part of Mini-LLVM. The instruction
$\iret{c}$ represents returning a value from a function. It models the
LLVM '\texttt{ret}' instruction.

Basic blocks are introduced with the $\iletrec{l}{\dbundle}{s}$
notation. This simultaneously binds the definitions $d_1$ through
$d_m$ of basic blocks to the name $l$. Note each definition will take
formal parameters for its $\phi$-nodes. The name $l$ will be
available in the context of the instruction $s$. We will often in the
following call a basic block mapping $l \mapsto \dbundle$
for a Basic block \emph{bundle}.

The instruction $\ibr{l^k}{(c_1, \dotsc, c_n)}$ designates an
unconditional branch to the $k$th projection in the basic block bundle
represented by the name $l$. The parameters $c_1$ through $c_n$ are
formal $\phi$-node parameters to the given basic block. In LLVM, the
projections are named explicitly by identifier names, but we felt that
a projection is easier to handle from a formal viewpoint.

The $\ibrc{x}{l^k}{(c_1, \dotsc, c_n)}{l^{k'}}{(c_1, \dotsc, c_n)'}$ represents a conditional
branch. It will, depending on the value of $x$ transfer control to
either the first or second basic block projection, injecting the
corresponding set of $\phi$-node parameters. In LLVM both
branch-instructions are called '\texttt{br}' -- the syntactical
difference discriminates them.

As noted in the design considerations, we represent a sequential chain
of operations as a chain of let-style-bindings. Thus the
$\ilet{x}{op}{s}$ instruction represents sequential execution. An
operation is executed and its result is placed into the register
$x$. The register is then available in the $s$ instructions.

The $\ido{x}{s_1}{s_2}$ instruction is not meant to be present in
initial Mini-LLVM programs. It is used internally to keep the context
of a function call around. This has to do with the fact that the
formalization lacks a stack and thus uses the current continuation
context to keep track of where the computation came from. Function
calls utilize the instruction while they are executing.

Finally the $\icall{x}{f}{(c_1, \dotsc, c_n)}{s}$ instruction
represents an LLVM '\texttt{call}' instruction in a very simplified
way. In LLVM it is possible to annotate the call-instruction with a
large number of hints. These hints are used to handle calling
conventions, tall-call applicability, etc., but we omit them in our
formalization because we do not attempt to formalize these aspects of
LLVM. The instruction will call the $f$ function with parameters $c_1$
through $c_n$ returning the result in the $r$ register. The result
will be available in the $s$ instructions. Thus a function call acts
like a special variant of a let-binding.

\paragraph{Programs}

A Mini-LLVM program is a list of definitions $\Phi$ together with an
initial instruction $s$. The notation is $\ipgm{\Phi}{s}$. Usually, we
expect the program to begin by calling a main-function in the list of
definitions, but we have chosen to deviate from LLVM here and allow
the execution of an arbitrary instruction rather a call to main. We
can simply limit valid programs to begin by a forced instruction
call to a function ``\texttt{main}'', should we so desire.

\chapter{Mini-LLVM type sytem}
\label{chap:type-system}

In this chapter we describe a type system for our Mini-LLVM
language. That we need a type system should be clear: our syntax
allows programs which can get stuck and we want a type system to
constrain programs.

\paragraph{Type Domains} The language employs a simple type system as in
figure \ref{fig:type-system}. There are two primitive base types,
natural numbers and boolean values. For handling passing of parameters
between basic blocks via $\phi$-nodes, there is a $\bbtype$
designation stating a (possibly empty) list of formal parameters. We
notate such lists as $\ntypes -> \bullet$ where the last
``$\bullet$'' states that it is a function but without return type.
The choice of two primitive types is deliberate. It is the simplest
non-trivial choice of types possible. Had there only been one base
type, all typing degenerates into questions on type arity in basic
block definitions.

\begin{figure}
  \begin{align*}
    \types \ni \tau & ::= \tnat \bor \tbool \\
    \bbtype \ni \sigma   & ::= \ntypes -> \bullet\\
    \ftype \ni \Phi & ::= \cdot \bor (f \mapsto (\ntypes -> \tau), \Phi) \\
    \tpenv \ni \Gamma & ::= \cdot \bor (x \mapsto \tau),\Gamma\\
    \bbenv \ni \Psi   & ::= \cdot \bor (l \mapsto \bbtypes),\Psi
  \end{align*}
  \caption{Type system}
  \label{fig:type-system}
\end{figure}

\newcommand{\tpr}{|-_{\mathrm{r}}}
\newcommand{\tpc}{|-_{\mathrm{c}}}
\newcommand{\tpop}{|-_{\mathrm{o}}}
\newcommand{\tpb}{|-_{\mathrm{b}}}

\begin{figure}
  \begin{gather*}
    \text{Registers:} \quad \boxed{\Gamma \tpr x : \tau}\\
    \inference[TpR]{\Gamma(x) = \tau}{\Gamma \tpr x : \tau}
  \end{gather*}
  \begin{gather*}
    \text{Constants:} \quad \boxed{\Gamma \tpc c : \tau}\\
    \inference[TpC-Reg]{\Gamma \tpr x}{\Gamma \tpc x : \tau}\\
    \inference[TpC-Nat]{}{\Gamma \tpc n : \tnat} \quad
    \inference[TpC-Bool]{}{\Gamma \tpc b : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{\Gamma \tpop op : \tau} \\
    \inference[TpOp-Cst]{\Gamma \tpc c : \tau}{\Gamma \tpop c : \tau}\\\\
    \inference[TpOp-Plus]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 + c_2 : \tnat} \quad
    \inference[TpOp-Mone]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 - c_2 : \tnat}\\\\
    \inference[TpOp-Lt]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 < c_2 : \tbool}
  \end{gather*}
  \caption{Typing 1}
  \label{fig:type-judgement-1}
\end{figure}

To take care of these problems, we need a type system ruling out these
possibilities in the syntax. In figure \ref{fig:type-judgement-1}, we
present typing relations for registers, constants and
operations. Register typing is simply handled by a judgment form
$\boxed{\Gamma \tpr x}$ with a single rule, TpR, for lookup into the
environment. The judgement form $\boxed{\Gamma \tpc c : \tau}$ states
that in the environment of $\Gamma$ the constant $c$ has type
$\tau$. There are 3 different cases, one for register lookup, and two
for each of the constant types.

The judgment form for operations is $\boxed{\Gamma \tpop op :
  \tau}$. Under the environment of $\Gamma$ the operation $op$ has
type $\tau$. These rules are rather straightforward.

\fixme{Define typing for basic blocks in the text}
\newcommand{\btype}{\ntypes -> \bullet}
\begin{figure}
  \begin{gather*}
    \text{Basic block Definitions:} \quad \boxed{\Phi;\Psi;\Gamma \tpb d
      : \sigma / \tau}\\
    \inference[BB-Def]{\Phi;\Psi;\Gamma[x_1 \mapsto \tau_1 \dotsb x_n
      \mapsto \tau_n] |- s :
  \tau}{\Phi;\Psi;\Gamma \tpb \lambda(x_1, x_2, \dotsc,
      x_n).s : (\ntypes -> \bullet) / \tau}
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{\Phi ; \Psi ; \Gamma |- s : \tau}\\\\
    \inference[Tp-ret]{\Gamma \tpc c : \tau}{\Phi ; \Psi ;
      \Gamma |- \iret{c} : \tau} \quad
    \inference[Tp-let]{\Gamma \tpop op : \tau_1 \quad \Phi ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- s : \tau}{\Phi ; \Psi ; \Gamma |-
      \ilet{x}{op}{s} : \tau}\\\\
    \inference[Tp-do]{\Phi;\cdot;\cdot |- s_1 : \tau_1 \quad
      \Phi;\Psi;\Gamma[x \mapsto \tau_1] |- s_2 : \tau} {\Phi;\Psi;\Gamma |-
      \ido{x}{s_1}{s_2} : \tau}\\\\
    \inference[Tp-br]{\Psi(l) = \bbtypes{} \quad \sigma_k :
      \ntypes -> \bullet\\
      \Gamma |- c_1 : \tau_1 \quad \Gamma |- c_2 : \tau_2 \quad \dotsb
      \quad \Gamma |- c_n : \tau_n}
    {\Phi;\Psi;\Gamma |- \ibr{l^k}(c_1, c_2, \dotsc, c_n) : \tau}\\\\
    \inference[Tp-brc]{\Gamma \tpc x : \tbool\\
      \Psi(l) = \bbtypes{}\\
      \sigma_k : \ntypes -> \bullet\\
      \Gamma |- c_1 : \tau_1 \quad \dotsb \quad \Gamma |- c_n :
      \tau_n\\
      \sigma_{k'} : \ntypesp -> \bullet\\
      \Gamma |- c'_1 : \tau'_1 \quad \dotsb \quad \Gamma |- c'_n :
      \tau'_n}
    {\Phi;\Psi;\Gamma |- \ibrc{x}{l^k}{(c_1, \dotsc,
        c_n)}{l^{k'}}{(c'_1, \dotsc, c'_{n'})} : \tau}\\\\
    \inference[Tp-letrec]{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb
      d_1 : \sigma_1 / \tau\\
      \dotsb\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m / \tau\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- s : \tau}
       {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{s} : \tau}\\\\
    \inference[Tp-call]{\Phi(f) = \ntypes -> \tau'\\
      \Gamma |- c_1 : \tau_1 \quad \dotsb \quad \Gamma |- c_n : \tau_n\\
  \Phi;\Psi;\Gamma[x \mapsto \tau'] |- s : \tau}
  {\Phi;\Psi;\Gamma |- \icall{x}{f}{(c_1, \dotsc, c_n)}{s} : \tau}
  \end{gather*}
  \caption{Typing 2}
  \label{fig:type-judgement-2}
\end{figure}

In figure \ref{fig:type-judgement-2} we present the typing relations
for instructions. The general judgment for these is
$\boxed{\Phi;\Psi;\Gamma |- s : \tau}$. This specifies that the
instruction $s$ has a type of $\tau$ in the environment of
$\Phi;\Psi;\Gamma$. % Do not explain it. It should be clear!

An instruction of the form $\iret{c}$ has type $\tau$ if the constant
it returns has. Correct typing of an $\ilet{x}{op}{s}$ instruction
requires that the operation $op$ returns the same type as is used for
the register $x$ in the body $s$.

The rule Tp-do defines a typing of a $\ido{x}{s_1}{s_2}$
instruction. The type of $s_1$ must the the same type as used in
$s_2$. Note the similarity between this instruction and the
let-binding above.

Unconditional branches are handled by the Tp-br rule. It states that a
well-typed branch can look up the basic block in the environment of
basic blocks and then take the $k$th projection of this to obtain the
type $\ntypes -> \bullet$. \fixme{Check we actually write something
  about the $\bullet$ and explain the details of it}

Conditional branches are well-typed if each path regarded as
unconditional branches are. Furthermore we require the branch variable
to be a boolean value.

The Tp-letrec rule introduces basic blocks. It first checks that each
basic block definition is well-typed. Then it type checks the body $s$
under an augmented environment where a mapping to the basic block
identifier has been made.

Finally, function calls are well-typed if we can look up the function
identifier in the function environment $\Phi$; and can show the
passed arguments obeys the type scheme.

\section{Programs}
\newcommand{\dom}[1]{\mathrm{dom}(#1)}
\begin{figure}
  \begin{gather*}
    \text{Definition Wellformedness:} \quad \boxed{\Phi |- D : \Phi'}\\\\
    \inference[Wf-defs/z]{}{\Phi |- \cdot : \cdot}\\\\
    \inference[Wf-defs/s]{\Phi |- D' : \Phi'' \quad \Phi;\cdot;[x_1 \mapsto
      \tau_1 \; \dotsb \; x_n \mapsto \tau_n] |- s :
      \tau \quad f \not \in \dom{\Phi'}}{\Phi |- (f(x_1, \dotsc, x_n) = s, D') : (f \mapsto \ntypes -> \tau, \Phi'')}
  \end{gather*}
  \begin{gather*}
    \text{Program Wellformedness:} \quad \quad \boxed{|- P}\\\\
    \inference[WF-Pgm]{\Phi |- D : \Phi \quad \Phi;\cdot;\cdot |- s}{|- \ipgm{D}{s}}
  \end{gather*}
  \caption{Typing 3}
  \label{fig:type-judgement-3}
\end{figure}

A program is well-formed (figure \ref{fig:type-judgement-3}) if it
obeys a wellformedness criterion $\boxed{\Phi |- D : \Phi}$ on its
definitions $\Phi$ and that the body is wellformed in empty Basic
block and variable environments. We write $\boxed{|- P}$ for
well-formed programs.

The criterion for definition blocks examines wellformedness of the
list of definitions. If the definition list is empty, then the
function environment has to be as well. Each function must be
wellformed with respect to its formal parameters and the full
environment $\Phi$. We furthermore require that the function identifier
does not occur twice with the premise $f \not \in \dom{\Phi'}$.

Note that the premise $\Phi |- D : \Phi$ ties the knot on function
definitions. The function environment $\Phi$ is being examined while it
is being built at the same time.

% The judgement $\boxed{\Phi;\Psi;\Gamma |- L : \Psi'}$ is used to state
% that a basic block relates to its context. We will use this in the
% proof of \emph{preservation}, to maintain the relationship. The idea
% is that if a basic-block environment is well-formed, all the
% definitions must be.


\chapter{Mini-LLVM Semantics}

In this chapter we present the Mini-LLVM semantics (see figure
\ref{fig:semantics}). We chose to implement the semantics as a
small-step operational semantics. A small-step operational semantics
is fairly easy to reason about when proving the meta-theoretic
properties of \emph{preservation} and \emph{progress}. Furthermore, it
follows the style used in \cite{pierce:2002:types}.

\paragraph{Step relation for operations}

\newcommand{\eop}{=>_{o}} For operations, $\boxed{|- op \eop n}$ is
the judgement form. The form state that the operation $op$ evaluate to a
value of $n$. This might look like a big-step semantics, but note that
all operations are \emph{primitive} in Mini-LLVM: An operation is
limited by the syntax such that it cannot be an arbitrary tree
tree. This is also the reason we chose the operation as a name rather
than the more common \emph{expressions}.

For each possible operator, there is a corresponding inference
rule. Each of these simply unwrap underlying integers and then applies
the proper mathematical arithmetic operation.
\newcommand{\meval}{:=}
\begin{figure}
  \begin{align*}
    \text{Definitions:} \ni D & ::= \cdot \bor (f(x_1, x_2, \dotsc,
    x_l) = s, D)\\
    \text{Basic Blocks:} \ni L & ::= \cdot \bor (l \mapsto \dbundle),L
  \end{align*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{|- op \eop n}\\
    \inference[E-Plus]{}{|- n_1 + n_2 \eop n}(n \meval n_1 + n_2)
    \quad \quad
    \inference[E-Mone]{}{|- n_1 - n_2 \eop n}(n \meval n_1 - n_2)\\\\
    \inference[E-Lt-T]{}{|- n_1  < n_2 \eop \btrue}(n_1 < n_2) \quad \quad
    \inference[E-Lt-F]{}{|- n_1  < n_2 \eop \bfalse}(n_1 >= n_2)
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{D;L |- s -> s'}\\
    \inference[S-let]{|- o \eop c}{D;L |- \ilet{x}{o}{s} -> s[c/x]}\\\\
    \inference[S-letrec-v]{}{D;L |- \iletrec{l}{\dbundle}
      {\iret{c}} -> \iret{c}}\\\\
    \inference[S-letrec-s]{D;L[l \mapsto \dbundle] |- s -> s'}
    {D;L |- \iletrec{l}{\dbundle}{s} -> \iletrec{l}{\dbundle}{s'}}\\\\
    \inference[S-brc-t]{}{D;L |-
      \ibrc{\btrue}{l^k}{(c_1, \dotsc, c_n)}{l^{k'}}{(c_1, \dotsc, c_n)'} -> \ibr{l^k}{(c_1, \dotsc, c_n)}}\\\\
    \inference[S-brc-f]{}{D;L |-
      \ibrc{\bfalse}{l^k}{(c_1, \dotsc, c_n)}{l^{k'}}{(c_1, \dotsc, c_n)'} ->
      \ibr{l^{k'}}{(c_1, \dotsc, c_n)'}}\\\\
    \inference[S-do-s]{D;L |- s_1 -> s'_1}{D;L |-
      \ido{x}{s_1}{s_2} -> \ido{x}{s'_1}{s_2}}\\\\
    \inference[S-do-v]{}{D;L |- \ido{x}{\iret{c}}{s_2} -> s_2[c/x]}\\\\
    \inference[S-call]{D(f) = (\;f(x_1, x_2, \dotsc, x_n) = s'\;)}{D;L |-
      \icall{s}{f}{(c_1, c_2, \dotsc, c_n)}{s} -> \ido{x}{s'[c_1/x_1, c_2/x_2,
        \dotsc, c_n/x_n]}{s}}\\\\
    \inference[S-br]{L(l) = \dbundle \quad d_k = \lambda(x_1, \dotsc,
      x_n).s}{D;L |- \ibr{l^k}{(c_1, \dotsc, c_n)} -> s[c_1/x_1, \dotsc, c_n/x_n]}
 \end{gather*}
 \begin{gather*}
   \text{Programs:} \quad \boxed{|- P --> P'}\\
   \inference[SP]{D;\cdot |- s -> s'}{\ipgm{D}{s} --> \ipgm{D}{s'}}
 \end{gather*}
  \caption{Semantics}
  \label{fig:semantics}
\end{figure}

\paragraph{Step relation for instructions}

Instructions is by far the most complex in this system. To describe
these, we need to describe two new classes: definitions and basic
blocks. Definitions, notated as $D$, is a list of function
definitions. Basic blocks, notated as $L$, is a mapping from a basic
block name to a tuple of basic blocks. Instructions have the
judgment form $\boxed{D;L |- s -> s'}$, where definitions and basic
blocks are contextual.

In the semantics, we use the notation $s[c/x]$. This means that you
substitute all occurrences of $x$ with $c$ in the syntax tree of
$s$.

The basic sequential operation in LLVM is handled by the
$\ilet{x}{op}{s}$ instruction in Mini-LLVM. As already noted in
\ref{llvm-consideration-let}, we translate sequences of instructions
into nested applications of $\mathbf{let}$s. To execute an operation,
$op$, is to know the contents of the register $x$. Since we have the
SSA-property and the SSA/FP correspondence, we can then just propagate
the value of $x$ to all its uses directly. This is done by
substituting the result for $x$ in the body of the let, $s$.

Evaluation of an instruction $\iletrec{l}{\dbundle}{s}$ progresses
depending on the structure of $s$. If $s$ is of the form $\iret{c}$,
then there is no reference to the basic blocks, and we can get rid of
them. This is done with the S-letrec-v rule. Otherwise, the S-letrec-s
rule introduces all the basic blocks into the context at once;
followed by a step underneath.  In effect, the body of a
$\mathbf{letrec}$ can act as the scratch-pad for the execution of
basic blocks and be replaced with a new basic block from the context.

Conditional branches examine the boolean value and then step into an
unconditional branch of the right kind. Unconditional branches, the
S-br rule first looks up the appropriate basic block in the
environment; then it applies the $k$th projection to get at the
correct basic block. Finally, it resolves the contents of the
$\phi$-nodes by substitution --- again exploiting the SSA/FP
correspondence.

The $\ido{x}{s_1}{s_2}$ instruction is equivalent to a normal
let-construction in a (monadic) lambda-calculus. It reduces $s_1$ via the
rule S-do-s until it becomes a canonical value (i.e., a $\iret{c}$);
then applies the rule S-do-v to push down the value of $x$ into the
body $s_2$.

Finally, function calls are handled by the S-call inference rule. We
look up the definition of the function call in the function
context. Then we step into a $\mathbf{do}$ instruction. Thus, we will
use the $\mathbf{do}$ as a scratchpad for the function evaluation.

\paragraph{Step relation for programs}

A Program steps by the form $\boxed{|- P --> P'}$. It simply
introduces the definitions in the context so they are callable from
the body.

\chapter{Twelf encoding}

We now seek to encode the syntax and semantics in Twelf. When
encoding, we must make certain choices along the way. Almost any
operational semantics will omit specific parts --- in the name of
notational simplicity. The encoding needs to take care of this
explicitly, however.

\paragraph{Extrinsic vs. Intrinsic encoding}

When we specify a syntax as an abstract syntax tree in a language like
ML, we usually do so by virtue of an algebraic data type. This syntax
description allows us to write down some \emph{illegal} programs:
certain syntax trees will get stuck under evaluation. A typing
relation then constrains the syntax trees such that only well-typed
programs are allowed. When the typing relation stands next to the
syntax description, we say that the encoding is \emph{extrinsic}.

In contrast, if the programming language has access to Generalized
algebraic data-types (GADTs) or dependent types, we might define the
syntax in way that rejects ill-typed programs directly. This encoding
form, called \emph{intrinsic} encoding, is possible in \twelf{},
\coq{}, \agda{}, and to a certain extent \haskell{}.

Intrinsic encodings have their limitations however. The typing
relation must be static in the sense that it must be driven by the
syntactical rules alone. An extrinsic encoding on the contrary can use
any (Turing Machine-) computable function. This might make the
intrinsic encoding impossible for some typing relations.

In our work, we sought to achieve an intrinsic encoding of as much of
the semantics as possible. This we aimed for an intrinsic encoding of
instructions, but adopted an extrinsic encoding for function
definitions and programs.

\section{The Prelude}

The prelude contains various helper-relations for use in the real
formalization. In other proof systems (e.g., \coq{}\cite{team:coq*1}),
these are already present in a standard library, but for \twelf{} we
are forced to code them by hand.

We encode the boolean values and Peano style natural numbers along with
operations on these. As examples, we encode arithmetic operations and
predicates for equality and non-equality.

\paragraph{properties}

Since we want to use properties of the prelude in meta-theory, we must
prove that the properties are true. In the following, we present some
example properties from the prelude:
\begin{lem}
  Suppose we have two natural numbers $n_1, n_2 \in \NN$. Then there
  exists an $n_3 \in \NN$ such that $n_1 + n_2 = n_3$.
\end{lem}
\begin{proof}
  Induction on $n_1$: If $n_1$ is $0$ then take $n_3 =
  n_2$. Otherwise, $n_1 = n'_1 + 1$. We now apply the induction
  hypothesis to obtain an $n'_3$ with $n'_1 + n_2 = n'_3$. To this, we
  can use the rule $n'_1 + 1 + n_2 = n'_3 + 1$ which is valid given
  our definition of plus. This gives the existence of an $n_3 = n'_3 +
  1$.
\end{proof}

Lemmas of this form is very common in \twelf{} signatures. They are
called \emph{effectiveness} lemmas and are usually named with a
\texttt{can-} prefix as in \texttt{can-nat-plus} and
\texttt{can-step-op}. They build a bridge between a pure syntactical
object and an accompanying relation on the object.

Another very common \twelf{} proof is reasoning from false. We have a
special type family defined, \texttt{void}, with no constructors
whatsoever. This can be used to prove absurd statements. For example
\begin{lem}
  Let $n_1$ and $n_2$ be natural numbers. Then $n_1 = n_2 \land n_1
  \neq n_2 \implies \bottom$.
\end{lem}

We can reason anything from \texttt{void} because void has no valid
constructors. Thus the sentence $\forall v \in \texttt{void} \; . \; \exists
E$ for any $E$ is vacuously true since there is no way the $v$ can be
inhabited.

\section{Syntax encoding}

\fixme{Read through this. It is not O.K. yet.}
We would like to use an intrinsic encoding for as much of the syntax
as possible. We would also like to use a for \twelf{} classic method
w.r.t. encoding variables, named \emph{higher order abstract syntax}
(HOAS). With HOAS, we use an LF-binding to represent a variable in the
object language we are encoding. We can use this method to represent
the registers of the language in the constants. In effect, execution
of the semantics will mean that when a register is \emph{defined} we
immediately ``push'' its value to all of its \emph{uses} by
substitution. Since our system is also intrinsic, we let a be a family
of types:
\begin{verbatim}
cst : tp -> type.
\end{verbatim}
In the same vein, we can define operations and instructions to be
bearing their types. For an instruction, its type is the type of a
return value.

This methodology is used to merge part of the typing relation into the
language syntax, directly handling the type in the syntax.

\paragraph{Handling basic blocks}

A complication with an intrinsic typing is how to type basic blocks. A
basic block is essentially a list of definitions $d_1, d_2, \dotsc,
d_n$, with each definition of the form $\lambda (x_1, \dotsc,
x_n).i$. The latter can be represented by a standard \twelf{}-HOAS-trick:
If $i$ is the syntax tree of the function body, we represent the
$\phi$-variable by wrapping the syntax tree in an LF-lambda: $\lambda
(x : \texttt{reg t}) . i$, where $x$ might be bound in $i$. Thus,
substitution is LF-application. By successively wrapping once for each
$x_i$ variable, we obtain a definition $d$. Since the typing is
intrinsic, we let each wrapping book-keep the typing.

The definition list also intrinsically encodes the typing. It is a
typical functional style list with a \texttt{nil} and a \texttt{cons}
element, but with a type-designation on each element.

This construction encodes types for a list of definitions $d_1, d_2,
\dotsc, d_n$ -- but we wish to handle such definitions by \twelf{}
regular worlds. Hence, we have an type family
\begin{verbatim}
bname : bb-tp -> type.
\end{verbatim}
where \texttt{bb-tp} is the type of definition lists. We use that to
introduce a new $bname$ into the context when stepping under a
$\mathbf{letrec}$ instruction:
\begin{verbatim}
step/letrec-s :
    step D (insn/letrec ([pb] Defs pb) ([pb] Body pb))
           (insn/letrec ([pb] Defs pb) ([pb] Body' pb))
     <- ({pb} bb-bind pb (Defs pb) ->
               step D (Body pb) (Body' pb)).
\end{verbatim}
Here, the \texttt{pb} variable is a hypothetical new variable which we
bind to the definitions with the \texttt{bb-bind} relation. Since
definitions are allowed to call each other, we pass in the \texttt{pb}
variable to the definitions. Note that the type of \texttt{pb} will be
the same as the type of \texttt{(Defs pb)}.

The above construction let us define a basic block bundle, but it does
not tell the whole story: how to project and call. In a branch
instruction $\ibr{l^k}{(c_1, \dotsc, c_n)}$, we need to encode the
call $l^k$. We define this by the means of the constants
\texttt{f-hd, f-tl/s} and \texttt{f-tl/z}. If $l$ is a
\texttt{bname}, we define $l^k$ as:
\newcommand{\fhd}{\mathtt{f\!\!-\!\!hd}}
\newcommand{\ftls}{\mathtt{f\!\!-\!\!tl/s}\; }
\newcommand{\ftlz}[1]{(\mathtt{f\!\!-\!\!tl/z} \; #1)}
\begin{equation*}
  \fhd \underbrace{(\ftls(\ftls ( \; \dotsb \; }_{k \; \text{terms}}\ftlz{l})))
\end{equation*}
The encoding allows us to maintain the intrinsic typing when transferring
control to another basic block. Each occurrence of an $\ftls$ will
have us taking the tail of the definition pointed to by $l$ -- giving
us the $k$th projection at the front of the list when finished. See
the \texttt{branch-lookup} relation in the \twelf{} source.

We tried several different ways of encoding basic blocks
intrinsically. Initially, we encoded a hypothetical name for
each basic block definition $d_i$. It turns out, however, that this
doesn't account for multiple definitions of the same basic block
name which would lead to loss of determinism among other
things. In general each basic block should occur once with a unique
name -- and the hypothetical name must obey the typing of the
definition. We used some time analyzing if it was possible to
intrinsically code the first-order $\mathbf{letrec}$-variant of
Mini-LLVM and the above encoding answers the question in the
affirmative.

\paragraph{Handling function calls}

For function calls, we deviate from the intrinsic encoding and encode
it extrinsically as is more traditional. A function identifier is
simply a natural number. But to build the bridge between the intrinsic
and extrinsic parts it was beneficial to augment the function
identifier with the presumed type from the intrinsic encoding:
\begin{verbatim}
fun-id : tp -> tp-list -> type.
fun-id/ : nat -> fun-id T TL.
\end{verbatim}
Consequently, the intrinsic type system will not be able to type check
the correctness of function calls.

\section{Semantics encoding}

The semantics are encoded rather straightforwardly from figure
\ref{fig:semantics}. The only deviance is the use of the \twelf{}
context to handle the semantic environments.

The somewhat informal invocation of basic blocks and function calls
need mention though. In the semantics, we write $s[c_1/x_1, \dotsc,
c_n/x_n]$ for substituting $c_i$ for $x_i$ ($1 \leq i \leq n$). In the
\twelf{} formalization this is realized by the following construction:
We have a list $[c_1 : \tau_1, \dotsc, c_n : \tau_n]$ of constant
parameters and a basic-block / function-body which HOAS-represents the
$\phi$-nodes: $\lambda x_1 : \tau_1 \;.\; (\lambda x_2 : \tau_2 \;.\;
\dotsc, (\lambda x_n : \tau_n \;.\; i)\dotsb{})$. We can then
successively apply a constant $c_i : \tau_i$ to the $i$th lambda-term
and then $\beta$-reduction solves the rest of the substitution. The
fact that $\beta$-reduction acts as our substitution principle is
central to \twelf{}-representations.

\section{Typing encoding}

The intrinsic parts of the type system is already encoded into the
syntax. The extrinsic parts are encoded in a set of relations which are
directly transcribed from the operational semantics given in chapter
\ref{chap:type-system}.

The notation $f \not \in D$ is implemented by a simple scan over the
list of definitions:
\begin{gather*}
  \text{Function Absence:} \quad \boxed{f \not \in D}\\
  \inference[f-notin/z]{}{f \not \in \cdot}\\\\
  \inference[f-notin/s]{f \neq f' \quad f \not \in D'}{f \not \in (f' = t, D')}
\end{gather*}
\section{Transformation of LLVM Programs to Mini-LLVM}

One rather important milestone in our work is to make sure a correct
LLVM IL program using a supported subset can be transformed into an
equivalent Mini-LLVM program. Our running first example will be the
calculation of triangular numbers:
\begin{equation}
  \label{eq:1}
  n? = 1 + 2 + \dotsb + n = \sum_{0 < i \leq n} i
\end{equation}

The notation $n?$ is due to Knuth\cite[section
1.2.5]{knuth:1997:taocp1}. We choose this example over the factorial
function since it is readily computable without the need for a
multiplication. Straightforward recursive implementation of
this in C yields:
\begin{verbatim}
int
tri (int n) {
    if (n == 0) { return 0; }
    else return (tri(n-1) + n);
}
\end{verbatim}
We can then use the \clang{} compiler from C to LLVM IL to generate
LLVM code for this C fragment. The \clang{} compiler circumvents the
need to produce SSA IL code by using the stack as a scratch-pad for
all register operations. Any operation will be a load from the memory
location of the stack and then a store back of the result. Thus the
raw output from the compiler cannot be used as our Mini-LLVM language
has no concept of a stack.

LLVM contains an optimization pass however, \texttt{mem2reg}, which
can transform stack references into register access. This effectively
eliminates the explicit allocation on the stack.

If we skip for us irrelevant parts about the LLVM data layout, we have
the following function body:
\begin{verbatim}
define i32 @tri(i32 %n) nounwind {
entry:
  %cmp = icmp eq i32 %n, 0
  br i1 %cmp, label %if.then, label %if.else

if.then:
  br label %return

if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return

return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0
}
\end{verbatim}
By hand-translation of this into Twelf, we obtain the following
twelf-function for the same fragment:
\begin{verbatim}
pgm_1 = pgm/ (defs/s gauss
  (fun-decl/parm ([n]
    fun-decl/body
      (insn/letrec ([pb]
        (bb-def-list/cons
          (bb-def/body (insn/let (op/cmp-lt n (cst/n 1))
    		     ([r : cst tp/bool]
                     (insn/brc r (b1 pb) cst-list/nil
                                 (b2 pb) cst-list/nil))))
        (bb-def-list/cons
          (bb-def/body (insn/br (b3 pb)
                                (cst-list/cons (cst/n 0)
                                       cst-list/nil)))
        (bb-def-list/cons
          (bb-def/body
    	    (insn/let (op/mone n (cst/n 1))
    	       ([sub : cst tp/nat]
                   (insn/call gauss (cst-list/cons sub
                                            cst-list/nil)
                        ([call : cst tp/nat]
                              insn/let (op/plus call n)
                                ([plus] insn/br (b3 pb)
                                           (cst-list/cons plus
                                             cst-list/nil)))))))
        (bb-def-list/cons
           (bb-def/phi [retval]
    	     (bb-def/body (insn/return retval)))
         bb-def-list/nil)))))
    ([pb] insn/br (b0 pb) cst-list/nil))))
     defs/z)
  (insn/call gauss (cst-list/cons (cst/n 3) cst-list/nil)
     ([r] insn/return r)).
\end{verbatim}

Note in the translated code how we translate the $\phi$-nodes. In the
LLVM IL, we have each basic block starting with the $\phi$-nodes and a
notation for each predecessor block stating which value should be
passed. In our translation, we have each branch passing the values on
as parameters.

\paragraph{Automatic translation}

A full treatment of translation ought to be automatic rather than
hand-written. It certainly looks possible automate the above
translations. If one parses LLVM IL into an abstract syntax tree,
output should be pretty straightforward --- save for the inversion of
$\phi$-nodes.

The inversion can be handled by a two-pass algorithm. In the first
pass we gather $\phi$-nodes for each basic block as well as what value
each branch into the basic block passed. In the second pass, we
replace all branch invocations with tail-calls such that the right
values are passed.

To establish the plausibility of a full isomorphism, an inverse parser
must also be created. This inverse parser should take a
\twelf{}-signature with a test definition and transform it into
equivalent full LLVM code. It has to invert the passing of
$\phi$-nodes as well. This can be done by a similar two-pass scan.

\chapter{Meta-theory}

In this chapter, we describe the meta-theoretic properties of
Mini-LLVM.

\section{Lemmas}

To prove the usual meta-theoretic theorems we need some auxiliary
lemmas. In the following, we present the lemmas we need

\begin{lem}{[Weakening, $\Psi$]}
  \label{lem:weaken-psi}
  Instruction typing admits Basic Block weakening: if $\Phi;\Psi;\Gamma
  |- s : \tau$ and $l' \mapsto \sbundle$, then $\Phi;\Psi[l' \mapsto
  \sbundle];\Gamma |- s : \tau$.
\end{lem}
\begin{proof}
  By mutual induction on the relation $\Phi;\Psi;\Gamma |- s : \tau$
  and on $\Phi;\Psi;\Gamma \tpb d : \sigma / \tau$.

  The case Tp-ret is immediate. The cases of BB-def, Tp-let, Tp-do,
  Tp-letrec and Tp-call are all appeal to the IH.

  For the cases of Tp-br and Tp-brc, we note that since
  $\Phi;\Psi;\Gamma |- s : \tau$, then $\Psi(l) =
  \sbundle$. Therefore, also $\Psi[l' \mapsto (\sigma_{11}, \dotsc,
  \sigma_{1m})](l) = \sbundle$.
\end{proof}

In the following proofs, we assume that the variable $x'$ is a new
``fresh'' variable.
\begin{lem}{[Weakening, $\Gamma$, registers]}
  \label{lem:weaken-registers}
  If $\Gamma \tpr x : \tau$ then it implies $\Gamma[x' \mapsto \tau']
  \tpr x : \tau$
\end{lem}
\begin{proof}
  Since $\Gamma \tpr x : \tau$, we must have $\Gamma(x) = \tau$. And
  then $\Gamma[x' \mapsto \tau'](x) = \tau$ for $x' \neq x$, which we
  can assume is the case.
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, constants]}
  \label{lem:weaken-constants}
  Constants admits weakening of the variable context: $\Gamma \tpc c :
  \tau$ implies $\Gamma[x' \mapsto \tau'] \tpc c : \tau$.
\end{lem}
\begin{proof}
  Immediate consequence or by use of lemma \ref{lem:weaken-registers}.
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, operations]}
  \label{lem:weaken-operations}
  Suppose $\Gamma \tpc op : \tau$. Then we have $\Gamma[x' \mapsto
  \tau'] \tpc op : \tau$.
\end{lem}
\begin{proof}
  All cases are either congruences or can be discharged by use of
  lemma \ref{lem:weaken-constants}
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, instructions]}
  \label{lem:weaken-gamma}
  Instruction typing admits weakening in the variable context: Suppose
  we have $\Phi;\Psi;\Gamma |- s : \tau$ for contexts $\Phi, \Psi$ and
  $\Gamma$. Then $\Phi;\Psi;\Gamma[x' \mapsto \tau'] |- s : \tau$.
\end{lem}
\begin{proof}
  We run mutual induction on $\Phi;\Psi;\Gamma |- s : \tau$ and the
  relation $\tpb$.

  The case Tp-ret uses lemma \ref{lem:weaken-constants}. Tp-let is
  done by the IH and lemma \ref{lem:weaken-operations}. Tp-do is a
  single appeal to the IH, as $\Phi;\cdot;\cdot |- s_1 : \tau_1$ is
  already the case. Tp-br and Tp-brc uses \ref{lem:weaken-constants}
  which is also the case for Tp-call -- with an added appeal to the
  IH. Finally, we Tp-letrec and BB-def cases uses the IH.
\end{proof}

\begin{lem}{[Substitution]}
  \label{lem:substitution}
  Suppose we are given a constant $c$ with $\Gamma \tpc c :
  \tau$. Further, let a register $x : \tau$ be given. Then, for all
  instructions $\Phi;\Psi;\Gamma[x \mapsto \tau] |- s : \tau'$ we have
  $\Phi;\Psi;\Gamma |- s[c/x] : \tau'$.
\end{lem}
\begin{proof}
  Induction on the structure of $s$. Note that the register $x$ must
  be free in $s[c/x]$.
\end{proof}

\section{Progress}

\fixme{Progress}

\begin{lem}{[Progress, instructions]}
  \label{lem:progress-instructions}
  For all instructions $s$ with $\Phi;\Psi;\Gamma |- s : \tau$ and
  $\Phi |- D : \Phi$, $s$ is either of the form $\iret{c}$ or $D;L |-
  s -> s'$.\fixme{There is a relation in Twelf we need to add here}
\end{lem}
\begin{proof}
  ... \fixme{Do the progress proof}
\end{proof}

\begin{thm}{[Progress]}
  For any program $P$ with $|- P$ either $P$ is a value (i.e., of the
  form $\ipgm{D}{\iret{c}}$) or $|- P --> P'$.
\end{thm}
\begin{proof}
  By lemma \ref{lem:progress-instructions}.
\end{proof}

\section{Preservation}

To prove preservation, we need a couple of lemmas, and a helping
judgement rule.

\newcommand{\tpbb}{|-_{\mathrm{L}}}
Like we use the judgment relation $\Phi |- D : \Phi'$ to relate
function definitions to function typing, we need a similar relation
$\boxed{\Phi;\Psi;\Gamma \tpbb L : \Psi'}$ linking basic blocks to their
typing relations. The helper judgement has two rules:
\begin{gather*}
  \text{Basic Block wellformedness:} \quad \boxed{\Phi;\Psi;\Gamma \tpbb
    L : \Psi'}\\\\
  \inference[Wf-bb/z]{}{\Phi;\Psi;\Gamma \tpbb \cdot : \cdot}\\\\
  \inference[Wf-bb/s]{\Phi;\Psi;\Gamma \tpb d_1 :
  \sigma_1 / \tau\\
  \dotsb\\
  \Phi;\Psi;\Gamma \tpb d_m : \sigma_m / \tau\\
  \Phi;\Psi;\Gamma \tpbb L' : \Psi'}
  {\Phi;\Psi;\Gamma \tpbb (l \mapsto \dbundle, L') : (l \mapsto
    \sbundle, \Psi')}
\end{gather*}
We now present the lemmas needed for preservation, and then present
the theorem:

\begin{lem}{[Weakening, Basic block wellformedness]}
  \label{lem:weaken-wf-bb}
  We can weaken the basic block environment $\Psi$ for Basic block
  wellformedness. Formally, if $\Phi;\Psi;\Gamma \tpbb L : \Psi'$
  then we can weaken $\Psi$ to $\Psi[l \mapsto \sbundle]$ and then
  \begin{equation*}
    \Phi;\Psi[l\mapsto \sbundle];\Gamma \tpbb L : \Psi'
  \end{equation*}
\end{lem}
\begin{proof}
  By induction on the structure of $\tpbb$: If we have the Wf-bb/z
  rule, then there is nothing to show. If we have the Wf-bb/s rule, we
  can weaken the premise $\Phi;\Psi;\Gamma \tpbb L' : \Psi'$ by the
  induction hypothesis. And the premises of the form $\Phi;\Psi;\Gamma
  \tpb d_j : \sigma_j / \tau$ can be weakened because of lemma
  \ref{lem:weaken-psi}.
\end{proof}

\begin{lem}{[Preservation, constants]}
  \label{lem:preservation-c}
  Suppose $\Gamma \tpop op : \tau$ and $op \eop c$ then $\Gamma \tpc
  c : \tau$.
\end{lem}
\begin{proof}
  Induction on $op \eop c$.
\end{proof}

\begin{lem}{[Preservation, function lookup]}
  \label{lem:preservation-lookup}
  Suppose $D(f) = f(x_1, \dotsc, x_n) = s$ and $\Phi |- D :
  \Phi'$. Then $\Phi;\cdot;[x_1 \mapsto \tau_1 \dotsb x_n \mapsto
  \tau_n] |- s : \tau$ where $\Phi'(f) = \tau_1 \times \dotsb \times
  \tau_n -> \tau$.
\end{lem}
\begin{proof}
  Induction on the structure of $D$: Either we have $D = (f(x_1,
  \dotsc, x_n) = s, D')$ so the function we seek is the first
  ``element'' in $D$. Then, by the structure of $\Phi |- D : \Phi'$,
  we must have a Wf-defs/s rule. From that rule, we have exactly what
  we seek as premises.

  If on the other hand, we have $D = (f'(x_{1'}, \dotsc, x_{n'}) = s',
  D')$, then we have, again by the Wf-defs/s rule, that $\Phi : D' :
  \Phi''$, so we can apply the induction hypothesis on $D'$ and $\Phi
  |- D' : \Phi''$ to get the desired result.
\end{proof}

\begin{lem}{Preservation, instructions:}
  \label{lem:preservation-i}
  Suppose $\Phi |- D : \Phi \;$, $\Phi;\Psi;\Gamma \tpbb L : \Psi'$ and
  $\; \Phi;\Psi;\Gamma |- s : \tau$. Then $D;L |- s -> s'$ implies
  $\Phi;\Psi;\Gamma |- s' : \tau$.
\end{lem}
\begin{proof}
  Induction on $\Phi;\Psi;\Gamma |- s -> s'$:
  \begin{itemize}
  \item (S-let): If the step is of the form:
    \begin{equation*}
      \inference{|- op \eop c}{D;L |- \ilet{x}{op}{s} -> s[c/x]}
    \end{equation*}
    Then the typing relation must be:
    \begin{equation*}
    \inference{\Gamma \tpop op : \tau_1 \quad \Phi ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- s : \tau}{\Phi ; \Psi ; \Gamma |-
      \ilet{x}{op}{s} : \tau}
    \end{equation*}
    We have $\Gamma \tpop op : \tau_1$ and $|- op \eop c$ so by lemma
    \ref{lem:preservation-c}, we have $\Gamma \tpc c : \tau_1$. By the
    substitution lemma \ref{lem:substitution}, $\Phi;\Psi;\Gamma |-
    s[c/x] : \tau$ as wanted.
  \item (S-letrec-v):
    The step is
    \begin{equation*}
      \inference{}{D;L |- \iletrec{l}{\dbundle}
        {\iret{c}} -> \iret{c}}
    \end{equation*}
    with the typing rule:
    \begin{equation*}
    \inference{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_1 :
      \sigma_1 / \tau\\
      \dotsb\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m / \tau\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- \iret{c} : \tau}
       {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{\iret{c}} : \tau}
    \end{equation*}
    Note that $\iret{c}$ has no reference to the basic block
    identifier $l$. So it must hold that $\Phi;\Psi';\Gamma |-
    \iret{c} : \tau$ for all $\Psi'$. In particular $\Phi;\Psi;\Gamma
    |- \iret{c} : \tau$.
  \item (S-letrec-s):
    The step is
      \begin{equation*}
        \inference{D;L[l \mapsto \dbundle] |- s -> s'}
        {D;L |- \iletrec{l}{\dbundle}{s} -> \iletrec{l}{\dbundle}{s'}}
      \end{equation*}
    with the typing rule:
        \begin{equation}
          \label{eq:preserv-tp-letrec-s}
          \inference{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_1 :
            \sigma_1 / \tau\\
            \dotsb\\
            \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m
            / \tau\\
            \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- s : \tau}
          {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{s} : \tau}\\\\
    \end{equation}
    We will like to call the induction hypothesis on the premise
    $D;L[l -> \dbundle] |- s -> s'$. This in turn will give us the
    conclusion of $\Phi;\Psi[l -> \sbundle];\Gamma |- s' : \tau$
    which we need for the Tp-letrec rule.

    But here we alter the environment of basic blocks, so our
    judgement $\Phi;\Psi;\Gamma \tpbb L : \Psi$ will have to be
    updated. First, we use lemma \ref{lem:weaken-wf-bb} to weaken
    the judgement to $\Psi;\Psi[l \mapsto \sbundle] \tpbb L :
    \Psi$. Then we construct an instance of the Wf-bb/s rule, where all the
    needed premises are present in the typing relation
    \eqref{eq:preserv-tp-letrec-s} and the weakened $\tpbb$
    judgement. This yields $\Phi;\Psi[l \mapsto \sbundle];\Gamma
    \tpbb L[l \mapsto \dbundle] : \Psi[l \mapsto \sbundle]$ and we
    can thus apply the IH to solve the case.
  \item (S-brc-t), (S-brc-f):
    In the conditional branch cases, we simply construct
    $\Phi;\Psi;\Gamma |- \ibr{l^k}{(c_1, \dotsc, c_n)}$ from the
    premises.
  \item (S-do-v):
    Use the substitution lemma \ref{lem:substitution}.
  \item (S-do-s):
    By the induction hypothesis on $s_1$. Note we reset the basic
    blocks, so we use $\Phi;\cdot;\cdot \tpbb \cdot : \cdot$ in the IH.
  \item (S-call): Since we step to
    $\ido{x}{s'[c_1/x_1,\dotsc,c_n/x_n]}{s}$, we must construct the
    premises $\Phi;\cdot;\Gamma |- s'[c_1/x_1,\dotsc,c_n/c_n] : \tau'$
    and $\Phi;\Psi;\Gamma[x \mapsto \tau'] |- s : \tau$. The second of
    these follow from the type rule for call. The first follows from
    the relation $\Phi |- D : \Phi$. We apply lemma
    \ref{lem:preservation-lookup} to obtain $\Phi;\cdot;[x_1
    \mapsto \tau_1 \dotsb x_n \mapsto \tau_n] |- s' : \tau'$ as
    needed. Successive use of the substitution lemma
    \ref{lem:substitution} then establishes $\Phi;\cdot;\cdot |-
    s'[c_1/x_1,\dotsc,c_n/c_n] : \tau'$.
  \item (S-branch):
    The step is
    \begin{equation*}
      \inference{L(l) = \dbundle \quad d_k = \lambda(x_1, \dotsc,
        x_n).s}
      {D;L |- \ibr{l^k}{(c_1, \dotsc, c_n)} -> s[c_1/x_1, \dotsc, c_n/x_n]}
    \end{equation*}
    and the typing is
    \begin{equation*}
      \inference{\Psi(l) = \bbtypes{} \quad \sigma_k :
        \ntypes -> \bullet\\
        \Gamma |- c_1 : \tau_1 \quad \Gamma |- c_2 : \tau_2 \quad \dotsb
        \quad \Gamma |- c_n : \tau_n}
      {\Phi;\Psi;\Gamma |- \ibr{l^k}(c_1, c_2, \dotsc, c_n) : \tau}
    \end{equation*}
    To prove this, we must show that $\Phi;\Psi;\Gamma |-
    s[c_1/x_1,\dotsc,c_n/x_n] : \tau$. This is true if
    $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k / \tau$ -- since we can then
    apply substitution \ref{lem:substitution} successively.

    To obtain $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k / \tau$, we note
    it can be found by means of the judgement $\Phi;\Psi;\Gamma \tpbb
    L : \Psi$ by induction on $L$: either it is the ``first
    element'' in which case the relation we seek is a premise. Or we
    can apply the IH to $L'$ and $\Psi'$ (the argument is similar to
    lemma \ref{lem:preservation-lookup}).

    This solves the case.
  \end{itemize}
\end{proof}

\begin{thm}{[Preservation]}
  \label{thm:preservation}
  If $|- P$ and $|- P --> P'$ then $|- P'$.
\end{thm}
\begin{proof}
  By application of lemma \ref{lem:preservation-i} where we use
  $\Phi;\cdot;\cdot \tpbb \cdot : \cdot$ as a starting point for the
  helper-judgement.
\end{proof}
\section{Determinism}
\fixme{Determinism}

\section{Twelf encoding}

We encode the proofs of progress and determinism in \twelf{} -- and
get \twelf{} to verify their totality. This constitutes a verified
proof of these theorems (see, for example,
\cite{harper.crary:2005:how}). The formalization exploits that the
\twelf{} encoding gives substitution and weakening ``for free'' - but
it also deviates from the paper proof due to the need for \emph{output
  factoring}. The coverage checker in \twelf{} can only consider each
rule in isolation and thus, it can not see that all outputs are
covered in certain cases. The standard transformation for handling
this problem is called output factoring.

\paragraph{Missing work}
Due to time constraints, the proof of preservation which is encoded in
\twelf{} is currently wrong. There are several problems as is: first,
the relation $\Phi;\Gamma \tpbb \Psi : BB$ is not treated correctly
which pose problems. Second, note that $\Psi$ is currently handled in
the \twelf{}-context.

If we add relations to the \twelf{} context, we can not ``get rid'' of
these relations again. We need to do this in the rule of Tp-do for the
$\Psi$ context. One trick to do this is to \emph{version} additions to
the context. We introduce a set $V := v_1, v_2, \dotsc$ of
``versions'' and then alter bindings in $\Psi$ from $l \mapsto
\sbundle$ into $l \mapsto^{v} \sbundle$, augmenting each binding with
a version. With the versioning in place, we can consider bindings of a
given version in isolation from other versions. If we generate a new
fresh version, $v$, then we effectively reset the context. Utilizing
this trick is thought to be necessary in order to prove preservation.

We are fairly sure that the addition of the $\ido{x}{s_1}{s_2}$ rule
is the culprit. A system built in the process of constructing the
semantics, but without $\mathbf{do}$ admitted preservation almost
trivially.

\chapter{Development Process}

\newcommand{\fskip}{\mathbf{skip}}
\newcommand{\fsemi}[2]{#1 \; ; \; #2}
\newcommand{\fcall}[1]{\mathbf{call} \; #1}
\newcommand{\fpgm}[2]{\mathbf{def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{center}
    Syntax:
  \end{center}
  \begin{align*}
    \text{Terms} \quad \ni t & ::= \fskip{} \bor \fsemi{t_1}{t_2} \bor
    \fcall{f}\\
    \text{Defs} \quad \ni D & ::= \cdot \bor f = t, D\\
    \text{Programs} \quad \ni P & ::= \fpgm{D}{t}
  \end{align*}
  \begin{center}
    Semantics:
  \end{center}
  \begin{gather*}
    \boxed{\Phi |- t -> t'}\\
    \inference[S-Skip]{}{D |- \fsemi{\fskip{}}{t} -> t}\\
    \inference[S-Semi]{D |- t_1 -> t'_1}{D |- \fsemi{t_1}{t_2}
      -> \fsemi{t'_1}{t_2}} \quad \quad
    \inference[S-Call]{D(f) = t}{D |- \fcall{f} -> t}\\
    \boxed{|- P --> P'}\\
    \inference[Pgm/]{D |- t -> t'}{\fpgm{D}{t} --> \fpgm{D}{t'}}
  \end{gather*}
  \begin{center}
    Typing
  \end{center}
  \begin{gather*}
    \text{Fun types} \ni \Phi ::= \cdot | f,\Phi\\
    \text{Wellformed terms:} \; \boxed{\Phi |- t}\\
    \inference[Wf-Skip]{}{\Phi |- \fskip{}} \quad \quad
    \inference[Wf-Call]{f \in \Phi}{\Phi |- \fcall{f}}\\
    \inference[Wf-Semi]{\Phi |- t_1 \quad \Phi |- t_2}{\Phi |-
      \fsemi{t_1}{t_2}}\\
    \text{Wellformed definitions:} \; \boxed{\Phi |- D :
      \Phi'}\\
    \inference[WfD/z]{}{\Phi |- \cdot : \cdot}\\
    \inference[WfD/s]{\Phi |- t \quad f \not \in \Phi' \quad
      \Phi |- D' : \Phi'}{\Phi |- f = t, D' \; : \;
      f,\Phi'}\\
    \text{Program typing:} \; \boxed{|- P}\\
    \inference{\Phi |- \Phi : \Phi \quad \Phi |- t}{|- \fpgm{D}{t}}
  \end{gather*}
  \caption{Toy language for function calls}
  \label{fig:func-call-lang}
\end{figure}

In this chapter, we describe the development process in the
project. Constructing formal semantics for an existing system by
discovering how it works contains several tripwires, booby traps and
some barbed wire. The crux of the problem is that syntax, types,
semantics and meta-theory fit together in an intricate network:
altering one of them may render the other parts invalid. Further
complication is added by LLVM: We cannot deviate too much from the
LLVM IL. Finally, we enforced ourselves to encode everything formally
in \twelf{}, which further complicates the task but also lifts it
above most formal work.

In practice, we needed to carry out several attempts in formalizing
Mini-LLVM before we arrived at the current formalization. In certain
ways even this formalization is incomplete; lacking any kind of memory
instructions and exceptions.

The formalization is built up from two simpler systems, both
formalized in \twelf{}. The first system is a first-order
functionally inspired language with the $\mathbf{letrec}$ as its most
prominent feature. The system helped us understand a way to formalize
mutually recursive functions in \twelf{}. We note that this already
exists\cite{twelfwiki:2007}, but we wanted to discover if it was
possible to define a variant based in intrinsic typing and
\twelf{}-contexts. It is then proven the system had the properties of
\emph{progress} and \emph{determinism}. The preservation-property was
obtained automatically by the intrinsic encoding: the step-relation in
\twelf{} is
\begin{verbatim}
step : tm T -> tm T -> type.
\end{verbatim}
stating that the step relation preserves the type directly. Thus
preservation is a built-in feature of the small-step relation.

The second system is presented in figure \ref{fig:func-call-lang}. It
is a small toy language for the function call semantics. It is
separately proven that this language has progress, preservation and
determinism and this result has been formalized in \twelf{}.

The Mini-LLVM formalization was then built by stratifying the first
language from (functional) terms into registers, constants, operations
and instructions syntactically; and then adding the second language on
top of it. The result is the Mini-LLVM formalization presented in this
report.

\chapter{Conclusion}

\paragraph{Summary}
\begin{itemize}
\item We present a formal semantics for Mini-LLVM, a subset of the
  LLVM IL language. We provide syntax, semantics and a type system for
  Mini-LLVM. We believe it can be used as a starting point for a
  formalization of the full LLVM syntax and semantics.
\item We encode the semantics in the logical framework \twelf{},
  utilizing HOAS and \emph{regular worlds} in the formalization where
  possible. We show that the encoding can correctly evaluate a small
  number of test programs.
\item We provide an alternative method by which to implement mutually
  recursive functions in \twelf{} for first-order languages in an
  intrinsically typed syntax.
\item We formulate and prove the meta-theoretic properties of
  \emph{progress} and \emph{determinism} in \twelf{} and in
  traditional form on paper.
\item We formulate and prove the property of \emph{preservation} on
  paper only.
\end{itemize}

The work should be of interest to anyone who work with the LLVM
system. It provides a key understanding on the basics of the language
and acts as a start for a EBNF grammar for LLVM (which is currently
lacking). In addition we have shown the strong similarity between a
first-order functional language and the LLVM IL. Hence, the work gives
another way to implement the syntax tree for LLVM in a compiler
front-end, before emitting IL instructions. We believe that the latter
part may be of practical use to compiler implementers seeking to use
LLVM in their work.

\paragraph{Further work}

Several extensions of the work are possible. We could extend the
formalization, incorporating more of LLVM. The memory heap would be
interesting to add; the most challenging part being the handling of
pointer arithmetic. A possible path would be to see if Separation
Logic\cite{reynolds:2002:separationlogic} can be used to understand
the heap.

Non-trivial control flow in the form of exceptions would also have to
be conquered. It would be interesting to analyze if a monadic solution
is feasible and reduces the complexity of the semantics.

\bibliography{biblio}
% State what the goals of this project is.
% State we focus on the operational semantics.
% State we will use Twelf where applicable if time allows.

\appendix
\chapter{Source code}
All source code are available either upon request from the author, or
by git revision control on github:
\url{http://github.com/jlouis/jlouis-tvm/tree/master/src/}. We note
that the final commit for the source is:\fixme{Update this commit id}
\begin{center}
  \texttt{cda8e7bb44a0168def492a313ff2d860db2d2889}.
\end{center}
Since this commit is an SHA-1 checksum, it is impossible for the
author to change the source after the deadline\footnote{If I on the
  contrary \emph{can} alter the source code, I have a paper to write
  in cryptography}.

\section{Prelude}
{\footnotesize
\verbatiminput{../src/prelude.elf}
}
\section{Prelude properties}
{\footnotesize
\verbatiminput{../src/prelude-properties.elf}
}
\section{Syntax}
{\footnotesize
\verbatiminput{../src/vm-syntax.elf}
}
\section{Semantics}
{\footnotesize
\verbatiminput{../src/vm-semantics.elf}
}
\section{Typing}
{\footnotesize
\verbatiminput{../src/vm-types.elf}
}
\section{Test code}
{\footnotesize
\verbatiminput{../src/vm-test.elf}
}
\section{Properties}
{\footnotesize
\verbatiminput{../src/vm-properties.elf}
}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
