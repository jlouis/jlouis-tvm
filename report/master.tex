\documentclass[a4paper, oneside, 10pt, draft]{memoir}

\chapterstyle{culver}
\RequirePackage[english]{jlouis}

\author{Jesper Louis
  Andersen\\jesper.louis.andersen@gmail.com\\140280-2029}
\title{Formalizing a Virtual Machine}
\date{\today}

\newlength{\drop}
\newcommand*{\titleM}{\begingroup% Misericords, T&H p 153
  \drop = 0.08\textheight
  \centering
  {\Huge\bfseries Lambda}\\[\baselineskip]
  {\scshape IR of exsml}\\[\baselineskip]
  {\scshape by}\\[\baselineskip]
  {\large\scshape Jesper Louis Andersen\\jesper.louis.andersen@gmail.com}\par
  \endgroup}

\newcommand{\clang}{\textsc{Clang}}
\newcommand{\twelf}{\textsc{Twelf}}
\newcommand{\coq}{\textsc{Coq}}
\newcommand{\agda}{\textsc{Agda}}
\newcommand{\haskell}{\textsc{Haskell}}

\newcommand{\bottom}{\perp}
\bibliographystyle{plain}

\begin{document}
\listoffixmes{}
\maketitle{}
\begin{abstract}
  We present the language Mini-LLVM, an idealized subset of the IL
  language for the \emph{Low Level Virtual machine}(LLVM). From an
  informal LLVM-description, we give a formal account of the syntax,
  semantics types and meta-theoretic properties of Mini-LLVM. We thus
  establish the -- to our knowledge -- first partial formalization of
  LLVM. Our formalization exploits the SSA-form requirement of the
  LLVM IL in a novel way to transform the IL into a functional
  representation. The representation and its meta-theoretic properties
  are encoded into the \twelf{} logical framework and we provide proof
  of \emph{progress}, \emph{preservation} and \emph{determinism} for
  well-typed programs\fixme{Preservation?}. Finally, we show how small
  LLVM IL programs can be translated to our Mini-LLVM language and
  show that they agree on certain inputs --- making it plausible our
  Mini-LLVM is adequate.
\end{abstract}
\newpage{}
\tableofcontents{}
\newpage{}
\section{Foreword}
\fixme{Write a foreword}
\newpage{}
\chapter{Introduction}

\fixme{Go through the whole encoding chapter. It needs some help!}
\fixme{Mention something about $\alpha$-conversion and
  contexts. Particularly that it comes for free in \twelf{}}
It is well known in compiler construction, that intermediate languages
are a useful and beneficial abstraction\cite{appel:1998:modern,
  mogensen:2008:basics}. Rather than targeting the instruction set
architecture directly, the compiler constructor first targets an
intermediate language (IL). Then the IL and is afterwards compiled to
the target machines instruction set\footnote{Sans
  optimizations. Optimization is usually carried out on the IL as
  well}. Schematically, the phases can be described as:
\begin{equation*}
  L ->^{fe} IL ->^{be} Q
\end{equation*}
where $L$ is the source language; the arrow marked by $fe$ the
front-end compilation; and the arrow marked by $be$ is the back-end
compilation onto the machine language $Q$. The construction is
advantageous because the compiler writer can share either the
front-end among several back-ends or the back-end among several
front-ends.

An interesting idea is to have a software program, the \emph{Virtual
  Machine} (VM), handle the work of the backend. The front-end
targets the IL and packs it up for transfer as a binary format. This
format is usually called \emph{bytecode}. The VM then either
interprets the IL or just-in-time compiles before execution. From the
eagles perspective, the VM software acts as a machine able to directly
execute the VM code.

ILs are usually designed to make front-end construction easier. The IL
can specifically factor out details of the underlying machine thus
simplifying compiler implementation. As an example, most VMs carry out
register allocation and the programmer is given an abstraction: either
a stack or an infinite set of registers. Some VMs are designed with a
fairly broad IL intended to capture many different language types
while others are more constrained, often tied to a single intended
language. Examples of the former are the the .NET
CLR/CIL\cite{ecma:2006:335} the C-- language\cite{http:cminmin} and
the LLVM infrastructure \cite{lattner.ea:2009:llvm-ref}, while an
example of the latter is the Warren abstract
machine\cite{warren:1983:prolog}.

\section{LLVM}

This report concerns itself with a virtual machine named LLVM, the Low
Level Virtual Machine. It adopted this name because the LLVM IL is
close to an idealized assembly language with several convenient
differences of which we list some:
\begin{itemize}
\item All LLVM IL programs are statically typed. This rules out many
  common programming errors and fits well into compilation schemes
  where intermediate stage transforms are type-checked.
\item There is an infinite amount of registers and register allocation
  is carried out by the LLVM system.
\item Correct LLVM IL programs have the SSA-property: A variable has
  only one (static/syntactic) point in the program where it is
  \emph{defined}. All \emph{uses} of a variable must then be from this
  single static assignment. The usual $\phi$-node method is used to
  handle the case where control flow joins in the CFG.
\item LLVM has a built-in exception primitive.
\item LLVM is expected to carry out a large number of advanced
  optimizations on its IL with the intent of simplifying work for
  compiler writers.
\end{itemize}

However, one Achilles heel of the LLVM IL is the total lack of
formality. There is not even an EBNF of its grammar available and no
attempts have been made to define its semantics operationally.

In this report, we aim for a subset of the LLVM IL language and
provide a syntax description, an operational (small-step) semantics and a type
system. We seek to prove the system fulfills the usual meta-theoretical
properties of \emph{progress} and \emph{preservation} as well as
\emph{determinism}.

The state-of-the-art emphasized by the poplmark
challenge\cite{aydemir:2005:mechanizedmetatheory} is the encoding of
syntax, semantics and proofs into a proof assistant or logical
framework. The goal is that every computer scientific report is
accompanied by a formal proof written such that the computer can
verify its correctness. In this report we aim for this goal: every
formal description has been encoded into the logical framework of
\twelf{}\cite{schurmann.pfenning:twelf} for verification.

\section{Report structure}

The report first introduces some preliminaries and then presents the
real work made in the following chapters: syntax, semantics and
meta-theory of our Mini-LLVM language is presented. It is expected
that the reader is familiar with operational semantics, proof theory
and machine verifiable proofs; in particular the \twelf{} logical
framework. It is also expected that the reader is familiar with
SSA-form and its implications (i.e., as found in
\cite[Chapter 19]{appel:1998:modern})\fixme{Pulled Appel chapter from
  memory, check when we have access to the book}.

\chapter{Design considerations}

\fixme{Read from ``Design considerations'' and onwards}
In this section, we limit the scope of the formalization and present
the main design considerations before attempting to formalize the work.

\begin{figure}
\begin{verbatim}
if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return
return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0

\end{verbatim}
  \caption{An example LLVM fragment}
  \label{fig:llvm-example-1}
\end{figure}

Figure \ref{fig:llvm-example-1} contains an example of a typical LLVM
basic block. The example is code generated by the \clang{} C frontend,
which compiles C code to LLVM IL. It begins with a label, identifying
the block. Then a series of instructions follow and the block ends in
an unconditional branch to the label '\texttt{\%return}'. Local
definitions in LLVM are prefixed by a '\%' marker and global
(top-level) names by an '@' marker. The instructions \texttt{sub,
  call, } and \texttt{add} informally act like one would expect. Note
that the result are stored in registers named \texttt{\%sub},
\texttt{\%add}, and \texttt{\%call}. This is somewhat confusing and
using $r_1, r_2, \dotsc$ would probably have been simpler to
understand. But we keep the output of the \clang{} compiler as we will
return to it later.

The LLVM type system can be seen in the type designation \texttt{i32},
a 32-bit integer and finally, the '\texttt{nsw}' designation is a
LLVM-specific flag for integer wrap-around, which can be ignored.

In the basic block for the return, we first do a $\phi$-node
assignment. These assignments are required to be at the very top of a
basic block and transfer the value from the appropriate basic block
depending on the control flow. The '\texttt{ret}' instruction
returns. Note that this fragment has the SSA property.

Since we would like to represent LLVM in a machine checkable form in
\twelf{}, we utilize a result formulated explicitly by
Appel\cite{appel:1998:modern, appel:1998:ssa}: every SSA program has
an equivalent functional program. Thus our first design choice is to
represent the LLVM subset as a functional first order program to ease
its encoding in \twelf{}. As we shall see, the SSA-property of LLVM
programs greatly simplifies a number of otherwise complex interactions
in the semantics. Informally, we can transform a fragment
\label{llvm-consideration-let}
\begin{verbatim}
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  ...
\end{verbatim}
of two instructions following each other into the functional fragment:
\begin{verbatim}
  let %sub = sub i32 %n, 1
  in let %call = call i32 @tri(i32 %sub)
     in ...
\end{verbatim}

Note how the lexical scoping rules binds the '\texttt{\%sub}' value
in the correct scope.

We handle the basic blocks as Appel: each basic block becomes a
function with formal parameters the $\phi$-node variables. A branch to
a basic-block then tail-calls the function with the variables needing
transfer as parameters. In the example, we would have a function
\begin{verbatim}
return (%retval) =
   ret %retval
\end{verbatim}
for the return-basic-block. And the branch to it would be
\begin{verbatim}
if.else (...) =
  ...
    br %return (%add)
\end{verbatim}
to designate that the value of '\texttt{\%add}' is the one that should
go to the first $\phi$-node.

\section{Extent of the formalization}

We limit the extent of the formalization to a small subset of
LLVM. First, we note the complete lack of any formal grammar for
the language means we have to begin from a clean slate. Thus,
establishing a small subset is more important as a first step towards
the goal.

We cut any heap-interaction. Specifically, we cut the ability to
load and store data to a heap. LLVM allows pointer arithmetic in the
heap which is hard to handle meta-theoretically. We also cut a large
number of operations that would be easy to add but don't provide
any further insight. Conversion operations are not going to be
considered, as they contain a potentially unsafe '\texttt{bitcast}'
operation. ``Aggregate'' and ``Vector'' operations are not going to be
considered (these include structs and arrays). Finally, we won't be
considering instructions handling exceptions.

While the list of omissions seems extensive, it is important to stress
that part of the task is to understand the subset that is left to a
level where it can be put into a formal system.

Under the course of development, we will use LLVM version 2.x. We
mention this because LLVM is only supposed to change in a backwards
compatible way as long as it remains a version 2.x.

\chapter{Syntax of Mini-LLVM}

\newcommand{\variables}{\mathrm{Variables}}
\newcommand{\BBlabels}{\mathrm{BB Labels}}
\newcommand{\tnat}{\mathbf{nat}}
\newcommand{\tbool}{\mathbf{bool}}
\newcommand{\types}{\mathrm{Types}}
\newcommand{\typelist}{\mathrm{Type lists}}
\newcommand{\bbtype}{\mathrm{BB Type}}
\newcommand{\ftype}{\mathrm{Fun Contexts}}
\newcommand{\tpenv}{\mathrm{Var Contexts}}
\newcommand{\bbenv}{\mathrm{BB Contexts}}
\newcommand{\bor}{\; \vert \;}
\newcommand{\ntypes}{\tau_1 \times \tau_2 \dotsb \times \tau_n}
\newcommand{\bbtypes}{(\sigma_1, \dotsc, \sigma_n)}

In this and the following sections, we present the language
Mini-LLVM. Mini-LLVM is a subset of the LLVM IL in functionality ---
it takes a different approach with respect to SSA-form: Mini-LLVM is a
first order functional language whereas the LLVM IL is an imperative
SSA-form. A functional form is expected to be easier to work with,
formally -- especially in the logical framework \twelf{}.

In the present section, we present the syntax of Mini-LLVM in a formal BNF
grammar. We also describe the type system as well as the basic domains
from which we draw values.

\section{Domains}


\newcommand{\numbers}{\mathrm{Numbers}}
\newcommand{\booleans}{\mathrm{Booleans}}
\newcommand{\funlabels}{\mathrm{Function\; labels}}
\newcommand{\nat}{n}
\newcommand{\bool}{b}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\btrue}{\mathbf{True}}
\newcommand{\bfalse}{\mathbf{False}}

Our language will be using several syntactic terminal domains, the
existence of which we assume (figure \ref{fig:syntactic-domains}). We
have variables, $x_1, x_2, \dotsc$ used for naming and discriminating
registers from each others. For simplicity we restrict the language to
natural numbers only. This restriction is due to \twelf{}: we need to
encode the system of numbers and Peano-style natural numbers are
fairly simple to work with and handle. Verification in other systems
might have chosen another domain. We only utilize basic properties of
arithmetic in our verification, hence it might be possible to change
this later on.
\begin{figure}
  \begin{align*}
    \numbers \ni \NN, \nat & ::= 0 \bor 1 \bor 2 \bor \dotsc\\
    \booleans \ni \BB, \bool & ::= \btrue \bor \bfalse \\
    \BBlabels \ni bb & ::= bb_1, bb_2, bb_3, \dotsc \\
    \funlabels \ni f & ::= f_1,f_2,f_3,\dotsc
  \end{align*}
  \caption{Syntactic domains}
  \label{fig:syntactic-domains}
\end{figure}

Boolean values are either the true value or the false
value. Internally these are encoded as the natural numbers $0$ and
$1$, but the type system is intended to restrict the use to these
values only. In the LLVM IL, an integer variable is typed as its
bit-size, so \texttt{i32} is a 32-bit integer. The special case
\texttt{i1} designate a boolean variable with values 0 or 1. Our
Mini-LLVM language model this by the above construction. Finally, we
assume a set of Basic Block label names and a set of function
names. These are used to refer to groups of basic blocks and
functions, respectively.

In the course of development, we started with a language more closely
resembling a functional language and then gradually stratified the
syntactic classes until it matched that of LLVM as much as
possible. Being an imperative language, LLVM resembles the usual
imperative construction with statements and expressions as stratified
syntactical classes.

Of course, since LLVM has no formal description and the informal
description lacks precision\cite{lattner.ea:2009:llvm-ref}, we run the
risk of having mistaken something in the definition. To mitigate this
risk somewhat, we also used the current LLVM system as a source by
studying and analyzing compiler output from various compilers
targeting LLVM; in particular, the \clang{}-project was used.

\newcommand{\registers}{\mathrm{Registers}}
\newcommand{\constants}{\mathrm{Constants}}
\newcommand{\operations}{\mathrm{Operations}}
\newcommand{\instructions}{\mathrm{Instructions}}
\newcommand{\programs}{\mathrm{Programs}}
\newcommand{\definitions}{\mathrm{Definitions}}
\newcommand{\basicblocks}{\mathrm{Basic Blocks}}
\newcommand{\iret}[1]{\mathbf{ret} \; #1}

\newcommand{\ibr}[2]{\mathbf{br} \; #1 \; #2}
\newcommand{\ibrc}[5]{\mathbf{brc} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\ilet}[3]{\mathbf{let} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\iletrec}[3]{\mathbf{letrec} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\ido}[3]{\mathbf{do} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\icall}[4]{\mathbf{call} \; #1 = #2 #3\; \mathbf{in} \;
  #4}
\newcommand{\ipgm}[2]{\mathbf{Def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{align*}
    \registers \ni r & ::= x_1, x_2, x_3, \dotsc\\
    \constants \ni c & ::= \; r \bor \nat \bor \bool \\
    \operations \ni op & ::= c \\
                       & \bor \quad c + c \\
                       & \bor \quad c - c \\
                       & \bor \quad c < c \\
   \basicblocks \ni d  & ::= \lambda (x_1, x_2, \cdots, x_n) . s\\
   \instructions \ni s & ::= \iret{c} \\
                       & \bor \quad \ibr{bb^n}{(c_1, \dotsc, c_n)} \\
                       & \bor \quad \ibrc{c}{bb^n}{(c_1, \dotsc, c_n)}{bb^n}{(c'_1, \dotsc, c'_n)}\\
                       & \bor \quad \ilet{r}{op}{s} \\
                       & \bor \quad \iletrec{bb}{(d_1, d_2, \dotsc, d_n)}{s} \\
                       & \bor \quad \ido{r}{s_1}{s_2} &
                       (\text{Internal})\\
                       & \bor \quad \icall{r}{f}{(c_1, \dotsc,
                         c_n)}{s}\\
    \definitions \ni D & ::= \cdot \bor (f(x_1, \dotsc, x_n) = s, D)\\
    \programs \ni p & ::= \ipgm{D}{s}
  \end{align*}
  \caption{Syntax}
  \label{fig:syntax}
\end{figure}

\section{Main syntax}

In figure \ref{fig:syntax} we present the complete syntax for the
Mini-LLVM language. The atomic expressions of the language are exactly
registers, natural numbers and boolean values. The language has three
primitive operations, namely $c + c$, $c - c$ and $c < c$. Of these,
the latter returns a boolean value, whereas the first two return
natural numbers. The '$-$' operation is defined such that if $y \geq
x$ then $x - y = 0$.

Instructions form the main part of Mini-LLVM. The instruction
$\iret{c}$ represents returning a value from a function. It models the
LLVM '\texttt{ret}' instruction.

Basic blocks are introduced with the $\iletrec{bb}{(d_1, \dotsc,
  d_n)}{i}$ notation. This simultaneously binds the definitions $d_1$
through $d_n$ of basic blocks to the name $bb$. Note each definition will
take formal parameters for its $\phi$-nodes. The name $bb$ will be
available in the context of the instruction $i$. We will often in the
following call a basic block mapping $bb \mapsto (d_1, \dotsc, d_n)$
for a Basic block \emph{bundle}.

The instruction $\ibr{bb^k}{(c_1, \dotsc, c_n)}$ designates an
unconditional branch to the $k$th projection in the basic block bundle
represented by the name $bb$. The parameters $c_1$ through $c_n$ are
formal $\phi$-node parameters to the given basic block. In LLVM, the
projections are named explicitly by identifier names, but we felt that
a projection is easier to handle from a formal viewpoint.

The $\ibrc{x}{bb^k}{Ps}{bb^{k'}}{Ps'}$ represents a conditional
branch. It will, depending on the value of $x$ transfer control to
either the first or second basic block projection, injecting the
corresponding set of $\phi$-node parameters. In LLVM both
branch-instructions are called '\texttt{br}' -- the syntactical
difference discriminates them.

As noted in the design considerations, we represent a sequential chain
of operations as a chain of let-style-bindings. Thus the
$\ilet{x}{op}{i}$ instruction represents sequential execution. An
operation is executed and its result is placed into the register
$x$. The register is then available in the $i$ instruction.

The $\ido{x}{i_1}{i_2}$ instruction is not meant to be present in
initial Mini-LLVM programs. It is used internally to keep the context
of a function call around. This has to do with the fact that the
formalization lacks a stack and thus uses the current continuation
context to keep track of where the computation came from. Function
calls utilize the instruction while they are executing.

Finally the $\icall{r}{f}{(c_1, \dotsc, c_n)}{i}$ instruction
represents an LLVM '\texttt{call}' instruction in a very simplified
way. In LLVM it is possible to annotate the call-instruction with a
large number of hints. These hints are used to handle calling
conventions, tall-call applicability, etc., but we omit them in our
formalization because we do not attempt to formalize these aspects of
LLVM. The instruction will call the $f$ function with parameters $c_1$
through $c_n$ returning the result in the $r$ register. The result
will be available in the $i$ instruction. Thus a function call acts
like a special variant of a let-binding.

\paragraph{Programs}

A Mini-LLVM program is a list of definitions $\Phi$ together with an
initial instruction $i$. The notation is $\ipgm{\Phi}{i}$. Usually, we
expect the program to begin by calling a main-function in the list of
definitions, but we have chosen to deviate from LLVM here and allow
the execution of an arbitrary instruction rather a call to main. We
can simply limit valid programs to begin by a forced instruction
call to a function ``\texttt{main}'', should we so desire.

\chapter{Mini-LLVM type sytem}
\label{chap:type-system}

In this chapter we describe a type system for our Mini-LLVM
language. That we need a type system should be clear: our syntax
allows programs which can get stuck and we want a type system to
constrain programs.

\paragraph{Type Domains} The language employs a simple type system as in
figure \ref{fig:type-system}. There are two primitive base types,
natural numbers and boolean values. For handling passing of parameters
between basic blocks via $\phi$-nodes, there is a $\bbtype$
designation stating a (possibly empty) list of formal parameters. We
notate such lists as $\ntypes -> \bullet$ where the last
``$\bullet$'' states that it is a function but without return type.
\fixme{Bullet here and in the figure below}
The choice of two primitive types is deliberate. It is the simplest
non-trivial choice of types possible. Had there only been one base
type, all typing degenerates into questions on type arity in basic
block definitions.

\begin{figure}
  \begin{align*}
    \types \ni \tau & ::= \tnat \bor \tbool \\
    \bbtype \ni \sigma   & ::= \ntypes -> \bullet\\
    \ftype \ni \Phi & ::= \cdot \bor (f \mapsto (\ntypes -> \tau), \Phi) \\
    \tpenv \ni \Gamma & ::= \cdot \bor (x \mapsto \tau),\Gamma\\
    \bbenv \ni \Psi   & ::= \cdot \bor (bb \mapsto \bbtypes),\Psi
  \end{align*}
  \caption{Type system}
  \label{fig:type-system}
\end{figure}

\newcommand{\tpr}{|-_{\mathrm{r}}}
\newcommand{\tpc}{|-_{\mathrm{c}}}
\newcommand{\tpop}{|-_{\mathrm{o}}}
\newcommand{\tpb}{|-_{\mathrm{b}}}

To take care of these problems, we need a type system ruling out these
possibilities in the syntax. In figure \ref{fig:type-judgement-1}, we
present typing relations for registers, constants and
operations. Register typing is simply handled by a judgment form
$\boxed{\Gamma \tpr x}$ with a single rule, TpR, for lookup into the
environment. The judgement form $\boxed{\Gamma \tpc c : \tau}$ states
that in the environment of $\Gamma$ the constant $c$ has type
$\tau$. There are 3 different cases, one for register lookup, and two
for each of the constant types.

The judgment form for operations is $\boxed{\Gamma \tpop op :
  \tau}$. Under the environment of $\Gamma$ the operation $op$ has
type $\tau$. These rules are somewhat straightforward for most
part. The only special case is that the less-than comparison operator
has boolean type.

Basic blocks are typed by checking that each of the formal parameters
have the stated type as a parameter and in the instruction body. Note
that we do not consider the return type of the instruction as we
handle it later on when type checking functions.

\begin{figure}
  \begin{gather*}
    \text{Registers:} \quad \boxed{\Gamma \tpr x : \tau}\\
    \inference[TpR]{\Gamma(x) = \tau}{\Gamma \tpr x : \tau}
  \end{gather*}
  \begin{gather*}
    \text{Constants:} \quad \boxed{\Gamma \tpc c : \tau}\\
    \inference[TpC-Var]{\Gamma \tpr x}{\Gamma \tpc x : \tau}\\
    \inference[TpC-Nat]{}{\Gamma \tpc n : \tnat} \quad
    \inference[TpC-Bool]{}{\Gamma \tpc b : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{\Gamma \tpop op : \tau} \\
    \inference[TpOp-Cst]{\Gamma \tpc c : \tau}{\Gamma |- c : \tau}\\\\
    \inference[TpOp-Plus]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 + o_2 : \tnat} \quad
    \inference[TpOp-Mone]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 - o_2 : \tnat}\\\\
    \inference[TpOp-Let]{\Gamma \tpop o_1 : \tnat \quad \Gamma
      \tpop o_2 : \tnat}{\Gamma \tpop o_1 < o_2 : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Basic block Definitions:} \quad \boxed{D;\Psi;\Gamma \tpb d
      : \tau}\\
    \inference[BB-Def]{D;\Psi;\Gamma[x_1 \mapsto \tau_1 \dotsb x_n \mapsto \tau_n] |- i :
  \tau}{D;\Psi;\Gamma \tpb \lambda(x_1, x_2, \dotsc,
      x_n).i : \tau_1 -> \tau_2 -> \dotsc -> \tau_n -> \tau}
  \end{gather*}
  \caption{Typing 1}
  \label{fig:type-judgement-1}
\end{figure}

\fixme{Let a tau be shared among a set of basic blocks perhaps?}
In figure \ref{fig:type-judgement-2} we present the typing relations
for instructions. The general judgment for these is
$\boxed{D;\Psi;\Gamma |- i : \tau}$. This specifies that the
instruction $i$ has a type of $\tau$ in the environment of
$D;\Psi;\Gamma$. The domain $D$ here is the domain of function
contexts (see figure \ref{fig:type-system}) mapping a function name
$f$ to its function type. The domain $\Psi$ maps basic blocks: for
each basic block there is a mapping from the basic block name to a
tuple of basic block types. Finally, the domain $\Gamma$ maps
registers to their types.

An instruction of the form $\iret{c}$ has type $\tau$ if the constant
it returns has. Correct typing of an $\ilet{x}{op}{i}$ instruction
requires that the operation $op$ returns the same type as is used for
the register $x$ in the body $i$.

The rule Tp-do defines a typing of a $\ido{x}{i_1}{i_2}$
instruction. The type of $i_1$ must the the same type as used in
$i_2$. Note the similarity between this instruction and the
let-binding above.\fixme{Decide if we should kill $\Psi$ here}.

Unconditional branches are handled by the Tp-br rule. It states that a
well-typed branch can look up the basic block in the environment of
basic blocks and then take the $k$th projection of this to obtain the
type $\tau_1 -> \dotsc -> \tau$.

Conditional branches are well-typed if each path regarded as
unconditional branches are. Furthermore we require the branch variable
to be a boolean value.

The Tp-letrec rule introduces basic blocks. It first checks that each
basic block definition is well-typed. Then it type checks the body $i$
under an augmented environment where a mapping to the basic block
identifier has been made.

Finally, function calls are well-typed if we can look up the function
identifier in the function environment $D$; and can show the
passed arguments obeys the type scheme.

\begin{figure}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{D ; \Psi ; \Gamma |- i : \tau}\\\\
    \inference[Tp-ret]{\Gamma \tpc c : \tau}{D ; \Psi ;
      \Gamma |- \iret{c} : \tau} \quad
    \inference[Tp-let]{\Gamma \tpop op : \tau_1 \quad D ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- i : \tau}{D ; \Psi ; \Gamma |-
      \ilet{x}{op}{i} : \tau}\\\\
    \inference[Tp-do]{D;\Psi;\Gamma |- i_1 : \tau_1 \quad
      D;\Psi;\Gamma[x \mapsto \tau_1] |- i_2 : \tau} {D;\Psi;\Gamma |-
      \ido{x}{i_1}{i_2} : \tau}\\\\
    \inference[Tp-br]{\Psi(bb) = BB\tau{}s \quad BB\tau{}s(k) : \tau_1 -> \tau_2 -> \dotsc ->
      \tau_n -> \tau\\
      c_1 : \tau_1 \quad c_2 : \tau_2 \quad \dotsb \quad c_n : \tau_n}
    {D;\Psi;\Gamma |- \ibr{bb^k}(c_1, c_2, \dotsc, c_n) : \tau}\\\\
    \inference[Tp-brc]{\Gamma \tpc x : \tbool \\ D;\Psi;\Gamma |-
      \ibr{bb^k}{(c_1, \dotsc c_n)} : \tau \\
    D;\Psi;\Gamma |- \ibr{bb^{k'}}{(c'_1, \dotsc, c'_{n'})} : \tau}{D;\Psi;\Gamma |- \ibrc{x}{bb^k}{(c_1, \dotsc,
        c_n)}{bb^{k'}}{(c'_1, \dotsc, c'_{n'})} : \tau} \\\\
    \inference[Tp-letrec]{D;\Psi[bb \mapsto (Bb \tau_1, \dotsc, Bb
      \tau_n)];\Gamma \tpb d_1 : Bb \tau_1\\
      \dotsb \\D;\Psi[bb \mapsto (Bb \tau_1, \dotsc, Bb
      \tau_n)];\Gamma \tpb d_n : Bb\tau_n \\
      D;\Psi[bb \mapsto (Bb \tau_1, \dotsc, Bb
      \tau_n)];\Gamma |- i : \tau}{D;\Psi;\Gamma |- \iletrec{bb}{(d1,
        \dotsc, d_n)}{i} : \tau}\\\\
    \inference[Tp-call]{D(f) = \tau_1 -> \dotsc -> \tau_n -> \tau\\
    c_1 : \tau_1 \quad \dotsb \quad c_n : \tau_n}{D;\Psi;\Gamma |- \icall{f}{(c_1, \dotsc,
        c_n)} : \tau}
  \end{gather*}
  \caption{Typing 2}
  \label{fig:type-judgement-2}
\end{figure}

\section{Programs}

A program is well-formed (figure \ref{fig:type-judgement-3}) if it
obeys a wellformedness criterion $\boxed{D |- \Phi : D}$ on its
definitions $\Phi$ and that the body is wellformed in empty Basic
block and variable environments. We write $\boxed{|- P}$ for
well-formed programs.

The criterion for definition blocks examines wellformedness of the
list of definitions. If the definition list is empty, then the
function environment has to be as well. Each function must be
wellformed with respect to its formal parameters and the full
environment $D$. We furthermore require that the function identifier
does not occur twice with the rule $f \not \in D'$.

Note that the rule $D |- \Phi : D$ ties the knot on function
definitions. The function environment $D$ is being examined while it
is being built at the same time.

The judgement $\boxed{D;\Psi;\Gamma |- BB : \Psi'}$ is used to state
that a basic block relates to its context. We will use this in the
proof of \emph{preservation}, to maintain the relationship. The idea
is that if a basic-block environment is well-formed, all the
definitions must be.

\begin{figure}
  \begin{gather*}
    \text{Definition Wellformedness:} \quad \boxed{D |- \Phi : D'}\\\\
    \inference[Wf-defs/z]{}{D |- \cdot : \cdot}\\\\
    \inference[Wf-defs/s]{D |- \Phi' : D' \quad D;\cdot;[x_1 \mapsto
      \tau_1 \; \dotsb \; x_n \mapsto \tau_n] |- i :
      \tau \quad f \not \in D'}{D |- (f(x_1, \dotsc, x_n) = i, \Phi') : (f
      \mapsto \tau_1 -> \dotsc -> \tau_n -> \tau, D')}
  \end{gather*}
  \begin{gather*}
    \text{Basic Block Wellformedness:} \quad \boxed{D;\Psi;\Gamma |-
    BB : \Psi'}\\\\
  \inference[Wf-bb/z]{}{D;\Psi;\Gamma |- \cdot : \cdot}\\\\
  \inference[Wf-bb/s]{D;\Psi;\Gamma \tpb d_1 : BB\tau_1\\
                      \dotsb\\
                      D;\Psi;\Gamma \tpb d_n : BB\tau_n\\
                      D;\Psi;\Gamma |- BB' : \Psi'}
                    {D;\Psi;\Gamma |- (bb = (d_1, \dotsc, d_n), BB') : (bb \mapsto
                      (Bb\tau_1,\dotsc,Bb\tau_n), \Psi')}
  \end{gather*}
  \begin{gather*}
    \text{Program Wellformedness:} \quad \quad \boxed{|- P}\\\\
    \inference[WF-Pgm]{D |- \Phi : D \quad D;\cdot;\cdot |- i}{|- \ipgm{\Phi}{i}}
  \end{gather*}
  \caption{Typing 3}
  \label{fig:type-judgement-3}
\end{figure}

\chapter{Mini-LLVM Semantics}

In this chapter we present the Mini-LLVM semantics (see figure
\ref{fig:semantics}). Since \twelf{} is partial to operational
semantics, we need to decide between a big-step operational semantics
and a small-step operational semantics.

The semantics in Pierce's seminal work \cite{pierce:2002:types} on
type systems are mostly given in small step semantics. Focusing our
effort on a small-step semantics thus gives us a framework in which
the meta-theory will follow the work of Pierce. A big-step semantics
is also possible, but then we need to work with a separate notion of
when terms terminate.

The small-step semantics -- however -- is \emph{inefficient}: we need
considerably more inference rule applications in order to reduce a
term to canonical form. On the other hand it is \emph{precise}:
certain details (like short-circuiting operators) are more easily
handled by a small step semantics.

We choose a small-step semantics for this work. Mostly to follow the
structural ideas from Pierce's book ``Types and Programming
Languages''.

\paragraph{Step relation for operations}

\newcommand{\eop}{=>_{o}} For operations, $\boxed{|- op \eop n}$ is
the judgement form. The form states the operation $op$ evaluate to a
value of $n$. This might look like a big-step semantics, but note that
all operations are \emph{primitive} in Mini-LLVM: An operation is
limited by the syntax such that it cannot be an arbitrary tree
tree. This is also the reason we chose the operation as a name rather
than the more common \emph{expressions}.

For each possible operator, there is a corresponding inference
rule. All of these simply unwraps underlying integers and then applies
the proper mathematical arithmetic operation.

\begin{figure}
  \begin{gather*}
    \text{Operations:} \quad \boxed{|- op \eop n}\\
    \inference[E-Cst]{}{|- c \eop n} \quad
    \inference[E-Plus]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 + n_2 = n}{|- c_1 + c_2 \eop n}\\\\
    \inference[E-Mone]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 - n_2 = n}{|- c_1 - c_2 \eop n}\\\\
    \inference[E-Lt]{|- c_1 \eop n_1 \quad |- c_2 \eop n_2 \quad
      n_1 < n_2 = b}{|- c_1  < c_2 \eop b}
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{\Phi;BB |- i -> i'}\\
    \inference[S-let]{|- o \eop v}{\Phi;BB |- \ilet{x}{o}{i} ->
      i[v/x]}\\\\
    \inference[S-letrec-v]{}{\Phi;BB |- \iletrec{bb}{(d_1, \dotsc,
        d_n)}{\iret{v}} -> \iret{v}}\\\\
    \inference[S-letrec-s]{\Phi;BB[bb \mapsto Dt] |- i -> i'}
    {\Phi;BB |- \iletrec{bb}{Dt}{i} -> \iletrec{bb}{Dt}{i'}}\\\\
    \inference[S-brc-t]{}{\Phi;BB |-
      \ibrc{\btrue}{bb^k}{Ps}{bb^{k'}}{Ps'} -> \ibr{bb^k}{Ps}}\\\\
    \inference[S-brc-f]{}{\Phi;BB |-
      \ibrc{\bfalse}{bb^k}{Ps}{bb^{k'}}{Ps'} ->
      \ibr{bb^{k'}}{Ps'}}\\\\
    \inference[S-do-s]{\Phi;BB |- i_1 -> i'_1}{\Phi;BB |-
      \ido{x}{i_1}{i_2} -> \ido{x}{i'_1}{i_2}}\\\\
    \inference[S-do-v]{}{\Phi;BB |- \ido{x}{\iret v}{i_2} ->
      i_2[v/x]}\\\\
    \inference[S-call]{\Phi(f) = (\;f(x_1, x_2, \dotsc, x_n) = i'\;)}{\Phi;BB |-
      \icall{r}{f}{(c_1, c_2, \dotsc, c_n)}{i} -> \ido{r}{i'[c_1/x_1, c_2/x_2,
        \dotsc, c_n/x_n]}{i}}\\\\
    \inference[S-br]{BB(bb) = Ks \quad Ks(k) = \lambda(x_1, \dotsc, x_n).i}{\Phi;BB |- \ibr{bb^k}{(c_1, \dotsc, c_n)} ->
      i[c_1/x_1, \dotsc, c_n/x_n]}
 \end{gather*}
 \begin{gather*}
   \text{Programs:} \quad \boxed{|- P --> P'}\\
   \inference[SP]{\Phi;\cdot |- i -> i'}{\ipgm{\Phi}{i} --> \ipgm{\Phi}{i'}}
 \end{gather*}
  \caption{Semantics}
  \label{fig:semantics}
\end{figure}

\paragraph{Step relation for instructions}

Instructions is by far the most complex in this system. They have the
judgment form $\boxed{\Phi;BB |- i -> i'}$. The context $\Phi$
contains function definitions we can call. The context $BB$ contains
the basic blocks we have introduced and can branch to.

In the semantics, we use the notation $i[v/x]$. This means that you
substitute all occurrences of $x$ with $v$ in the syntax tree of
$i$. In other words, if $(\lambda x . i\; x)$ the higher order
abstraction of $i$ then $i[v/x] \equiv (\lambda x . i\; x) v$. We
use this fact extensively when encoding the semantics in \twelf{}.

The basic sequential operation in LLVM is handled by the
$\ilet{x}{op}{i}$ instruction in Mini-LLVM. As already noted in
\ref{llvm-consideration-let}, we translate sequences of instructions
into nested applications of $\mathbf{let}$s. To execute an operation,
$op$, is to know the contents of the register $x$. Since we have the
SSA-property and the SSA/FP correspondence, we can then just propagate
the value of $x$ to all its uses directly. This is done by
substituting the result for $x$ in the body of the let, $i$.

Evaluation of an instruction $\iletrec{bb}{Defs}{i}$ progresses
depending on the structure of $i$. If $i$ is of the form $\iret{c}$,
then there is no reference to the basic blocks, and we can get rid of
them. This is done with the S-letrec-v rule. Otherwise, the S-letrec-s
rule introduces all the basic blocks into the context at once;
followed by a step underneath.  In effect, the body of a
$\mathbf{letrec}$ can act as the scratch-pad for the execution of
basic blocks and be replaced with a new basic block from the context.

Conditional branches examine the boolean value and then step into an
unconditional branch of the right kind. Unconditional branches, the
S-br rule first look up the appropriate basic block in the
environment; then it applies the $k$th projection to get at the
correct basic block. Finally, it resolves the contents of the
$\phi$-nodes by substitution --- again exploiting the SSA/FP
correspondence.

The $\ido{x}{i_1}{i_2}$ instruction is equivalent to a normal
let-construction in an (extended) lambda-calculus. It reduces $i_1$ via the
rule S-do-s until it becomes a canonical value (i.e., a $\iret{c}$);
then applies the rule S-do-v to push down the value of $x$ into the
body $i_2$.

Finally, function calls are handled by the S-call inference rule. We
look up the definition of the function call in the function
context. Then we step into a $\mathbf{do}$ instruction. Thus, we will
use the $\mathbf{do}$ as a scratchpad for the function evaluation. It
is not particularly efficient, but it avoids the introduction of a
separate stack onto Mini-LLVM. Exploitation of the SSA-property leads
to a simple substitution of function parameters.

\paragraph{Step relation for programs}

A Program steps by the form $\boxed{|- P --> P'}$. It simply
introduces the definitions in the context so they are callable from
the body.

\chapter{Twelf encoding}

We now seek to encode the syntax and semantics in Twelf. When
encoding, we must make certain choices along the way. Almost any
operational semantics will omit specific parts --- in the name of
notational simplicity. The encoding needs to take care of this
explicitly, however.

\paragraph{Extrinsic vs. Intrinsic encoding}

When we specify a syntax as an abstract syntax tree in a language like
ML, we usually do so by virtue of a recursive sum type. This syntax
description allows us to write down some \emph{illegal} programs:
certain syntax trees will get stuck under evaluation. A typing
relation then constrain the syntax trees such that only well-typed
programs are allowed. When the typing relation stands next to the
syntax description, we say that the encoding is \emph{extrinsic}.

In contrast, if the programming language has access to Generalized
algebraic data-types (GADTs) or dependent types, we might define the
syntax in way that rejects ill-typed programs directly. This encoding
form, called \emph{intrinsic} encoding, is possible in \twelf{},
\coq{}, \agda{}, and to a certain extent \haskell{}.

Intrinsic encodings have their limitations however. The typing
relation must be static in the sense that it must be driven by the
syntactical rules alone. An extrinsic encoding on the contrary can use
any (Turing Machine-)computable function. This might make the
intrinsic encoding impossible for some typing relations.

In our work, we sought to achieve an intrinsic encoding of as much of
the semantics as possible. This we aimed for an intrinsic encoding of
instructions, but adopted an extrinsic encoding for function
definitions and programs.

\section{The Prelude}

The prelude contains various helper-relations for use in the real
formalization. In other proof systems (e.g., \coq{}\cite{team:coq*1}),
these are already present in a standard library, but for \twelf{} we
are forced to code them by hand.

We encode the boolean values and Peano style natural numbers along with
operations on these. As examples, we encode arithmetic operations and
predicates for equality and non-equality.

\paragraph{properties}

Since we want to use properties of the prelude in meta-theory, we must
prove that the properties are true. In the following, we present some
example properties from the prelude:
\begin{lem}
  Suppose we have two natural numbers $n_1, n_2 \in \NN$. Then there
  exists an $n_3 \in \NN$ such that $n_1 + n_2 = n_3$.
\end{lem}
\begin{proof}
  Induction on $n_1$: If $n_1$ is $0$ then take $n_3 =
  n_2$. Otherwise then by induction $(n_1 - 1) + n_2 = (n_3 - 1)$. To this
  we can add one to both sides to obtain the result.
\end{proof}

Lemmas of this form is very common in \twelf{} signatures. They are
called \emph{effectiveness} lemmas and are usually named with a
\texttt{can-} prefix as in \texttt{can-nat-plus} and
\texttt{can-step-op}. They build a bridge between a pure syntactical
object and an accompanying relation on the object.

Another very common \twelf{} proof is reasoning from false. We have a
special type family defined, \texttt{void}, with no constructors
whatsoever. This can be used to prove absurd statements. Our first
such statement is
\begin{lem}
  Let $n_1$ and $n_2$ be natural numbers. Then $n_1 = n_2 \land n_1
  \neq n_2 \implies \bottom$.
\end{lem}
\begin{proof}
  The proof relies on the fact that the premise is always false. In
  our formal encoding we can analyze the structure on $n_1
  \neq n_2$ to show this.
\end{proof}

We can reason anything from \texttt{void} because void has no valid
constructors. Thus the sentence $\forall v \in \texttt{void} \; . \; \exists
E$ for any $E$ is vacuously true since there is no way the $v$ can be
inhabited.

\section{Syntax encoding}

We would like to use an intrinsic encoding for as much of the syntax
as possible. We would also like to use a for \twelf{} classic method
w.r.t. encoding variables, named \emph{higher order abstract syntax}
(HOAS). With HOAS, we use an LF-binding to represent a variable in the
object language we are encoding. We can use this method to represent
the registers of the language in the constants. In effect, execution
of the semantics will mean that when a register is \emph{defined} we
immediately ``push'' its value to all of its \emph{uses} by
substitution. Since our system is also intrinsic, we let a be a family
of types:
\begin{verbatim}
cst : tp -> type.
\end{verbatim}
In the same vein, we can define operations and instructions to be
bearing their types. For an instruction, its type is the type of a
return value.

This methodology is used to merge part of the typing relation into the
language syntax, directly handling the type in the syntax.

\paragraph{Handling basic blocks}

A complication with an intrinsic typing is how to type basic blocks. A
basic block is essentially a list of definitions $d_1, d_2, \dotsc,
d_n$, with each definition of the form $\lambda (x_1, \dotsc,
x_n).i$. The latter can be represented by a standard \twelf{}-HOAS-trick:
If $i$ is the syntax tree of the function body, we represent the
$\phi$-variable by wrapping the syntax tree in an LF-lambda: $\lambda
(x : \texttt{reg t}) . i$, where $x$ might be bound in $i$. Thus,
substitution is LF-application. By successively wrapping once for each
$x_i$ variable, we obtain a definition $d$. Since the typing is
intrinsic, we let each wrapping book-keep the typing.

The definition list also intrinsically encodes the typing. It is a
typical functional style list with a \texttt{nil} and a \texttt{cons}
element, but with a type-designation on each element.

This construction encodes types for a list of definitions $d_1, d_2,
\dotsc, d_n$ -- but we wish to handle such definitions by \twelf{}
regular worlds. Hence, we have an type family
\begin{verbatim}
bname : bb-tp -> type.
\end{verbatim}
where \texttt{bb-tp} is the type of definition lists. We use that to
introduce a new $bname$ into the context when stepping under a
$\mathbf{letrec}$ instruction:
\begin{verbatim}
step/letrec-s : step D (insn/letrec ([pb] Defs pb) ([pb] Body pb))
                     (insn/letrec ([pb] Defs pb) ([pb] Body' pb))
                 <- ({pb} bb-bind pb (Defs pb) ->
                         step D (Body pb) (Body' pb)).
\end{verbatim}
Here, the \texttt{pb} variable is a hypothetical new variable which we
bind to the definitions with the \texttt{bb-bind} relation. Since
definitions are allowed to call each other, we pass in the \texttt{pb}
variable to the definitions. Note that the type of \texttt{pb} will be
the same as the type of \texttt{(Defs pb)}.

The above construction let us define a basic block bundle, but it does
not tell the whole story: how to project and call. In a branch
instruction $\ibr{bb^k}{(c_1, \dotsc, c_n)}$, we need to encode the
call $bb^k$. We define this by the means of the constants
\texttt{f-hd, f-tl/s} and \texttt{f-tl/z}. If $bb$ is a
\texttt{bname}, we define $bb^k$ as:
\newcommand{\fhd}{\mathtt{f\!\!-\!\!hd}}
\newcommand{\ftls}{\mathtt{f\!\!-\!\!tl/s}\; }
\newcommand{\ftlz}[1]{(\mathtt{f\!\!-\!\!tl/z} \; #1)}
\begin{equation*}
  \fhd \underbrace{(\ftls(\ftls ( \; \dotsb \; }_{k \; \text{terms}}\ftlz{bb})))
\end{equation*}
The encoding allows us to maintain the intrinsic typing when transferring
control to another basic block. Each occurrence of an $\ftls$ will
have us taking the tail of the definition pointed to by $bb$ -- giving
us the $k$th projection at the front of the list when finished. See
the \texttt{branch-lookup} relation in the \twelf{} source.

We tried several different ways of encoding basic blocks
intrinsically. Initially, we encoded a hypothetical name for
each basic block definition $d_i$. It turns out, however, that this
doesn't account for multiple definitions of the same basic block
name which would lead to loss of determinism among other
things. In general each basic block should occur once with a unique
name -- and the hypothetical name must obey the typing of the
definition. We used some time analyzing if it was possible to
intrinsically code the first-order $\mathbf{letrec}$-variant of
Mini-LLVM and the above encoding answers the question in the
affirmative.

\paragraph{Handling function calls}

For function calls, we deviate from the intrinsic encoding and encode
it extrinsically as is more traditional. A function identifier is
simply a natural number. But to build the bridge between the intrinsic
and extrinsic parts it was beneficial to augment the function
identifier with the presumed type from the intrinsic encoding:
\begin{verbatim}
fun-id : tp -> tp-list -> type.
fun-id/ : nat -> fun-id T TL.
\end{verbatim}
Consequently, the intrinsic type system will not be able to type check
the correctness of function calls.

\section{Semantics encoding}

The semantics are encoded rather straightforwardly from figure
\ref{fig:semantics}. The only deviance is the use of the \twelf{}
context to handle the semantic environments.

The somewhat informal invocation of basic blocks and function calls
need mention though. In the semantics, we write $i[c_1/x_1, \dotsc,
c_n/x_n]$ for substituting $c_i$ for $x_i$ ($1 \leq i \leq n$). In the
\twelf{} formalization this is realized by the following construction:
We have a list $[c_1 : \tau_1, \dotsc, c_n : \tau_n]$ of constant
parameters and a basic-block / function-body which HOAS-represents the
$\phi$-nodes: $\lambda x_1 : \tau_1 \;.\; (\lambda x_2 : \tau_2 \;.\;
\dotsc, (\lambda x_n : \tau_n \;.\; i)\dotsb{})$. We can then
successively apply a constant $c_i : \tau_i$ to the $i$th lambda-term
and then $\beta$-reduction solves the rest of the substitution. The
very fact that $\beta$-reduction acts as our substitution principle is
central to \twelf{}-representations.

\section{Typing encoding}

The intrinsic parts of the type system is already encoded into the
syntax. The extrinsic parts are encoded in a set of relations which are
directly transcribed from the operational semantics given in chapter
\ref{chap:type-system}.

The notation $f \not \in D$ is implemented by a simple scan over the
list of definitions:
\begin{gather*}
  \text{Function Absence:} \quad \boxed{f \not \in D}\\
  \inference[f-notin/z]{}{f \not \in \cdot}\\\\
  \inference[f-notin/s]{f \neq f' \quad f \not \in D'}{f \not \in (f' = t, D')}
\end{gather*}
\section{Transformation of LLVM Programs to Mini-LLVM}

One rather important milestone in our work is to make sure a correct
LLVM IL program using a supported subset can be transformed into an
equivalent Mini-LLVM program. Our running first example will be the
calculation of triads:
\begin{equation}
  \label{eq:1}
  n? = 1 + 2 + \dotsb + n = \sum_{0 < i \leq n} i
\end{equation}

The notation $n?$ is due to Knuth\cite[section
1.2.5]{knuth:1997:taocp1}. We choose this example over the factorial
function since it is readily computable without the need for a
multiplication operator. Straightforward recursive implementation of
this in C yields:
\begin{verbatim}
int
tri (int n) {
    if (n == 0) { return 0; }
    else return (tri(n-1) + n);
}
\end{verbatim}
We can then use the \clang{} compiler from C to LLVM IL to generate
LLVM code for this C fragment. The \clang{} compiler circumvents the
need to produce SSA IL code by using the stack as a scratch-pad for
all operations. Any operation will be a load from the memory location
of the stack and then a store back of the result. Thus the raw output
from the compiler cannot be used as our Mini-LLVM language has no
concept of a stack.

LLVM contains an optimization pass however, \texttt{mem2reg}, which
can transform stack references into register access. This effectively
eliminates the explicit allocation on the stack.

If we skip for us irrelevant parts about the LLVM data layout, we have
the following function body:
\begin{verbatim}
define i32 @tri(i32 %n) nounwind {
entry:
  %cmp = icmp eq i32 %n, 0
  br i1 %cmp, label %if.then, label %if.else

if.then:
  br label %return

if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return

return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0
}
\end{verbatim}
By hand-translation of this into Twelf, we obtain the following
twelf-function for the same fragment:
\fixme{Insert fragment}
\fixme{Note something about inverted phi-nodes}
\paragraph{Automatic translation}

A full treatment of translation ought to be automatic rather than
hand-written. It certainly looks possible automate the above
translations. If one parses LLVM IL into an abstract syntax tree,
output should be pretty straightforward --- save for the inversion of
$\phi$-nodes.

The inversion can be handled by a two-pass algorithm. In the first
pass we gather $\phi$-nodes for each basic block as well as what value
each branch into the basic block passed. In the second pass, we
replace all branch invocations with tail-calls such that the right
values are passed.

To establish the plausibility of a full isomorphism, an inverse parser
must also be created. This inverse parser should take a
\twelf{}-signature with a test definition and transform it into
equivalent full LLVM code. It has to invert the passing of
$\phi$-nodes as well. This can be done by a similar two-pass scan.
\fixme{Provide at least one more encoding example}

\chapter{Meta-theory}

\fixme{Describe the ``Meta-theory''}
\section{Lemmas}

To prove the usual meta-theoretic theorems we need some auxiliary
lemmas. For instructions, we need the presence of weakening lemmas for
instructions with respect to variable- and basic-block-contexts.

\begin{lem}
  \label{lem:weaken-gamma}
  Instruction typing admits weakening in the variable context: Suppose
  we have $D;\Psi;\Gamma |- i : \tau$ for contexts $D, \Psi$ and
  $\Gamma$. Further suppose $\Gamma \subseteq \Gamma'$ -- then
  $D;\Psi;\Gamma' |- i : \tau$.
\end{lem}
\begin{rem}
  The notation $\Gamma \subseteq \Gamma'$ warrants some
  explanation. We say that the environment $\Gamma'$ is an
  \emph{extension} or \emph{augmentation} of $\Gamma$: If $\Gamma(x) =
  \tau$ then also $\Gamma'(s) = \tau$ for all $x \in \Gamma$. In
  addition, $\Gamma'$ might have variables which are not in the
  original $\Gamma$, and these are required to not shadow any existing
  variables. We note this is an accordance with the SSA property of
  Mini-LLVM/LLVM.
\end{rem}
\begin{proof}(Sketch)
  Since we have $D;\Psi;\Gamma |- i : \tau$ we know that $i$ can't use
  any variable but those in $\Gamma$ and those introduced in the
  typing derivation. If we systematically use $\alpha$-conversion, we
  can avoid capture of a new variable $y \not \in \Gamma$. Thus we can
  use $y$ in $\Gamma'$ extending it with one new name.

  Continuing this process, we can extend to the full $\Gamma'$.
\end{proof}
\begin{lem}
  \label{lem:weaken-psi}
  Instruction typing admits Basic Block weakening: if $D;\Psi;\Gamma
  |- i : \tau$ and $\Psi \subseteq \Psi'$ then $D;\Psi';\Gamma |- i :
  \tau$.
\end{lem}
\begin{proof}
  I have no idea on how to do this yet.\fixme{Get an idea on the weakening!}
\end{proof}
\section{Progress}
\fixme{Progress}

\section{Preservation}

We would like to prove the following theorem:
\begin{thm}
  \label{thm:preservation}
  If $|- P$ and $|- P --> P'$ then $|- P'$.
\end{thm}
To do that, we need a lemma:
\begin{lem}
  \label{thm:preservation-i}
  Suppose $D |- \Phi : D \;$, $\; D;\Psi;\Gamma |- i : \tau$ and $D;\Psi;\Gamma
  |- BB : \Psi$. In other words that definitions are wellformed, the
  instruction $i$ is well-typed and that the typing of basic blocks
  relates to the typing of the instructions. If then $\Phi;BB |- i ->
  i'$ it implies we have $D;\Psi;\Gamma |- i' : \tau$.
\end{lem}
\begin{proof}
  Induction on: $D;\Psi;\Gamma |- i -> i'$:\fixme{Many cases are
    currently missing}
  \begin{itemize}
  \item (Branch) If the step is of the form
    \begin{equation*}
    \inference{BB(bb) = Ks \quad Ks(k) = \lambda(x_1, \dotsc, x_n).i}{\Phi;BB |- \ibr{bb^k}{(c_1, \dotsc, c_n)} ->
      i(c_1, \dotsc, c_n)}
    \end{equation*}
    then we must have the following type derivation
    \begin{equation*}
    \inference{\Psi(bb) = BB\tau{}s \quad BB\tau{}s(k) : \tau_1 -> \tau_2 -> \dotsc ->
      \tau_n -> \tau\\
      c_1 : \tau_1 \quad c_2 : \tau_2 \quad \dotsb \quad c_n : \tau_n}
    {D;\Psi;\Gamma |- \ibr{bb^k}(c_1, c_2, \dotsc, c_n) : \tau}
    \end{equation*}
    The type of the basic block $bb$ is then $BB\tau{}s$. The $k$th
    projection must have type $\tau_1 -> \dotsc -> \tau_n ->
    \tau$. Now, by the helper-relation $D;\Psi;\Gamma |- BB : \Psi$,
    we have that $D;\Psi';\Gamma' \tpb \lambda(x_1, \dotsc, x_n).i :
    \tau_1 -> \dotsc -> \tau_n -> \tau$. Note that the contexts of
    variables and basic block definitions are different than those we
    want. But as $\Gamma' \subseteq \Gamma$ and $\Psi' \subseteq \Psi$
    we can utilize lemma \eqref{lem:weaken-gamma} and
    \eqref{lem:weaken-psi} to obtain a proof of $D;\Psi;\Gamma |- t :
    \tau$ as wanted.
    \item (Letrec step)
      \begin{rem}
        We use induction on the premise and note that we can extend
        $D;\Psi;\Gamma |- BB : \Psi$ properly so the IH can be
        applied.\fixme{Preservation needs much more work here}
      \end{rem}
  \end{itemize}
\end{proof}
\fixme{Rename ``Gamma'' in the Twelf code to something sensible}
\section{Determinism}
\fixme{Determinism}

\section{Twelf encoding}
\fixme{Write this section}

\chapter{Development Process}

\newcommand{\fskip}{\mathbf{skip}}
\newcommand{\fsemi}[2]{#1 \; ; \; #2}
\newcommand{\fcall}[1]{\mathbf{call} \; #1}
\newcommand{\fpgm}[2]{\mathbf{def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{center}
    Syntax:
  \end{center}
  \begin{align*}
    \text{Terms} \quad \ni t & ::= \fskip{} \bor \fsemi{t_1}{t_2} \bor
    \fcall{f}\\
    \text{Defs} \quad \ni \Phi & ::= \cdot \bor f = t, \Phi\\
    \text{Programs} \quad \ni P & ::= \fpgm{\Phi}{t}
  \end{align*}
  \begin{center}
    Semantics:
  \end{center}
  \begin{gather*}
    \boxed{\Phi |- t -> t'}\\
    \inference[S-Skip]{}{\Phi |- \fsemi{\fskip{}}{t} -> t}\\
    \inference[S-Semi]{\Phi |- t_1 -> t'_1}{\Phi |- \fsemi{t_1}{t_2}
      -> \fsemi{t'_1}{t_2}} \quad \quad
    \inference[S-Call]{\Phi(f) = t}{\Phi |- \fcall{f} -> t}\\
    \boxed{|- P --> P'}\\
    \inference[Pgm/]{\Phi |- t -> t'}{\fpgm{\Phi}{t} --> \fpgm{\Phi}{t'}}
  \end{gather*}
  \begin{center}
    Typing
  \end{center}
  \begin{gather*}
    \text{Fun types} \ni \Gamma ::= \cdot | f,\Gamma\\
    \text{Wellformed terms:} \; \boxed{\Gamma |- t}\\
    \inference[Wf-Skip]{}{\Gamma |- \fskip{}} \quad \quad
    \inference[Wf-Call]{f \in \Gamma}{\Gamma |- \fcall{f}}\\
    \inference[Wf-Semi]{\Gamma |- t_1 \quad \Gamma |- t_2}{\Gamma |-
      \fsemi{t_1}{t_2}}\\
    \text{Wellformed definitions:} \; \boxed{\Gamma |- \Phi :
      \Gamma'}\\
    \inference[WfD/z]{}{\Gamma |- \cdot : \cdot}\\
    \inference[WfD/s]{\Gamma |- t \quad f \not \in \Gamma' \quad
      \Gamma |- \Phi' : \Gamma'}{\Gamma |- f = t, \Phi' \; : \;
      f,\Gamma'}\\
    \text{Program typing:} \; \boxed{|- P}\\
    \inference{\Gamma |- \Phi : \Gamma \quad \Gamma |- t}{|- \fpgm{\Phi}{t}}
  \end{gather*}
  \caption{Toy language for function calls}
  \label{fig:func-call-lang}
\end{figure}

In this chapter, we describe the development process in the
project. Constructing formal semantics for an existing system by
discovering how it works contains several tripwires, booby traps and
some barbed wire. The crux of the problem is that syntax, types,
semantics and meta-theory fit together in an intricate network:
altering one of them may render the other parts invalid. Further
complication is added by LLVM: We cannot deviate too much from the
LLVM IL. Finally, we enforced ourselves to encode everything formally
in \twelf{}, which further complicates the task but also lifts it
above most formal work.

In practice, we needed to carry out several attempts in formalizing
Mini-LLVM before we arrived at the current formalization. In certain
ways even this formalization is incomplete; lacking any kind of memory
instructions and exceptions.

The formalization is built up from two simpler systems, both
formalized in \twelf{}. The first system is a first-order
functionally inspired language with the $\mathbf{letrec}$ as its most
prominent feature. The system helped us understand a way to formalize
mutually recursive functions in \twelf{}. We note that this already
exists\cite{twelfwiki:2007}, but we wanted to discover if it was
possible to define a variant based in intrinsic typing and
\twelf{}-contexts. It is then proven the system had the properties of
\emph{progress} and \emph{determinism}. The preservation-property was
obtained automatically by the intrinsic encoding: the step-relation in
\twelf{} is
\begin{verbatim}
step : tm T -> tm T -> type.
\end{verbatim}
stating that the step relation preserves the type directly. Thus
preservation is a built-in feature of the small-step relation.

The second system is presented in figure \ref{fig:func-call-lang}. It
is a small toy language for the function call semantics. It is
separately proven that this language has progress, preservation and
determinism and this result has been formalized in \twelf{}.

The Mini-LLVM formalization was then built by stratifying the first
language from (functional) terms into registers, constants, operations
and instructions syntactically; and then adding the second language on
top of it. The result is the Mini-LLVM formalization presented in this
report.

\chapter{Conclusion}

\paragraph{Summary}
\begin{itemize}
\item We present a formal semantics for Mini-LLVM, a subset of the
  LLVM IL language. We provide syntax, semantics and a type system for
  Mini-LLVM. We believe it can be used as a starting point for a
  formalization of the full LLVM syntax and semantics.
\item We encode the semantics in the logical framework \twelf{},
  utilizing HOAS and \emph{regular worlds} in the formalization where
  possible. We show that the encoding can correctly evaluate a small
  number of test programs.
\item We provide an alternative method by which to implement mutually
  recursive functions in \twelf{} for first-order languages in an
  intrinsically typed syntax.
\item We formulate and prove the meta-theoretic properties of
  \emph{progress} and \emph{determinism} in \twelf{}.
  \fixme{Preservation?}
\end{itemize}

The work should be of interest to anyone who work with the LLVM
system. It provides a key understanding on the basics of the language
and acts as a start for a EBNF grammar for LLVM (which is currently
lacking). In addition we have shown the strong similarity between a
first-order functional language and the LLVM IL. Hence, the work gives
another way to implement the syntax tree for LLVM in a compiler
front-end, before emitting IL instructions. We believe that the latter
part may be of practical use to compiler implementers seeking to use
LLVM in their work.

\paragraph{Further work}

Several extensions of the work are possible. We could extend the
formalization, incorporating more of LLVM. The memory heap would be
interesting to add; the most challenging part being the handling of
pointer arithmetic. A possible path would be to see if Separation
Logic\cite{reynolds:2002:separationlogic} can be used to understand
the heap.

Non-trivial control flow in the form of exceptions would also have to
be conquered. It would be interesting to analyze if a monadic solution
is feasible and reduces the complexity of the semantics.

\bibliography{biblio}
% State what the goals of this project is.
% State we focus on the operational semantics.
% State we will use Twelf where applicable if time allows.

\appendix
\chapter{Source code}
All source code are available either upon request from the author, or
by git revision control on github:
\url{http://github.com/jlouis/jlouis-tvm/tree/master/src/}. We note
that the final commit for the source is:\fixme{Update this commit it}
\begin{center}
  \texttt{cda8e7bb44a0168def492a313ff2d860db2d2889}.
\end{center}
Since this commit is an SHA-1 checksum, it is impossible for the
author to change the source after the deadline\footnote{If I on the
  contrary \emph{can} alter the source code, I have a paper to write
  in cryptography}.

\fixme{Find LNCS number for the POPLMark challenge paper}
\fixme{Include source code}
\section{Prelude}
\section{Prelude properties}
\section{Syntax}
\section{Semantics}
\section{Typing}
\section{Test code}
\section{Properties}
\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
