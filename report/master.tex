\documentclass[a4paper, oneside, 10pt, final]{memoir}

\chapterstyle{culver}
\RequirePackage[english]{jlouis}

\author{Jesper Louis Andersen\\jesper.louis.andersen@gmail.com\\140280-2029}
\title{Formalizing a Virtual Machine}
\date{December 4, 2009}

\newlength{\drop}
\newcommand*{\titleM}{\begingroup% Misericords, T&H p 153
  \drop = 0.08\textheight
  \centering
  {\Huge\bfseries Lambda}\\[\baselineskip]
  {\scshape IR of exsml}\\[\baselineskip]
  {\scshape by}\\[\baselineskip]
  {\large\scshape Jesper Louis Andersen\\jesper.louis.andersen@gmail.com}\par
  \endgroup}

\newcommand{\clang}{\textsc{Clang}}
\newcommand{\twelf}{\textsc{Twelf}}
\newcommand{\coq}{\textsc{Coq}}
\newcommand{\agda}{\textsc{Agda}}
\newcommand{\haskell}{\textsc{Haskell}}

\newcommand{\bottom}{\perp}
\bibliographystyle{plain}

\begin{document}
\listoffixmes{}
\maketitle{}
\begin{abstract}
  We present the language Mini-LLVM, an idealized subset of the IL
  language for the \emph{Low Level Virtual machine}(LLVM). From an
  informal LLVM-description, we give a formal account of the syntax,
  semantics, types and meta-theoretic properties of Mini-LLVM. We thus
  establish the --- to our knowledge --- first partial formalization
  of LLVM. Our formalization exploits the SSA-form requirement of the
  LLVM IL in a novel way to transform the IL into a functional
  representation. The representation and most of its meta-theoretic
  properties are encoded into the \twelf{} logical framework and we
  provide proof of \emph{progress}, \emph{preservation} and
  \emph{determinism} for well-typed programs. Finally, we show how
  small LLVM IL programs can be translated to our Mini-LLVM language
  and show that they agree on certain inputs --- making it plausible
  our Mini-LLVM is adequate.
\end{abstract}
\newpage{}
\tableofcontents{}
\newpage{}
\section{Foreword}
This report is meant to be read by people interested in the LLVM
compiler infrastructure. The goal from the beginning was to shed
light on the informal approach of LLVM. The basic premise was that
``if their system works, then it can be formalized'' -- though it
might prove very hard to do so.

The work was produced by trying to formalize smaller systems and then
stitch them together. On the large scale, numerous ``full restarts''
happened when something new was discovered that affected the complete
formalization. This report attempts to convey the final result, but it
omits thorough treatment of all the intermediate steps. Production of
formal systems is partially a learning experience: you keep working
with the system until you can treat the whole system in your head and
understand each part. Then, and only then, can you
present the system in its complete form.

In retrospect, it would probably have been advantageous to let
\twelf{} enter later in the process. The logical framework was used
from the very beginning, and that might have hampered development. The
logic is that if you are struggling with a proof, you do not want to
be struggling with \twelf{} at the same time.

Of course, since this is a learning process as well as a presentation,
it is very possible that the treatment contains errors and omissions
--- they are all mine and nobody else can be held responsible for
them. I am of the belief that you learn more by trying and failing
than by standing on secure ground all the way. This belief is
certainly true for the work herein: as a project you may question and
discuss its completeness; as a learning process it fulfilled
its goals.\\

\begin{flushright}
  Jesper Louis Andersen, December 2009.
\end{flushright}

\newpage{}
\chapter{Introduction}
\newcommand{\dom}[1]{\mathrm{dom}(#1)}
\newcommand{\lbl}[1]{l[#1]}
\newcommand{\lblp}[1]{l'[#1]}
It is well known in compiler construction, that intermediate languages
are a useful and beneficial abstraction\cite{appel:1998:modern,
  mogensen:2008:basics}. Rather than targeting the instruction set
architecture directly, the compiler constructor first targets an
intermediate language (IL). Then the IL and is afterwards compiled to
the target machines instruction set\footnote{Sans
  optimizations. Optimization is usually carried out on the IL as
  well}. Schematically, the phases can be described as:
\begin{equation*}
  L ->^{fe} IL ->^{be} Q
\end{equation*}
where $L$ is the source language; the arrow marked by $fe$ the
front-end compilation; and the arrow marked by $be$ is the back-end
compilation onto the machine language $Q$. The construction is
advantageous because the compiler writer can share either the
front-end among several back-ends or the back-end among several
front-ends.

An interesting idea is to have a software program, the \emph{Virtual
  Machine} (VM), handle the work of the backend. The front-end
targets the IL and packs it up for transfer as a binary format. This
format is usually called \emph{bytecode}. The VM then either
interprets the IL or just-in-time compiles before execution. From the
eagles perspective, the VM software acts as a machine able to directly
execute the VM code.

ILs are usually designed to make front-end construction easier. The IL
can specifically factor out details of the underlying machine thus
simplifying compiler implementation. As an example, most VMs carry out
register allocation and the programmer is given an abstraction: either
a stack or an infinite set of registers. Some VMs are designed with a
fairly broad IL intended to capture many different language types
while others are more constrained, often tied to a single intended
language. Examples of the former are the the .NET
CLR/CIL\cite{ecma:2006:335} the C-\ - language\cite{http:cminmin} and
the LLVM infrastructure \cite{lattner.ea:2009:llvm-ref}, while an
example of the latter is the Warren abstract
machine\cite{warren:1983:prolog}.

\section{LLVM}

This report concerns itself with a virtual machine named LLVM, the Low
Level Virtual Machine. It adopted this name because the LLVM IL is
close to an idealized assembly language with several convenient
differences of which we list some:
\begin{itemize}
\item All LLVM IL programs are statically typed. This rules out many
  common programming errors and fits well into compilation schemes
  where intermediate stage transforms are type-checked.
\item There is an infinite amount of registers and register allocation
  is carried out by the LLVM system.
\item Correct LLVM IL programs have the SSA-property: A variable has
  only one (static/syntactic) point in the program where it is
  \emph{defined}. All \emph{uses} of a variable must then be from this
  single static assignment. The usual $\phi$-node method is used to
  handle the case where control flow joins in the CFG.
\item LLVM has a built-in exception primitive.
\item LLVM is expected to carry out a large number of advanced
  optimizations on its IL with the intent of simplifying work for
  compiler writers.
\end{itemize}

However, one Achilles heel of the LLVM IL is the total lack of
formality. There is not even an EBNF of its grammar available and no
attempts have been made to define its semantics operationally.

In this report, we aim for a subset of the LLVM IL language and
provide a syntax description, an operational (small-step) semantics and a type
system. We seek to prove the system fulfills the usual meta-theoretical
properties of \emph{progress} and \emph{preservation} as well as
\emph{determinism}.

The state-of-the-art emphasized by the poplmark
challenge\cite{aydemir:2005:mechanizedmetatheory} is the encoding of
syntax, semantics and proofs into a proof assistant or logical
framework. The goal is that every computer scientific report is
accompanied by a formal proof written such that the computer can
verify its correctness. In this report we aim for this goal: every
formal description has been encoded into the logical framework of
\twelf{}\cite{schurmann.pfenning:1999:twelf} for verification.

\section{Report structure}

The report first introduces some preliminaries and then presents the
real work made in the following chapters: syntax, semantics and
meta-theory of our Mini-LLVM language is presented. It is expected
that the reader is familiar with operational semantics, proof theory
and machine verifiable proofs; in particular the \twelf{} logical
framework. It is also expected that the reader is familiar with
SSA-form and its implications (e.g., as found in
\cite[Chapter 19]{appel:1998:modern}).

\chapter{Design considerations}

In this section, we limit the scope of the formalization and present
the main design considerations before attempting to formalize the work.

\begin{figure}
\begin{verbatim}
if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return
return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0

\end{verbatim}
  \caption{An example LLVM fragment}
  \label{fig:llvm-example-1}
\end{figure}

Figure \ref{fig:llvm-example-1} contains an example of a typical LLVM
basic block. The example is code generated by the \clang{} C frontend,
which compiles C code to LLVM IL. It begins with a label, identifying
the block. Then a series of instructions follow and the block ends in
an unconditional branch to the label '\texttt{\%return}'. Local
definitions in LLVM are prefixed by a '\%' marker and global
(top-level) names by an '@' marker. The instructions \texttt{sub,
  call, } and \texttt{add} informally act like one would expect. Note
that the result are stored in registers named \texttt{\%sub},
\texttt{\%add}, and \texttt{\%call}. This is somewhat confusing and
using $r_1, r_2, \dotsc$ would probably have been simpler to
understand. But we keep the output of the \clang{} compiler as we will
return to it later.

The LLVM type system can be seen in the type designation \texttt{i32},
a 32-bit integer and finally, the '\texttt{nsw}' designation is a
LLVM-specific flag for integer wrap-around, which can be ignored.

In the basic block for the return, we first do a $\phi$-node
assignment. These assignments are required to be at the very top of a
basic block and transfer the value from the appropriate basic block
depending on the control flow. The '\texttt{ret}' instruction
returns. Note that this fragment has the SSA property.

Since we would like to represent LLVM in a machine checkable form in
\twelf{}, we utilize a result formulated explicitly by
Appel\cite{appel:1998:modern, appel:1998:ssa}: every SSA program has
an equivalent functional program. Thus our first design choice is to
represent the LLVM subset as a functional first order program to ease
its encoding in \twelf{}. As we shall see, the SSA-property of LLVM
programs greatly simplifies a number of otherwise complex interactions
in the semantics. Informally, we can transform a fragment
\label{llvm-consideration-let}
\begin{verbatim}
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  ...
\end{verbatim}
of two instructions following each other into the functional fragment:
\begin{verbatim}
  let %sub = sub i32 %n, 1
  in let %call = call i32 @tri(i32 %sub)
     in ...
\end{verbatim}

Note how the lexical scoping rules binds the '\texttt{\%sub}' value
in the correct scope.

We handle the basic blocks as Appel: each basic block becomes a
function with formal parameters the $\phi$-node variables. A branch to
a basic-block then tail-calls the function with the variables needing
transfer as parameters. In the example, we would have a function
\begin{verbatim}
return (%retval) =
   ret %retval
\end{verbatim}
for the return basic-block. And the branch to it would be
\begin{verbatim}
if.else (...) =
  ...
    br %return (%add)
\end{verbatim}
to designate that the value of '\texttt{\%add}' is the one that should
go to the first $\phi$-node.

In the paper of Appel\cite{appel:1998:ssa}, it is shown that a
lexically scoped functional form is superior to a more linear form in
which all basic blocks are introduced in the same scope. The lexical
scoping of basic blocks will let us represent programs in a more
convenient form, as is noted by the paper. We thus chose to deviate
from the LLVM IL in this respect, and follow the functional form closer.

\section{Extent of the formalization}

We limit the extent of the formalization to a small subset of
LLVM. First, we note the complete lack of any formal grammar for
the language means we have to begin from a clean slate. Thus,
establishing a small subset is more important as a first step towards
the goal.

We cut any heap-interaction. Specifically, we cut the ability to
load and store data to a heap. LLVM allows pointer arithmetic in the
heap which is hard to handle meta-theoretically. We also cut a large
number of operations that would be easy to add but don't provide
any further insight. Conversion operations are not going to be
considered, as they contain a potentially unsafe '\texttt{bitcast}'
operation. ``Aggregate'' and ``Vector'' operations are not going to be
considered (these include structs and arrays). Finally, we won't be
considering instructions handling exceptions.

While the list of omissions seems extensive, it is important to stress
that part of the task is to understand the subset that is left to a
level where it can be put into a formal system.

Under the course of development, we will use LLVM version 2.x. We
mention this because LLVM is only supposed to change in a backwards
compatible way as long as it remains a version 2.x.

\chapter{Syntax of Mini-LLVM}

\newcommand{\variables}{\mathrm{Variables}}
\newcommand{\BBlabels}{\mathrm{Labels}}
\newcommand{\tnat}{\mathbf{nat}}
\newcommand{\tbool}{\mathbf{bool}}
\newcommand{\types}{\mathrm{Types}}
\newcommand{\typelist}{\mathrm{Type lists}}
\newcommand{\bbtype}{\mathrm{Label Type}}
\newcommand{\ftype}{\mathrm{Fun Contexts}}
\newcommand{\tpenv}{\mathrm{Var Contexts}}
\newcommand{\bbenv}{\mathrm{Label Contexts}}
\newcommand{\bor}{\; \vert \;}
\newcommand{\ntypes}{\tau_1 \times \tau_2 \times \dotsb \times \tau_n}
\newcommand{\ntypesp}{\tau'_1 \times \tau'_2 \times \dotsb \times
  \tau'_n}
\newcommand{\ntypespp}{\tau_1 \times \tau_2 \times \dotsb \times \tau_{n'}}
In this and the following sections, we present the language
Mini-LLVM. Mini-LLVM is a subset of the LLVM IL in functionality ---
it takes a different approach with respect to SSA-form: Mini-LLVM is a
first order functional language whereas the LLVM IL is an imperative
SSA-form. A functional form is expected to be easier to work with,
formally -- especially in the logical framework \twelf{}.

In the present section, we present the syntax of Mini-LLVM in a formal BNF
grammar. We also describe the type system as well as the basic domains
from which we draw values.

\section{Domains}


\newcommand{\numbers}{\mathrm{Numbers}}
\newcommand{\booleans}{\mathrm{Booleans}}
\newcommand{\funlabels}{\mathrm{Function\; labels}}
\newcommand{\nat}{n}
\newcommand{\bool}{b}
\newcommand{\BB}{\mathbb{B}}
\newcommand{\btrue}{\mathbf{True}}
\newcommand{\bfalse}{\mathbf{False}}
\newcommand{\dbundle}{(d_1, d_2, \dotsc, d_m)}
\newcommand{\sbundle}{(\sigma_1, \sigma_2, \dotsc, \sigma_m)}
\newcommand{\bbtypes}{\sbundle}

Our language will be using several syntactic terminal domains, the
existence of which we assume (figure \ref{fig:syntactic-domains}). We
have variables, $x_1, x_2, \dotsc$ used for naming and discriminating
registers from each others. For simplicity we restrict the language to
natural numbers only. This restriction is due to \twelf{}: we need to
encode the system of numbers and Peano-style natural numbers are
fairly simple to work with and handle. Verification in other systems
might have chosen another domain. We only utilize basic properties of
arithmetic in our verification, hence it might be possible to change
this later on.
\begin{figure}
  \begin{align*}
    \numbers \ni \NN, \nat & ::= 0 \bor 1 \bor 2 \bor \dotsc\\
    \booleans \ni \BB, \bool & ::= \btrue \bor \bfalse \\
    \BBlabels \ni l & ::= l_1, l_2, l_3, \dotsc \\
    \funlabels \ni f & ::= f_1,f_2,f_3,\dotsc
  \end{align*}
  \caption{Syntactic domains}
  \label{fig:syntactic-domains}
\end{figure}

Boolean values are either the true value or the false
value. Internally these are encoded as the natural numbers $0$ and
$1$, but the type system is intended to restrict the use to these
values only. In the LLVM IL, an integer variable is typed as its
bit-size, so \texttt{i32} is a 32-bit integer. The special case
\texttt{i1} designate a boolean variable with values 0 or 1. Our
Mini-LLVM language model this by the above construction. Finally, we
assume a set of Basic Block label names and a set of function
names. These are used to refer to groups of basic blocks and
functions, respectively.

In the course of development, we started with a language more closely
resembling a functional language and then gradually stratified the
syntactic classes until it matched that of LLVM as much as
possible. Being an imperative language, LLVM resembles the usual
imperative construction with statements and expressions as stratified
syntactical classes.

Of course, since LLVM has no formal description and the informal
description lacks precision\cite{lattner.ea:2009:llvm-ref}, we run the
risk of having mistaken something in the definition. To mitigate this
risk somewhat, we also used the current LLVM system as a source by
studying and analyzing compiler output from various compilers
targeting LLVM; in particular, the \clang{}-project was used.

\newcommand{\registers}{\mathrm{Registers}}
\newcommand{\constants}{\mathrm{Constants}}
\newcommand{\operations}{\mathrm{Operations}}
\newcommand{\instructions}{\mathrm{Instructions}}
\newcommand{\programs}{\mathrm{Programs}}
\newcommand{\definitions}{\mathrm{Definitions}}
\newcommand{\basicblocks}{\mathrm{Basic Blocks}}
\newcommand{\iret}[1]{\mathbf{ret} \; #1}

\newcommand{\ibr}[2]{\mathbf{br} \; #1 \; #2}
\newcommand{\ibrc}[5]{\mathbf{brc} \; #1 \; #2 \; #3 \; #4 \; #5}
\newcommand{\ilet}[3]{\mathbf{let} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\iletrec}[3]{\mathbf{letrec} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\ido}[3]{\mathbf{do} \; #1 = #2 \; \mathbf{in} \; #3}
\newcommand{\icall}[4]{\mathbf{call} \; #1 = #2 #3\; \mathbf{in} \;
  #4}
\newcommand{\ipgm}[2]{\mathbf{Def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{align*}
    \registers \ni r & ::= x_1, x_2, x_3, \dotsc\\
    \constants \ni c & ::= \; r \bor \nat \bor \bool \\
    \operations \ni op & ::= c \\
                       & \bor \quad c + c \\
                       & \bor \quad c - c \\
                       & \bor \quad c < c \\
   \basicblocks \ni d  & ::= \lambda (x_1, x_2, \cdots, x_n) . s\\
   \instructions \ni s & ::= \iret{c} \\
                       & \bor \quad \ibr{\lbl{k}}{(c_1, \dotsc, c_n)} \\
                       & \bor \quad \ibrc{c}{\lbl{k}}{(c_1, \dotsc, c_n)}{\lbl{{k'}}}{(c'_1, \dotsc, c'_{n'})}\\
                       & \bor \quad \ilet{x}{op}{s} \\
                       & \bor \quad \iletrec{l}{\dbundle}{s} \\
                       & \bor \quad \ido{x}{s_1}{s_2} &
                       (\text{Internal})\\
                       & \bor \quad \icall{x}{f}{(c_1, \dotsc,
                         c_n)}{s}\\
    \definitions \ni D & ::= \cdot \bor (f(x_1, \dotsc, x_n) = s, D)\\
    \programs \ni p & ::= \ipgm{D}{s}
  \end{align*}
  \caption{Syntax}
  \label{fig:syntax}
\end{figure}

\section{Main syntax}

In figure \ref{fig:syntax} we present the complete syntax for the
Mini-LLVM language. The atomic expressions of the language are exactly
registers, natural numbers and boolean values. The language has three
primitive operations, namely $c + c$, $c - c$ and $c < c$. Of these,
the latter returns a boolean value, whereas the first two return
natural numbers. The '$-$' operation is defined such that if $y \geq
x$ then $x - y = 0$.

Instructions form the main part of Mini-LLVM. The instruction
$\iret{c}$ represents returning a value from a function. It models the
LLVM '\texttt{ret}' instruction.

Basic blocks are introduced with the $\iletrec{l}{\dbundle}{s}$
notation. This simultaneously binds the definitions $d_1$ through
$d_m$ of basic blocks to the name $l$. Note each definition will take
formal parameters for its $\phi$-nodes. The name $l$ will be
available in the context of the instruction $s$. We will often in the
following call a basic block mapping $l \mapsto \dbundle$
for a Basic block \emph{bundle}.

The instruction $\ibr{\lbl{k}}{(c_1, \dotsc, c_n)}$ designates an
unconditional branch to the $k$th projection in the basic block bundle
represented by the name $l$. The parameters $c_1$ through $c_n$ are
formal $\phi$-node parameters to the given basic block. In LLVM, the
projections are named explicitly by identifier names, but we felt that
a projection is easier to handle from a formal viewpoint.

The $\ibrc{x}{\lbl{k}}{(c_1, \dotsc, c_n)}{\lbl{{k'}}}{(c_1, \dotsc, c_n)'}$ represents a conditional
branch. It will, depending on the value of $x$ transfer control to
either the first or second basic block projection, injecting the
corresponding set of $\phi$-node parameters. In LLVM both
branch-instructions are called '\texttt{br}' -- the syntactical
difference discriminates them.

As noted in the design considerations, we represent a sequential chain
of operations as a chain of let-style-bindings. Thus the
$\ilet{x}{op}{s}$ instruction represents sequential execution. An
operation is executed and its result is placed into the register
$x$. The register is then available in the $s$ instructions.

The $\ido{x}{s_1}{s_2}$ instruction is not meant to be present in
initial Mini-LLVM programs. It is used internally to keep the context
of a function call around. This has to do with the fact that the
formalization lacks a stack and thus uses the current continuation
context to keep track of where the computation came from. Function
calls utilize the instruction while they are executing.

Finally the $\icall{x}{f}{(c_1, \dotsc, c_n)}{s}$ instruction
represents an LLVM '\texttt{call}' instruction in a very simplified
way. In LLVM it is possible to annotate the call-instruction with a
large number of hints. These hints are used to handle calling
conventions, tall-call applicability, etc., but we omit them in our
formalization because we do not attempt to formalize these aspects of
LLVM. The instruction will call the $f$ function with parameters $c_1$
through $c_n$ returning the result in the $r$ register. The result
will be available in the $s$ instructions. Thus a function call acts
like a special variant of a let-binding.

\paragraph{Programs}

A Mini-LLVM program is a list of definitions $D$ together with an
initial instruction $s$. The notation is $\ipgm{D}{s}$. Usually, we
expect the program to begin by calling a main-function in the list of
definitions, but we have chosen to deviate from LLVM here and allow
the execution of an arbitrary instruction rather a call to main. We
can simply limit valid programs to begin by a forced instruction
call to a function ``\texttt{main}'', should we so desire.

\paragraph{Function types}

Mini-LLVM deviates from LLVM in the introduction of functions and
their types. In LLVM a function is typed explicitly, so each parameter
is annotated with a type; in addition to the function return type. Our
system allows any valid typing for a function that fulfills the type
system. In hindsight, this was probably the wrong decision -- we
should have typed functions explicitly to follow the LLVM IL closer.

\paragraph{Free variables and fresh names}
\newcommand{\fv}{\mathrm{FV}}
We define a function $\fv(s)$ which returns the set of free variables
for a given instruction $s$. The function is defined inductively in
the obvious way and is ``overloaded'' for operations and register
lookups.

For any class of names, we assume we can generate a new unique fresh
name which has not been used before.

\paragraph{A remark on lists}

Lists of definitions, $D$ is defined to be either the empty list
$\cdot$ or a ``cons'' by $k \mapsto v,D'$ for some key/value pair
$k,v$. We will be introducing several list-like definitions of this
form. Hence, we will handle them once and for all. Since they are
list-like, we can handle them on a case-by-case analysis -- and we
will do so extensively in the formalization. We treat $D$ as
a partial function and write $D(k) = v$ for the search through the
list-like construction on an element-by-element basis and obtaining
$v$. In particular, if $D(k) = v$ then $k$ must be in the domain of
$D$ and lookup succeeded.

\chapter{Mini-LLVM type system}
\label{chap:type-system}

In this chapter we describe a type system for our Mini-LLVM
language. That we need a type system should be clear: our syntax
allows programs which can get stuck and we want a type system to
constrain programs.

\paragraph{Type Domains} The language employs a simple type system as in
figure \ref{fig:type-system}. There are two primitive base types,
natural numbers and boolean values. For handling passing of parameters
between basic blocks via $\phi$-nodes, there is a $\bbtype$
designation stating a (possibly empty) list of formal parameters. We
notate such lists as $\ntypes -> \bullet$ where the last
``$\bullet$'' states that it is a function but without return type.
The choice of two primitive types is deliberate. It is the simplest
non-trivial choice of types possible. Had there only been one base
type, all typing degenerates into questions on type arity in basic
block definitions.

\begin{figure}
  \begin{align*}
    \types \ni \tau & ::= \tnat \bor \tbool \\
    \bbtype \ni \sigma   & ::= \ntypes -> \bullet\\
    \ftype \ni \Phi & ::= \cdot \bor f \mapsto (\ntypes -> \tau), \Phi \\
    \tpenv \ni \Gamma & ::= \cdot \bor x \mapsto \tau,\Gamma\\
    \bbenv \ni \Psi   & ::= \cdot \bor l \mapsto \bbtypes,\Psi
  \end{align*}
  \caption{Type system}
  \label{fig:type-system}
\end{figure}

\newcommand{\tpr}{|-_{\mathrm{r}}}
\newcommand{\tpc}{|-_{\mathrm{c}}}
\newcommand{\tpop}{|-_{\mathrm{o}}}
\newcommand{\tpb}{|-_{\mathrm{b}}}

\begin{figure}
  \begin{gather*}
    \text{Registers:} \quad \boxed{\Gamma \tpr x : \tau}\\
    \inference[TpR]{\Gamma(x) = \tau}{\Gamma \tpr x : \tau}
  \end{gather*}
  \begin{gather*}
    \text{Constants:} \quad \boxed{\Gamma \tpc c : \tau}\\
    \inference[TpC-Reg]{\Gamma \tpr x}{\Gamma \tpc x : \tau}\\
    \inference[TpC-Nat]{}{\Gamma \tpc n : \tnat} \quad
    \inference[TpC-Bool]{}{\Gamma \tpc b : \tbool}
  \end{gather*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{\Gamma \tpop o : \tau} \\
    \inference[TpOp-Cst]{\Gamma \tpc c : \tau}{\Gamma \tpop c : \tau}\\\\
    \inference[TpOp-Plus]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 + c_2 : \tnat} \quad
    \inference[TpOp-Mone]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 - c_2 : \tnat}\\\\
    \inference[TpOp-Lt]{\Gamma \tpc c_1 : \tnat \quad \Gamma
      \tpc c_2 : \tnat}{\Gamma \tpop c_1 < c_2 : \tbool}
  \end{gather*}
  \caption{Typing 1}
  \label{fig:type-judgement-1}
\end{figure}

To take care of these problems, we need a type system ruling out these
possibilities in the syntax. In figure \ref{fig:type-judgement-1}, we
present typing relations for registers, constants and
operations. Register typing is simply handled by a judgment form
$\boxed{\Gamma \tpr x}$ with a single rule, TpR, for lookup into the
environment. The judgement form $\boxed{\Gamma \tpc c : \tau}$ states
that in the environment of $\Gamma$ the constant $c$ has type
$\tau$. There are 3 different cases, one for register lookup, and two
for each of the constant types.

The judgment form for operations is $\boxed{\Gamma \tpop o :
  \tau}$. Under the environment of $\Gamma$ the operation $o$ has
type $\tau$. These rules are rather straightforward.

\newcommand{\btype}{\ntypes -> \bullet}
\begin{figure}
  \begin{gather*}
    \text{Basic block Definitions:} \quad \boxed{\Phi;\Psi;\Gamma \tpb d
      : \sigma / \tau}\\
    \inference[BB-Def]{\Phi;\Psi;\Gamma[x_1 \mapsto \tau_1 \dotsb x_n
      \mapsto \tau_n] |- s :
  \tau}{\Phi;\Psi;\Gamma \tpb \lambda(x_1, x_2, \dotsc,
      x_n).s : (\ntypes -> \bullet) / \tau}
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{\Phi ; \Psi ; \Gamma |- s : \tau}\\\\
    \inference[Tp-ret]{\Gamma \tpc c : \tau}{\Phi ; \Psi ;
      \Gamma |- \iret{c} : \tau} \quad
    \inference[Tp-let]{\Gamma \tpop o : \tau_1 \quad \Phi ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- s : \tau}{\Phi ; \Psi ; \Gamma |-
      \ilet{x}{o}{s} : \tau}\\\\
    \inference[Tp-do]{\Phi;\cdot;\cdot |- s_1 : \tau_1 \quad
      \Phi;\Psi;\Gamma[x \mapsto \tau_1] |- s_2 : \tau} {\Phi;\Psi;\Gamma |-
      \ido{x}{s_1}{s_2} : \tau}\\\\
    \inference[Tp-br]{\Psi(l) = \bbtypes{} \quad \sigma_k = \ntypes -> \bullet\\
      \Gamma |- c_1 : \tau_1 \quad \Gamma |- c_2 : \tau_2 \quad \dotsb
      \quad \Gamma |- c_n : \tau_n}
    {\Phi;\Psi;\Gamma |- \ibr{\lbl{k}}(c_1, c_2, \dotsc, c_n) : \tau}\\\\
    \inference[Tp-brc]{\Gamma \tpc x : \tbool\\
      \Psi(l) = \bbtypes{}\\
      \sigma_k = \ntypes -> \bullet\\
      \Gamma |- c_1 : \tau_1 \quad \dotsb \quad \Gamma |- c_n :
      \tau_n\\
      \sigma_{k'} = \ntypesp -> \bullet\\
      \Gamma |- c'_1 : \tau'_1 \quad \dotsb \quad \Gamma |- c'_n :
      \tau'_n}
    {\Phi;\Psi;\Gamma |- \ibrc{x}{\lbl{k}}{(c_1, \dotsc,
        c_n)}{\lbl{{k'}}}{(c'_1, \dotsc, c'_{n'})} : \tau}\\\\
    \inference[Tp-letrec]{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb
      d_1 : \sigma_1 / \tau\\
      \vdots\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m / \tau\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- s : \tau}
       {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{s} : \tau}(l \not
       \in \dom{\Psi})\\\\
    \inference[Tp-call]{\Phi(f) = \ntypes -> \tau'\\
      \Gamma |- c_1 : \tau_1 \quad \dotsb \quad \Gamma |- c_n : \tau_n\\
  \Phi;\Psi;\Gamma[x \mapsto \tau'] |- s : \tau}
  {\Phi;\Psi;\Gamma |- \icall{x}{f}{(c_1, \dotsc, c_n)}{s} : \tau}
  \end{gather*}
  \caption{Typing 2}
  \label{fig:type-judgement-2}
\end{figure}

\newcommand{\ftypeone}{\ntypes -> \tau_1}
\newcommand{\ftypez}{\ntypes -> \tau}

In figure \ref{fig:type-judgement-2} we present the typing relations
for instructions. Basic blocks are typed by the judgement
$\boxed{\Phi;\Psi;\Gamma \tpb d : \sigma / \tau}$. This form states
that a basic block definition $d$ has the basic block type $\sigma$
and any returns occurring in it has type $\tau$. This under the
mentioned contexts for functions, basic blocks and variables.

The general judgment for these is $\boxed{\Phi;\Psi;\Gamma |- s :
  \tau}$. This specifies that the instruction $s$ has a type of $\tau$
in the environment of
$\Phi;\Psi;\Gamma$. % Do not explain it. It should be clear!

An instruction of the form $\iret{c}$ has type $\tau$ if the constant
it returns has. Correct typing of an $\ilet{x}{o}{s}$ instruction
requires that the operation $o$ returns the same type as is used for
the register $x$ in the body $s$.

The rule Tp-do defines a typing of a $\ido{x}{s_1}{s_2}$
instruction. The type of $s_1$ must the the same type as used in
$s_2$. Note the similarity between this instruction and the
let-binding above.

Unconditional branches are handled by the Tp-br rule. It states that a
well-typed branch can look up the basic block in the environment of
basic blocks and then take the $k$th projection of this to obtain the
type $\ntypes -> \bullet$. We are not interested in the return value
of a branch here. We check them in the Tp-letrec rule described later.

Conditional branches are well-typed if each path regarded as
unconditional branches are. Furthermore we require the branch variable
to be a boolean value.

The Tp-letrec rule introduces basic blocks. It first checks that each
basic block definition is well-typed. Then it type checks the body $s$
under an augmented environment where a mapping to the basic block
identifier has been made. The rule also ensures type agreement of all the basic
blocks containing a return instruction of the form $\iret{c}$.

Finally, function calls are well-typed if we can look up the function
identifier in the function environment $\Phi$; and can show the
passed arguments obeys the type scheme.

\section{Programs}
\begin{figure}
  \begin{gather*}
    \text{Definition Wellformedness:} \quad \boxed{\Phi |- D : \Phi'}\\\\
    \inference[Wf-defs/z]{}{\Phi |- \cdot : \cdot}\\\\
    \inference[Wf-defs/s]{\Phi |- D' : \Phi'' \quad \Phi;\cdot;[x_1 \mapsto
      \tau_1 \; \dotsb \; x_n \mapsto \tau_n] |- s :
      \tau \quad f \not \in \dom{\Phi'}}{\Phi |- (f(x_1, \dotsc, x_n) = s, D') : (f \mapsto \ntypes -> \tau, \Phi'')}
  \end{gather*}
  \begin{gather*}
    \text{Program Wellformedness:} \quad \quad \boxed{|- P}\\\\
    \inference[WF-Pgm]{\Phi |- D : \Phi \quad \Phi;\cdot;\cdot |- s}{|- \ipgm{D}{s}}
  \end{gather*}
  \caption{Typing 3}
  \label{fig:type-judgement-3}
\end{figure}

A program is well-formed (figure \ref{fig:type-judgement-3}) if it
obeys a wellformedness criterion $\boxed{\Phi |- D : \Phi}$ on its
definitions $\Phi$ and that the body is wellformed in empty Basic
block and variable environments. We write $\boxed{|- P}$ for
well-formed programs.

The criterion for definition blocks examines wellformedness of the
list of definitions. If the definition list is empty, then the
function environment has to be as well. Each function must be
wellformed with respect to its formal parameters and the full
environment $\Phi$. We furthermore require that the function identifier
does not occur twice with the premise $f \not \in \dom{\Phi'}$.

Note that the premise $\Phi |- D : \Phi$ ties the knot on function
definitions. The function environment $\Phi$ is being examined while it
is being built at the same time.

% The judgement $\boxed{\Phi;\Psi;\Gamma |- L : \Psi'}$ is used to state
% that a basic block relates to its context. We will use this in the
% proof of \emph{preservation}, to maintain the relationship. The idea
% is that if a basic-block environment is well-formed, all the
% definitions must be.


\chapter{Mini-LLVM Semantics}

In this chapter we present the Mini-LLVM semantics (see figure
\ref{fig:semantics}). We chose to implement the semantics as a
small-step operational semantics. A small-step operational semantics
is fairly easy to reason about when proving the meta-theoretic
properties of \emph{preservation} and \emph{progress}. Furthermore, it
follows the style used in \cite{pierce:2002:types}.

\paragraph{Step relation for operations}

\newcommand{\eop}{=>_{o}} For operations, $\boxed{|- o \eop n}$ is the
judgement form. The form state that the operation $op$ evaluate to a
value of $n$. This might look like a big-step semantics, but note that
all operations are \emph{primitive} in Mini-LLVM: An operation is
limited by the syntax such that it cannot be an arbitrary tree. This
is also the reason we chose the operation as a name rather than the
more common \emph{expressions}.

For each possible operator, there is a corresponding inference
rule. Each of these simply unwrap underlying integers and then applies
the proper mathematical arithmetic operation.
\newcommand{\meval}{:=}
\begin{figure}
  \begin{align*}
    \text{Definitions:} \ni D & ::= \cdot \bor (f(x_1, x_2, \dotsc,
    x_l) = s, D)\\
    \text{Basic Blocks:} \ni L & ::= \cdot \bor (l \mapsto \dbundle),L
  \end{align*}
  \begin{gather*}
    \text{Operations:} \quad \boxed{|- o \eop n}\\
    \inference[E-Plus]{}{|- n_1 + n_2 \eop n}(n \meval n_1 + n_2)
    \quad \quad
    \inference[E-Mone]{}{|- n_1 - n_2 \eop n}(n \meval n_1 - n_2)\\\\
    \inference[E-Lt-T]{}{|- n_1  < n_2 \eop \btrue}(n_1 < n_2) \quad \quad
    \inference[E-Lt-F]{}{|- n_1  < n_2 \eop \bfalse}(n_1 \geq n_2)
  \end{gather*}
  \begin{gather*}
    \text{Instructions:} \quad \boxed{D;L |- s -> s'}\\
    \inference[S-let]{|- o \eop c}{D;L |- \ilet{x}{o}{s} -> s[c/x]}\\\\
    \inference[S-letrec-v]{}{D;L |- \iletrec{l}{\dbundle}
      {\iret{c}} -> \iret{c}}\\\\
    \inference[S-letrec-s]{D;L[l \mapsto \dbundle] |- s -> s'}
    {D;L |- \iletrec{l}{\dbundle}{s} -> \iletrec{l}{\dbundle}{s'}}(l \not \in \dom{L})\\\\
    \inference[S-brc-t]{}{D;L |-
      \ibrc{\btrue}{\lbl{k}}{(c_1, \dotsc, c_n)}{\lblp{k'}}{(c'_1, \dotsc,
        c'_{n'})} -> \ibr{\lbl{k}}{(c_1, \dotsc, c_n)}}\\\\
    \inference[S-brc-f]{}{D;L |-
      \ibrc{\bfalse}{\lbl{k}}{(c_1, \dotsc, c_n)}{\lbl{{k'}}}{(c'_1, \dotsc, c'_n)} ->
      \ibr{\lbl{{k'}}}{(c'_1, \dotsc, c'_n)}}\\\\
    \inference[S-do-s]{D;L |- s_1 -> s'_1}{D;L |-
      \ido{x}{s_1}{s_2} -> \ido{x}{s'_1}{s_2}}\\\\
    \inference[S-do-v]{}{D;L |- \ido{x}{\iret{c}}{s_2} -> s_2[c/x]}\\\\
    \inference[S-call]{D(f) = (\;f(x_1, x_2, \dotsc, x_n) = s'\;)}{D;L |-
      \icall{x}{f}{(c_1, c_2, \dotsc, c_n)}{s} -> \ido{x}{s'[c_1/x_1, c_2/x_2,
        \dotsc, c_n/x_n]}{s}}\\\\
    \inference[S-br]{L(l) = \dbundle \quad d_k = \lambda(x_1, \dotsc,
      x_n).s}{D;L |- \ibr{\lbl{k}}{(c_1, \dotsc, c_n)} -> s[c_1/x_1, \dotsc, c_n/x_n]}
 \end{gather*}
 \begin{gather*}
   \text{Programs:} \quad \boxed{|- P --> P'}\\
   \inference[SP]{D;\cdot |- s -> s'}{\ipgm{D}{s} --> \ipgm{D}{s'}}
 \end{gather*}
  \caption{Semantics}
  \label{fig:semantics}
\end{figure}

\paragraph{Step relation for instructions}

Instructions is by far the most complex in this system. To describe
these, we need to describe two new classes: definitions and basic
blocks. Definitions, notated as $D$, is a list of function
definitions. Basic blocks, notated as $L$, is a mapping from a basic
block name to a tuple of basic blocks. Instructions have the
judgment form $\boxed{D;L |- s -> s'}$, where definitions and basic
blocks are contextual.

In the semantics, we use the notation $s[c/x]$. This means that you
substitute all occurrences of $x$ with $c$ in the syntax tree of
$s$.

The basic sequential operation in LLVM is handled by the
$\ilet{x}{o}{s}$ instruction in Mini-LLVM. As already noted in
\ref{llvm-consideration-let}, we translate sequences of instructions
into nested applications of $\mathbf{let}$s. To execute an operation,
$o$, is to know the contents of the register $x$. Since we have the
SSA-property and the SSA/FP correspondence, we can then just propagate
the value of $x$ to all its uses directly. This is done by
substituting the result for $x$ in the body of the let, $s$.

Evaluation of an instruction $\iletrec{l}{\dbundle}{s}$ progresses
depending on the structure of $s$. If $s$ is of the form $\iret{c}$,
then there is no reference to the basic blocks, and we can get rid of
them. This is done with the S-letrec-v rule. Otherwise, the S-letrec-s
rule introduces all the basic blocks into the context at once;
followed by a step underneath.  In effect, the body of a
$\mathbf{letrec}$ can act as the scratch-pad for the execution of
basic blocks and be replaced with a new basic block from the context.

Conditional branches examine the boolean value and then step into an
unconditional branch of the right kind. Unconditional branches, the
S-br rule first looks up the appropriate basic block in the
environment; then it applies the $k$th projection to get at the
correct basic block. Finally, it resolves the contents of the
$\phi$-nodes by substitution --- again exploiting the SSA/FP
correspondence.

The $\ido{x}{s_1}{s_2}$ instruction is equivalent to a normal
let-construction in a (monadic) lambda-calculus. It reduces $s_1$ via the
rule S-do-s until it becomes a canonical value (i.e., a $\iret{c}$);
then applies the rule S-do-v to push down the value of $x$ into the
body $s_2$.

Finally, function calls are handled by the S-call inference rule. We
look up the definition of the function call in the function
context. Then we step into a $\mathbf{do}$ instruction. Thus, we will
use the $\mathbf{do}$ as a scratchpad for the function evaluation.

\paragraph{Step relation for programs}

A Program steps by the form $\boxed{|- P --> P'}$. It simply
introduces the definitions in the context so they are callable from
the body.

\chapter{Twelf encoding}
We now seek to encode the syntax and semantics in Twelf. When
encoding, we must make certain choices along the way. Almost any
operational semantics will omit specific parts --- in the name of
notational simplicity. The encoding needs to take care of this
explicitly, however.

\paragraph{Extrinsic vs. Intrinsic encoding}

When we specify a syntax as an abstract syntax tree in a language like
ML, we usually do so by virtue of an algebraic data type. This syntax
description allows us to write down some \emph{illegal} programs:
certain syntax trees will get stuck under evaluation. A typing
relation then constrains the syntax trees such that only well-typed
programs are allowed. When the typing relation stands next to the
syntax description, we say that the encoding is \emph{extrinsic}.

In contrast, if the programming language has access to Generalized
algebraic data-types (GADTs) or dependent types, we might define the
syntax in way that rejects ill-typed programs directly. This encoding
form, called \emph{intrinsic} encoding, is possible in \twelf{},
\coq{}, \agda{}, and to a certain extent \haskell{}.

Intrinsic encodings have their limitations however. The typing
relation must be static in the sense that it must be driven by the
syntactical rules alone. An extrinsic encoding on the contrary can use
any computable function. This might make the
intrinsic encoding impossible for some typing relations.

In our work, we sought to achieve an intrinsic encoding of as much of
the semantics as possible. Thus we aimed for an intrinsic encoding of
instructions, but adopted an extrinsic encoding for function
definitions and programs.

\section{The Prelude}

The prelude contains various helper-relations for use in the real
formalization. In other proof systems (e.g., \coq{}\cite{team:coq*1}),
these are already present in a standard library, but for \twelf{} we
are forced to code them by hand.

We encode the boolean values and Peano style natural numbers along with
operations on these. As examples, we encode arithmetic operations and
predicates for equality and non-equality.

\paragraph{properties}

Since we want to use properties of the prelude in meta-theory, we must
prove that the properties are true. In the following, we present some
example properties from the prelude:
\begin{lem}
  Suppose we have two natural numbers $n_1, n_2 \in \NN$. Then there
  exists an $n_3 \in \NN$ such that $n_1 + n_2 = n_3$.
\end{lem}
\begin{proof}
  Induction on $n_1$: If $n_1$ is $0$ then take $n_3 =
  n_2$. Otherwise, $n_1 = n'_1 + 1$. We now apply the induction
  hypothesis to obtain an $n'_3$ with $n'_1 + n_2 = n'_3$. To this, we
  can use the rule $n'_1 + 1 + n_2 = n'_3 + 1$ which is valid given
  our definition of plus. This gives the existence of an $n_3 = n'_3 +
  1$.
\end{proof}

Lemmas of this form is very common in \twelf{} signatures. They are
called \emph{effectiveness} lemmas and are usually named with a
\texttt{can-} prefix as in \texttt{can-nat-plus} and
\texttt{can-step-op}. They build a bridge between a pure syntactical
object and an accompanying relation on the object.

Another very common \twelf{} proof is reasoning from false. We have a
special type family defined, \texttt{void}, with no constructors
whatsoever. This can be used to prove absurd statements. For example
\begin{lem}
  Let $n_1$ and $n_2$ be natural numbers. Then $n_1 = n_2 \land n_1
  \neq n_2 \implies \bottom$.
\end{lem}

We can reason anything from \texttt{void} because void has no valid
constructors. Thus the sentence $\forall v \in \texttt{void} \; . \; \exists
E$ for any $E$ is vacuously true since there is no way the $v$ can be
inhabited.

\section{Syntax encoding}

We would like to use an intrinsic encoding for as much of the syntax
as possible. We would also like to use a for \twelf{} classic method
w.r.t. encoding variables, named \emph{higher order abstract syntax}
(HOAS). With HOAS, we use an LF-binding to represent a variable in the
object language we are encoding. We can use this method to represent
the registers of the language in the constants. In effect, execution
of the semantics will mean that when a register is \emph{defined} we
immediately ``push'' its value to all of its \emph{uses} by
substitution. Since our system is also intrinsic, we let a be a family
of types:
\begin{verbatim}
cst : tp -> type.
\end{verbatim}
In the same vein, we can define operations and instructions to be
bearing their types. For an instruction, its type is the type of a
return value.

This methodology is used to merge part of the typing relation into the
language syntax, directly handling the type in the syntax.

\paragraph{Handling basic blocks}

A complication with an intrinsic typing is how to type basic blocks. A
basic block is essentially a list of definitions $d_1, d_2, \dotsc,
d_n$, with each definition of the form $\lambda (x_1, \dotsc,
x_n).s$. The latter can be represented by a standard \twelf{}-HOAS-trick:
If $i$ is the syntax tree of the function body, we represent the
$\phi$-variable by wrapping the syntax tree in an LF-lambda: $\lambda
(x : \texttt{reg t}) . s$, where $x$ might be bound in $s$. Thus,
substitution is LF-application. By successively wrapping once for each
$x_i$ variable, we obtain a definition $d$. Since the typing is
intrinsic, we let each wrapping book-keep the typing.

We use lists of definitions to encode $\dbundle$. But when we build up
the list, we also intrinsically keep track of the types of each $d_k$.

We wish to handle such definitions by \twelf{} regular worlds. Hence,
we have an type family
\begin{verbatim}
bname : bb-tp -> type.
\end{verbatim}
where \texttt{bb-tp} is the type of definition lists. We use that to
introduce a new $bname$ into the context when stepping under a
$\mathbf{letrec}$ instruction:
\begin{verbatim}
step/letrec-s :
    step D (insn/letrec ([pb] Defs pb) ([pb] Body pb))
           (insn/letrec ([pb] Defs pb) ([pb] Body' pb))
     <- ({pb} bb-bind pb (Defs pb) ->
               step D (Body pb) (Body' pb)).
\end{verbatim}
Here, the \texttt{pb} variable is a hypothetical new variable which we
bind to the definitions with the \texttt{bb-bind} relation. This is
the reason for the requirement that $l$ be ``fresh'' in the
semantics. Since definitions are allowed to call each other, we pass
in the \texttt{pb} variable to the definitions. Note that the type of
\texttt{pb} will be the same as the type of \texttt{(Defs pb)}.

The above construction let us define a basic block bundle, but it does
not tell the whole story: how to project and call. In a branch
instruction $\ibr{\lbl{k}}{(c_1, \dotsc, c_n)}$, we need to encode the
call $\lbl{k}$. We define this by the means of the constants
\texttt{f-hd, f-tl/s} and \texttt{f-tl/z}. If $l$ is a
\texttt{bname}, we define $\lbl{k}$ as:
\newcommand{\fhd}{\mathtt{f\!\!-\!\!hd}}
\newcommand{\ftls}{\mathtt{f\!\!-\!\!tl/s}\; }
\newcommand{\ftlz}[1]{(\mathtt{f\!\!-\!\!tl/z} \; #1)}
\begin{equation*}
  \fhd \underbrace{(\ftls(\ftls ( \; \dotsb \; }_{k \; \text{terms}}\ftlz{l})))
\end{equation*}
The encoding allows us to maintain the intrinsic typing when transferring
control to another basic block. Each occurrence of an $\ftls$ will
have us taking the tail of the definition pointed to by $l$ -- giving
us the $k$th projection at the front of the list when finished. See
the \texttt{branch-lookup} relation in the \twelf{} source.

We tried several different ways of encoding basic blocks
intrinsically. Initially, we encoded a hypothetical name for
each basic block definition $d_i$. It turns out, however, that this
doesn't account for multiple definitions of the same basic block
name which would lead to loss of determinism among other
things. In general each basic block should occur once with a unique
name -- and the hypothetical name must obey the typing of the
definition. We used some time analyzing if it was possible to
intrinsically code the first-order $\mathbf{letrec}$-variant of
Mini-LLVM and the above encoding answers the question in the
affirmative.

\paragraph{Handling function calls}

For function calls, we deviate from the intrinsic encoding and encode
it extrinsically as is more traditional. A function identifier is
simply a natural number. But to build the bridge between the intrinsic
and extrinsic parts it was beneficial to augment the function
identifier with the presumed type from the intrinsic encoding:
\begin{verbatim}
fun-id : tp -> tp-list -> type.
fun-id/ : nat -> fun-id T TL.
\end{verbatim}
Consequently, the intrinsic type system will not be able to type check
the correctness of function calls.

\section{Semantics encoding}

The semantics are encoded rather straightforwardly from figure
\ref{fig:semantics}. The only deviance is the use of the \twelf{}
context to handle the semantic environments.

The somewhat informal invocation of basic blocks and function calls
need mention though. In the semantics, we write $s[c_1/x_1, \dotsc,
c_n/x_n]$ for substituting $c_i$ for $x_i$ ($1 \leq i \leq n$). In the
\twelf{} formalization this is realized by the following construction:
We have a list $[c_1 : \tau_1, \dotsc, c_n : \tau_n]$ of constant
parameters and a basic-block / function-body which HOAS-represents the
$\phi$-nodes: $\lambda x_1 : \tau_1 \;.\; (\lambda x_2 : \tau_2 \;.\;
\dotsc, (\lambda x_n : \tau_n \;.\; i)\dotsb{})$. We can then
successively apply a constant $c_i : \tau_i$ to the $i$th lambda-term
and then $\beta$-reduction solves the rest of the substitution. The
fact that $\beta$-reduction acts as our substitution principle is
central to \twelf{}-representations.

\section{Typing encoding}

The intrinsic parts of the type system is already encoded into the
syntax. The extrinsic parts are encoded in a set of relations which are
directly transcribed from the typing rules given in chapter
\ref{chap:type-system}.

The notation $f \not \in D$ is implemented by a simple scan over the
list of definitions:
\begin{gather*}
  \text{Function Absence:} \quad \boxed{f \not \in \dom{D}}\\
  \inference[f-notin/z]{}{f \not \in \dom{\cdot}}\\\\
  \inference[f-notin/s]{f \neq f' \quad f \not \in \dom{D'}}{f \not \in \dom{f' = t, D'}}
\end{gather*}
\section{Transformation of LLVM Programs to Mini-LLVM}

One rather important milestone in our work is to make sure a correct
LLVM IL program using a supported subset can be transformed into an
equivalent Mini-LLVM program. Our running first example will be the
calculation of triangular numbers:
\begin{equation}
  \label{eq:1}
  n? = 1 + 2 + \dotsb + n = \sum_{0 < i \leq n} i
\end{equation}

The notation $n?$ is due to Knuth\cite[section
1.2.5]{knuth:1997:taocp1}. We choose this example over the factorial
function since it is readily computable without the need for a
multiplication. Straightforward recursive implementation of
this in C yields:
\begin{verbatim}
int
tri (int n) {
    if (n == 0) { return 0; }
    else return (tri(n-1) + n);
}
\end{verbatim}
We can then use the \clang{} compiler from C to LLVM IL to generate
LLVM code for this C fragment. The \clang{} compiler circumvents the
need to produce SSA IL code by using the stack as a scratch-pad for
all register operations. Any operation will be a load from a memory
location on the stack and then a store of the result back to the
stack. Thus the raw output from the compiler cannot be used as our
Mini-LLVM language has no concept of a stack.

LLVM contains an optimization pass however, \texttt{mem2reg}, which
can transform stack references into register access. This effectively
eliminates the explicit allocation on the stack.

If we skip for us irrelevant parts about the LLVM data layout, we have
the following function body:
\begin{verbatim}
define i32 @tri(i32 %n) nounwind {
entry:
  %cmp = icmp eq i32 %n, 0
  br i1 %cmp, label %if.then, label %if.else

if.then:
  br label %return

if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return

return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0
}
\end{verbatim}

We hand-translate this into Mini-LLVM code The outer skeleton is of
the form:
\begin{equation*}
  \ipgm{D}{\icall{x}{tri}{(3)}{\iret{x}}}
\end{equation*}
for a call to the $tri$ function with a value of 3. The definition
list $D$ contains a single definition:
\begin{equation*}
  tri(n) = \iletrec{l}{(d_1, d_2, d_3, d_4)}{\ibr{\lbl{1}{()}}}
\end{equation*}
where we define the definitions as:
\begin{align*}
  d_1 \equiv &\lambda().\ilet{x_1}{n < 0}{\ibrc{x_1}{\lbl{2}}{()}{\lbl{3}}{()}}\\
  d_2 \equiv &\lambda().\ibr{4}{(0)}\\
  d_3 \equiv &\lambda().\ilet{x_2}{n - 1}{\\ & \quad \icall{x_3}{tri}{(x_2)}
    {\\ & \qquad \ilet{x_4}{x_3 + n}{\\ & \qquad \quad \ibr{\lbl{4}}{(x_4)}}}}\\
  d_4 \equiv &\lambda(y).\iret{y}
\end{align*}

By hand-translation of this into Twelf, we obtain the following
twelf-function for the same fragment:
\begin{verbatim}
tri = fun-id/ z.

b0 = [pb] f-hd (f-tl/z pb).
b1 = [pb] f-hd (f-tl/s (f-tl/z pb)).
b2 = [pb] f-hd (f-tl/s (f-tl/s (f-tl/z pb))).
b3 = [pb] f-hd (f-tl/s (f-tl/s (f-tl/s (f-tl/z pb)))).

pgm_1 = pgm/ (defs/s tri
  (fun-decl/parm ([n]
    fun-decl/body
      (insn/letrec ([pb]
        (bb-def-list/cons
          (bb-def/body (insn/let (op/cmp-lt n (cst/n 1))
    		     ([r : cst tp/bool]
                     (insn/brc r (b1 pb) cst-list/nil
                                 (b2 pb) cst-list/nil))))
        (bb-def-list/cons
          (bb-def/body (insn/br (b3 pb)
                                (cst-list/cons (cst/n 0)
                                       cst-list/nil)))
        (bb-def-list/cons
          (bb-def/body
    	    (insn/let (op/mone n (cst/n 1))
    	       ([sub : cst tp/nat]
                   (insn/call tri (cst-list/cons sub
                                            cst-list/nil)
                        ([call : cst tp/nat]
                              insn/let (op/plus call n)
                                ([plus] insn/br (b3 pb)
                                           (cst-list/cons plus
                                             cst-list/nil)))))))
        (bb-def-list/cons
           (bb-def/phi [retval]
    	     (bb-def/body (insn/return retval)))
         bb-def-list/nil)))))
    ([pb] insn/br (b0 pb) cst-list/nil))))
     defs/z)
  (insn/call tri (cst-list/cons (cst/n 3) cst-list/nil)
     ([r] insn/return r)).
\end{verbatim}

Note in the translated code how we translate the $\phi$-nodes. In the
LLVM IL, we have each basic block starting with the $\phi$-nodes and a
notation for each predecessor block stating which value should be
passed. In our translation, we have each branch passing the values on
as parameters.

We have tried to compute the result of a few functions like these by
hand-translating them into \twelf{} and executing queries. The queries
seem to agree with the results produced by the LLVM IL. Though this is
no proof, it hints that the system is not totally off from reality.

\paragraph{Automatic translation}

A full treatment of translation ought to be automatic rather than
hand-written. It certainly looks possible automate the above
translations. If one parses LLVM IL into an abstract syntax tree,
output should be pretty straightforward --- save for the inversion of
$\phi$-nodes.

The inversion can be handled by a two-pass algorithm. In the first
pass we gather $\phi$-nodes for each basic block as well as what value
each branch into the basic block passed. In the second pass, we
replace all branch invocations with tail-calls such that the right
values are passed.

To establish the plausibility of a full isomorphism, an inverse parser
must also be created. This inverse parser should take a
\twelf{}-signature with a test definition and transform it into
equivalent full LLVM code. It has to invert the passing of
$\phi$-nodes as well. This can be done by a similar two-pass scan.

\chapter{Meta-theory}

In this chapter, we describe the meta-theoretic properties of
Mini-LLVM.

\section{Lemmas}

To prove the usual meta-theoretic theorems we need some auxiliary
lemmas.

\begin{lem}{[Weakening, $\Psi$]}
  \label{lem:weaken-psi}
  Instruction typing admits basic block weakening: if $\Phi;\Psi;\Gamma
  |- s : \tau$ and $l' \mapsto \sbundle$, then $\Phi;\Psi[l' \mapsto
  \sbundle];\Gamma |- s : \tau$ where $l \not \in \dom{\Psi}$.
\end{lem}
\begin{proof}
  By mutual induction on the relation $\Phi;\Psi;\Gamma |- s : \tau$
  and on $\Phi;\Psi;\Gamma \tpb d : \sigma / \tau$.

  The case Tp-ret is immediate. The cases of BB-def, Tp-let, Tp-do,
  Tp-letrec and Tp-call are all appeal to the IH.

  For the cases of Tp-br and Tp-brc, we note that since
  $\Phi;\Psi;\Gamma |- s : \tau$, then $\Psi(l) =
  \sbundle$. Therefore, also $\Psi[l' \mapsto (\sigma_{11}, \dotsc,
  \sigma_{1m})](l) = \sbundle$.
\end{proof}

\begin{lem}{[Weakening, Definitions, $\Psi$]}
  \label{lem:weaken-psi-d}
  Definitions admit basic block weakening: if $\Phi;\Psi;\Gamma \tpb d
  : \sigma / \tau$ and for $l' \mapsto \sbundle$, then it implies
  $\Phi;\Psi[l' \mapsto \sbundle];\Gamma \tpb d : \sigma / \tau$ where
  $l' \not \in \dom{\Psi}$.
\end{lem}
\begin{proof}
  Immediate consequence of lemma \ref{lem:weaken-psi} and the rule
  BB-Def. We weaken the premise and so it can used to construct a
  new BB-Def rule as wanted. Alternatively, the proof is actually part
  of the mutual induction hypothesis in lemma \ref{lem:weaken-psi} so we
  could regard this lemma as being part of the lemma above.
\end{proof}

\begin{lem}{[Weakening, $\Gamma$, registers]}
  \label{lem:weaken-registers}
  If $\Gamma \tpr x : \tau$ then it implies $\Gamma[x' \mapsto \tau']
  \tpr x : \tau$ if $x' \neq x$.
\end{lem}
\begin{proof}
  Since $\Gamma \tpr x : \tau$, we must have $\Gamma(x) = \tau$. And
  then $\Gamma[x' \mapsto \tau'](x) = \tau$ for $x' \neq x$, which we
  assume is the case.
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, constants]}
  \label{lem:weaken-constants}
  Constants admits weakening of the variable context: $\Gamma \tpc c :
  \tau$ implies $\Gamma[x' \mapsto \tau'] \tpc c : \tau$ for $x' \not
  \in \fv(c)$.
\end{lem}
\begin{proof}
  Case analysis: Immediate consequence or by use of lemma \ref{lem:weaken-registers}.
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, operations]}
  \label{lem:weaken-operations}
  Suppose $\Gamma \tpc o : \tau$. Then we have $\Gamma[x' \mapsto
  \tau'] \tpc o : \tau$ where $x; \not \in \fv(o)$.
\end{lem}
\begin{proof}
  All cases are either congruences or can be discharged by use of
  lemma \ref{lem:weaken-constants}
\end{proof}
\begin{lem}{[Weakening, $\Gamma$, instructions]}
  \label{lem:weaken-gamma}
  Instruction typing admits weakening in the variable context: Suppose
  we have $\Phi;\Psi;\Gamma |- s : \tau$ for contexts $\Phi, \Psi$ and
  $\Gamma$. Then $\Phi;\Psi;\Gamma[x' \mapsto \tau'] |- s : \tau$
  where $x' \not \in \fv(s)$.
\end{lem}
\begin{proof}
  We run mutual induction on $\Phi;\Psi;\Gamma |- s : \tau$ and the
  relation $\tpb$.

  The case Tp-ret uses lemma \ref{lem:weaken-constants}. Tp-let is
  done by the IH and lemma \ref{lem:weaken-operations}. Tp-do is a
  single appeal to the IH, as $\Phi;\cdot;\cdot |- s_1 : \tau_1$ is
  already the case. Tp-br and Tp-brc uses \ref{lem:weaken-constants}
  which is also the case for Tp-call -- with an added appeal to the
  IH. Finally, the Tp-letrec and BB-def cases uses the IH.
\end{proof}

\begin{lem}{[Substitution]}
  \label{lem:substitution}
  Suppose we are given a constant $c$ with $\Gamma \tpc c :
  \tau$. Further, let a register $x : \tau$ be given. Then, for all
  instructions $\Phi;\Psi;\Gamma[x \mapsto \tau] |- s : \tau'$ we have
  $\Phi;\Psi;\Gamma |- s[c/x] : \tau'$.
\end{lem}
\begin{proof}
  Induction on the structure of $s$. Note that the register $x$ must
  be free in $s[c/x]$.
\end{proof}

\paragraph{A helper judgement}

\newcommand{\tpbb}{|-_{\mathrm{L}}}
To prove the theorems of progress and preservation, we will make use
of a helper-judgement. The problem we will like to solve with this
helper-lemma is that there is no relation between a list of basic
blocks $L$ and the context $\Psi$ of their typing. By analysis we can
determine the relation to have the form $\boxed{\Phi;\Gamma \tpbb L :
  \Psi / \tau}$. This relation is driven by the typing context of $\Psi$.

The relation somewhat resembles the judgment $\Phi |- D : \Phi'$ used
to relate function definitions to function typing, and the general
idea is the same.

\begin{gather*}
  \text{Basic Block wellformedness:} \quad \boxed{\Phi;\Gamma \tpbb
    L : \Psi / \tau}\\\\
  \inference[Wf-bb/z]{}{\Phi;\Gamma \tpbb L : \cdot / \tau}\\\\
  \inference[Wf-bb/s]{\Phi;\Psi[l\mapsto \sbundle];\Gamma \tpb d_1 :  \sigma_1 / \tau\\
  \vdots\\
  \Phi;\Psi[l\mapsto \sbundle];\Gamma \tpb d_m : \sigma_m / \tau\\
  \Phi;\Gamma \tpbb L : \Psi' / \tau\\
  L(l) = \dbundle}
  {\Phi;\Gamma \tpbb L : (l \mapsto \sbundle, \Psi') / \tau}(l \not \in \dom{\Psi'})
\end{gather*}
There are two rules for this relation. The first rule state that any
environment of basic blocks relates to the empty context. This is
important for the correct typing of the $\mathbf{do}$ block. The
second rule describes how to decompose a $\Psi$. Apart from the
recursive rule, we require that there is a match for a name $l$ with
respect to typing. Furthermore, this rule defines the resulting type
of the function as $\tau$.

\begin{lem}
  \label{lem:tpbb-lookup}
  Suppose $\Phi;\Gamma \tpbb L : \Psi / \tau$ and $\Psi(l) =
  \sbundle$. Then $L(l) = \dbundle$, for some $d_1, \dotsc, d_m$; and
  for all $1 \leq k \leq m$ we have $\Phi;\Psi;\Gamma
  \tpb d_k : \sigma_k / \tau$.
\end{lem}
\begin{proof}
  Induction on the structure of $\Phi;\Gamma \tpbb L : \Psi / \tau$:
  If we have $\Psi = l \mapsto \sbundle, \Phi'$ then by the rule Wf-bb/s, we
  have $L(l) = \dbundle$ and $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k /
  \tau$ as a premise. If on the other hand $\Psi = l'
  \mapsto \dotsb, \Phi'$ then, $\Phi'(l) = \sbundle$. By induction on
  the Wf-bb/s premise $\Phi;\Gamma \tpbb L : \Psi' / \tau$ we can get $L(l) =
  \dbundle$ and $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k / \tau$ as wanted.
\end{proof}

\newcommand{\dbundlep}{(d'_1, \dotsc, d'_m)}
\begin{lem}
  \label{lem:tpbb-weaken-l}
  Suppose $\Phi;\Gamma \tpbb L : \Psi / \tau$. Further let $l' \mapsto
  \dbundlep$ be a binding where $l' \not \in \dom{\Psi}$. Then
  $\Phi;\Gamma \tpbb L[l' \mapsto \dbundlep] : \Psi / \tau$.
\end{lem}
\begin{proof}
  By induction on $\Phi;\Gamma \tpbb L : \Psi / \tau$. The Wf-bb/z
  case is immediate. For the Wf-bb/s case we note that $\Phi;\Gamma
  \tpbb L[l' \mapsto \dbundlep] : \Psi' / \tau$ holds by
  induction. And certainly $L[l' \mapsto \dbundlep](l) = \dbundle$
  since $l' \not \in \dom{\Psi}$. This means all premises are
  fulfilled for the Wf-bb/s case.
\end{proof}
\section{Progress}

\begin{lem}{[Effectiveness, operations]}
  \label{lem:can-step-op}
  For all operations $o$ such that $\cdot |- o : \tau$ there exists a
  derivation, $|- o \eop c$.
\end{lem}
\begin{proof}
  Straightforward case analysis. We use basic facts of the
  effectiveness of arithmetic on natural numbers. For instance:
  $\forall n_1, n_2 \in \NN . \exists n_1 + n_2 = n_3$.
\end{proof}

\begin{lem}{[Function lookup, progress]}
  \label{lem:phi-lookup-good}
  If $\Phi |- D : \Phi$ and $\Phi(f) = \ftypez$ then $D(f) = (\; f(x_1,
  x_2, \dotsc, x_n) = s$.
\end{lem}
\begin{proof}
  Induction on $\Phi |- D : \Phi$. Either we have $\Phi = (f \mapsto
  \ftypez),\Phi'$ in which case the rule states that $D = (f(x_1,
  \dotsc, x_n) = s, D')$. By our lookup method, this means $D(f) = (\; f(x_1,
  x_2, \dotsc, x_n) = s$.

  Otherwise, $\Phi = (f' \mapsto \dotsb, \Phi')$ But then $\Phi'(f) =
  \ftypez$ and by induction, we can find $D'(f) = (\; f(x_1,
  x_2, \dotsc, x_n) = s$. Stitching this together with $D = (f'
  \mapsto \dotsb, D')$ yields $D(f) = (\; f(x_1,  x_2, \dotsc, x_n) =
  s \; )$ as wanted.
\end{proof}

\begin{lem}{[Progress, instructions]}
  \label{lem:progress-instructions}
  For all instructions $s$ with $\Phi;\Psi;\cdot |- s : \tau$, $\Phi
  |- D : \Phi$ and $\Phi;\cdot \tpbb L : \Psi / \tau$; $s$ is either
  of the form $\iret{c}$ or $D;L |- s -> s'$.
\end{lem}
\begin{proof}
  The proof proceeds by induction on the structure of $s$:
  \begin{itemize}
  \item (Return): If $s$ is of the form $\iret{c}$, it already a
    canonical value.
  \item (Letrec): Suppose $s$ is of the form
    $\iletrec{l}{\dbundle}{s'}$. We look at the form of $s'$. If is
    $\iret{c}$, then we can step by the rule S-letrec-v. Otherwise, we
    will have to show that the rule S-letrec-s applies.

    We claim $D;L[l \mapsto \dbundle] |- s' -> s''$ in this
    case. Since $\Phi;\Psi;\Gamma |- s : \tau$, we know -- by the
    Tp-letrec rule -- that $\Phi;\Psi[l \mapsto \sbundle];\Gamma |- s'
    : \tau$. Furthermore, it is fairly clear that $L[l \mapsto
    \dbundle](l) = \dbundle$ if $L$ is partial and that $\Phi;\Psi[l
    \mapsto \sbundle];\Gamma \tpb d_j : \sigma_j / \tau$ for $1 \leq j
    \leq m$. Thus we have the premises to construct
    \begin{equation*}
      \Phi;\Gamma \tpbb L[l \mapsto \dbundle] : \Psi[l \mapsto \sbundle] / \tau
    \end{equation*}
    and therefore, we can apply the induction hypothesis which proves the claim.

    Because the claim holds, we can apply the rule S-letrec-s with the
    claim as a premise so the $\mathbf{letrec}$ rule steps.
  \item (Branch, unconditional): Suppose $s$ has the form $\ibr{\lbl{k}}{(c_1, \dotsc,
      c_n)}$. We want to show that the S-br rule applies; which means
    we must show that $L(l) = \dbundle$.

    Since $\Phi;\Psi;\Gamma |- \ibr{\lbl{k}}{(c_1, dotsc, c_n)}$, we have
    $\Psi(l) = \sbundle$ from the premises. Because $\Phi;\Gamma \tpbb
    L : \Psi / \tau$ and we can apply lemma
    \ref{lem:tpbb-lookup} which gives that $L(l) = \dbundle$.

  \item (Branch, conditional): These two cases can step by the cases
    S-brc-t and S-brc-f respectively. This works because the constant
    $c$ must be closed.
  \item (Let): We show that the expression $\ilet{x}{o}{s}$ can step
    by the S-let rule. By lemma \ref{lem:can-step-op} used on $o$,
    there exists a derivation $|- o \eop c$. Using this as the premise
    for the S-let rule solves the case.
  \item (Do): Suppose that $s$ is of the form $\ido{x}{s_1}{s_2}$. We
    discriminate on the form of $s_1$. If the form is $\iret{c}$, then
    we can step by the rule of S-do-v.

    Otherwise, we must construct $D;L |- s_1 -> s'_1$ because then
    this can be used as a premise in the rule S-do-s. The typing rule
    Tp-do gives us $\Phi;\cdot;\cdot |- s_1 : \tau_1$. And by the rule
    Wf-bb/z we have $\Phi;\cdot \tpbb L : \cdot / \tau_1$. Thus we can
    apply the induction hypothesis to obtain the needed premise $D;L
    |- s_1 -> s'_1$ and we can step with S-do-s.
  \item (Call): Suppose the form of $s$ is $\icall{x}{f}{(c_1, c_2,
      \dotsc, c_n)}{s}$. We show the rule S-call applies and that we
    can step. In other words, we must show the premise $D(f) = (\;
    f(x_1, \dotsc, x_n) = s' \;)$ holds.

    By the typing rule Tp-call, we have $\Phi(f) = \ftypeone$. This
    means we can apply lemma \ref{lem:phi-lookup-good} to obtain the
    proper lookup $D(f)$.
  \end{itemize}
\end{proof}

\begin{thm}{[Progress]}
  For any program $P$ with $|- P$ either $P$ is a value (i.e., of the
  form $\ipgm{D}{\iret{c}}$) or $|- P --> P'$.
\end{thm}
\begin{proof}
  Since $|- P$ we have $\Phi |- D : \Phi$ and $\Phi;\cdot;\cdot |- s :
  \tau$ by definition. We can then use lemma
  \ref{lem:progress-instructions} because $\Phi;\Gamma \tpbb \cdot :
  \cdot / \tau$. This establishes that $s$ is either of the form
  $\iret{c}$ for some $c$ or that $D;\cdot |- s -> s'$. The latter is
  exactly the premise for $|- P --> P'$.
\end{proof}

\section{Preservation}

To prove preservation, we need a couple of lemmas:

\begin{lem}{[Preservation, constants]}
  \label{lem:preservation-c}
  Suppose $\cdot \tpop o : \tau$ and $o \eop c$ then $\cdot \tpc
  c : \tau$.
\end{lem}
\begin{proof}
  Induction on $o \eop c$.
\end{proof}

\begin{lem}{[Preservation, function lookup]}
  \label{lem:preservation-lookup}
  Suppose $D(f) = f(x_1, \dotsc, x_n) = s$ and $\Phi |- D :
  \Phi'$. Then $\Phi;\cdot;[x_1 \mapsto \tau_1 \dotsb x_n \mapsto
  \tau_n] |- s : \tau$ where $\Phi'(f) = \tau_1 \times \dotsb \times
  \tau_n -> \tau$.
\end{lem}
\begin{proof}
  Induction on the structure of $D$: Either we have $D = (f(x_1,
  \dotsc, x_n) = s, D')$ so the function we seek is the first
  ``element'' in $D$. Then, by the structure of $\Phi |- D : \Phi'$,
  we must have a Wf-defs/s rule. From that rule, we have exactly what
  we seek as premises.

  If on the other hand, we have $D = (f'(x_{1'}, \dotsc, x_{n'}) = s',
  D')$, then we have, again by the Wf-defs/s rule, that $\Phi : D' :
  \Phi''$, so we can apply the induction hypothesis on $D'$ and $\Phi
  |- D' : \Phi''$ to get the desired result.
\end{proof}

\begin{lem}{[Preservation, instructions]}
  \label{lem:preservation-i}
  Suppose $\Phi |- D : \Phi \;$, $\Phi;\Gamma \tpbb L : \Psi / \tau$ and
  $\; \Phi;\Psi;\Gamma |- s : \tau$. Then $D;L |- s -> s'$ implies
  $\Phi;\Psi;\Gamma |- s' : \tau$.
\end{lem}
\begin{proof}
  Induction on $\Phi;\Psi;\Gamma |- s -> s'$:
  \begin{itemize}
  \item (S-let): If the step is of the form:
    \begin{equation*}
      \inference{|- o \eop c}{D;L |- \ilet{x}{o}{s} -> s[c/x]}
    \end{equation*}
    Then the typing relation must be:
    \begin{equation*}
    \inference{\Gamma \tpop o : \tau_1 \quad \Phi ; \Psi ;
      \Gamma[x \mapsto \tau_1] |- s : \tau}{\Phi ; \Psi ; \Gamma |-
      \ilet{x}{o}{s} : \tau}
    \end{equation*}
    We have $\Gamma \tpop o : \tau_1$ and $|- o \eop c$ so by lemma
    \ref{lem:preservation-c}, we have $\Gamma \tpc c : \tau_1$. By the
    substitution lemma \ref{lem:substitution}, $\Phi;\Psi;\Gamma |-
    s[c/x] : \tau$ as wanted.
  \item (S-letrec-v):
    The step is
    \begin{equation*}
      \inference{}{D;L |- \iletrec{l}{\dbundle}
        {\iret{c}} -> \iret{c}}
    \end{equation*}
    with the typing rule:
    \begin{equation*}
    \inference{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_1 :
      \sigma_1 / \tau\\
      \vdots\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m / \tau\\
      \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- \iret{c} : \tau}
       {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{\iret{c}} : \tau}
    \end{equation*}
    We will focus on the premise $\Phi;\Psi[l \mapsto \bbtypes];\Gamma
    |- \iret{c} : \tau$  since if we can show $\Phi;\Psi;\Gamma |-
    \iret{c} : \tau$ then we are done with the case. By the Tp-ret
    rule, it holds that $\Gamma \tpc c : \tau$ from the premise $\Phi;\Psi[l \mapsto \bbtypes];\Gamma
    |- \iret{c} : \tau$. So for any $\Psi'$ and $\Phi'$ we have
    $\Phi';\Psi';\Gamma |- \iret{c} : \tau$ by the Tp-ret rule. In
    particular, $\Phi;\Psi;\Gamma |- \iret{c} : \tau$ as wanted.
  \item (S-letrec-s):
    The step is
      \begin{equation*}
        \inference{D;L[l \mapsto \dbundle] |- s -> s'}
        {D;L |- \iletrec{l}{\dbundle}{s} -> \iletrec{l}{\dbundle}{s'}}
      \end{equation*}
    with the typing rule:
        \begin{equation}
          \label{eq:preserv-tp-letrec-s}
          \inference{\Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_1 :
            \sigma_1 / \tau\\
            \vdots\\
            \Phi;\Psi[l \mapsto \bbtypes];\Gamma \tpb d_m : \sigma_m
            / \tau\\
            \Phi;\Psi[l \mapsto \bbtypes];\Gamma |- s : \tau}
          {\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{s} : \tau}\\\\
    \end{equation}
    We must show that $\Phi;\Psi;\Gamma |- \iletrec{l}{\dbundle}{s'} :
    \tau$. We note, that if the premise $\Phi;\Psi[l \mapsto
    \bbtypes];\Gamma |- s' : \tau$ holds, then we can construct a
    Tp-letrec rule for $\iletrec{l}{\dbundle}{s'}$.

    We now claim $\Phi;\Gamma \tpbb L[l\mapsto \dbundle] : \Psi[l \mapsto \sbundle] / \tau$. To see this, note that for a $l \not
    \in \dom{\Psi}$, we certainly have
    $\Phi;\Gamma \tpbb L[l\mapsto \dbundle] : \Psi / \tau$ because of
    the assumption $\Phi;\Gamma \tpbb L : \Psi / \tau$ and lemma
    \ref{lem:tpbb-weaken-l}. We also have $L[l\mapsto \dbundle](l) =
    \dbundle$. And by the Tp-letrec rule for
    $\iletrec{x}{\dbundle}{s}$, we have the relation $\Phi;\Psi[l
    \mapsto \sbundle];\Gamma \tpb d_j : \sigma_j / \tau$ for $1 \leq j
    \leq m$. Thus we have all the premises to show the claim by the
    Wf-bb/s rule.

    By the claim, the premise $D;L[l\mapsto \dbundle] |- s -> s'$
    from the S-letrec-s rule and the premise $\Phi;\Psi[l \mapsto
    \sbundle];\Gamma |- s : \tau$, we can apply the IH which yields $\Phi;\Psi[l \mapsto
    \bbtypes];\Gamma |- s' : \tau$. Thus we can construct a Tp-letrec
    rule for $\iletrec{l}{\dbundle}{s'}$.
  \item (S-do-v):
    We have a step relation of the S-do-v form and we have a typing of
    the form Tp-do. We want to show $\Phi;\Psi;\Gamma |- s_2[c/x] :
    \tau$. From the Tp-do rule we know $\Phi;\cdot;\cdot |- \iret{c} :
    \tau_1$. This gives, from the Tp-ret rule, that $\cdot \tpc c :
    \tau_1$. We can thus use the substitution lemma
    \ref{lem:substitution} on the other Tp-do premise
    $\Phi;\Psi;\Gamma[x \mapsto \tau_1] |- s_2 : \tau$ to obtain
    $\Phi;\Psi;\Gamma |- s_2[c/x] : \tau$.
  \item (S-do-s): We must show that the Tp-do rule fits
    $\ido{x}{s'_1}{s_2}$. To show this, we must show $\Phi;\cdot;\cdot
    |- s'_1 : \tau_1$. By the assumption $\Phi |- D : \Phi$, from the
    S-do-s premise $D;L |- s_1 -> s'_1$ and the Tp-do premise
    $\Phi;\cdot;\cdot |- s_1 : \tau$, we have most of the premises for
    applying the IH. The only thing missing is $\Phi;\cdot \tpbb L :
    \cdot / \tau_1$. But this holds because it is a construction of the
    Wf-bb/z rule. Thus we can apply the IH to obtain $\Phi;\cdot;\cdot
    |- s'_1 : \tau_1$ as wanted.
  \item (S-call):
    The case concerns a call statement
    $\icall{x}{f}{(c_1,\dotsc,c_n)}{s}$. This rule steps by the S-call
    rule to $\ido{x}{s'[c_1/x_1,\dotsc,c_n/x_n]}{s}$; so we
    must construct the premises of the Tp-do typing relation. These are
    $\Phi;\cdot;\cdot |- s'[c_1/x_1,\dotsc,c_n/c_n] : \tau'$ and
    $\Phi;\Psi;\Gamma[x \mapsto  \tau'] |- s : \tau$.

    We take the second premise first. By the Tp-call typing relation, we
    have a premise $\Phi;\Psi;\Gamma[x \mapsto \tau'] |- s : \tau$
    which is what we need.

    To construct the first premise, we need to apply lemma
    \ref{lem:preservation-lookup} to $D(f) = \dotsb$ from the
    S-call premises and $\Phi : D : \Phi$ from the assumptions. This
    yields $\Phi;\cdot;[x_1 \mapsto \tau_1 \; \dotsb ;\ x_n \mapsto
    \tau_n] |- s' : \tau'$. We have $\Gamma |- c_1 : \tau_1$ from the
    premises of the Tp-call rule. Utilizing the lemma
    \ref{lem:substitution} once yields $\Phi;\cdot;[x_2 \mapsto \tau_2
    \dotsb x_n : \tau_n] |- s'[c_1/x_1] : \tau'$. Successive
    applications of lemma \ref{lem:substitution} then yields
    $\Phi;\cdot;\cdot |- s'[c_1/x_1,\dotsc,c_n/x_n] : \tau'$ as
    wanted.
  \item (S-branch):
    The step is
    \begin{equation*}
      \inference{L(l) = \dbundle \quad d_k = \lambda(x_1, \dotsc,
        x_n).s}
      {D;L |- \ibr{\lbl{k}}{(c_1, \dotsc, c_n)} -> s[c_1/x_1, \dotsc, c_n/x_n]}
    \end{equation*}
    and the typing is
    \begin{equation*}
      \inference{\Psi(l) = \bbtypes{} \quad \sigma_k =
        \ntypes -> \bullet\\
        \Gamma |- c_1 : \tau_1 \quad \Gamma |- c_2 : \tau_2 \quad \dotsb
        \quad \Gamma |- c_n : \tau_n}
      {\Phi;\Psi;\Gamma |- \ibr{\lbl{k}}(c_1, c_2, \dotsc, c_n) : \tau}
    \end{equation*}
    To solve this case, we must show that $\Phi;\Psi;\Gamma |-
    s[c_1/x_1,\dotsc,c_n/x_n] : \tau$. We first show $\Phi;\Psi;\Gamma
    \tpb d_k : \sigma_k / \tau$ holds. By the premise $\Psi(l) =
    \sbundle$, we can apply the lemma \ref{lem:preservation-lookup} to
    obtain a value $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k / \tau$,

    Next, from $\Phi;\Psi;\Gamma \tpb d_k : \sigma_k / \tau$ we
    immediately have $\Phi;\Psi;\Gamma[x_1 \mapsto \tau_1 \dotsb x_n
    \mapsto \tau_n] |- s : \tau$. From the premise of the typing rule
    Tp-br we have $\Gamma \tpc c_i : \tau_i$ for $1 \leq i \leq
    n$. Thus we can apply \ref{lem:substitution} successively yielding
    $\Phi;\Psi;\Gamma |- s[c_1/x_1,\dotsc,c_n/x_n] : \tau$ as wanted.
  \item (S-brc-t), (S-brc-f):
    In the conditional branch cases, we immediately construct
    $\Phi;\Psi;\Gamma |- \ibr{\lbl{k}}{(c_1, \dotsc, c_n)}$ from the
    premises.
  \end{itemize}
\end{proof}

\begin{thm}{[Preservation]}
  \label{thm:preservation}
  If $|- P$ and $|- P --> P'$ then $|- P'$.
\end{thm}
\begin{proof}
  By application of lemma \ref{lem:preservation-i} where we use
  $\Phi;\cdot;\cdot \tpbb \cdot : \cdot$ as a starting point for the
  helper-judgement.
\end{proof}

\section{Twelf Encoding}

We would have liked to formalize this system in \twelf{} -- but the
deadline came too close. Instead, we have a \emph{different} system in
\twelf{} which is the one we present an encoding of. This system
admits progress and determinism -- with the totality verified by
\twelf{}. It constitutes a verified proof of these theorems (see, for
example, \cite{harper.crary:2005:how}). The formalization exploits
that the \twelf{} encoding gives substitution and weakening ``for
free'' - but it also deviates from the paper proof due to the need for
\emph{output factoring}. The coverage checker in \twelf{} can only
consider each rule in isolation and thus, it can not see that all
outputs are covered in certain cases.

For the proof of determinism, we make good use of the \twelf{}-keyword
\texttt{\%{}unique} which automatically determine that certain
relations are unique. By giving \twelf{} enough knowledge through
these uniqueness hints, the main proof of determinism becomes much
easier.

\chapter{Development Process}

\newcommand{\fskip}{\mathbf{skip}}
\newcommand{\fsemi}[2]{#1 \; ; \; #2}
\newcommand{\fcall}[1]{\mathbf{call} \; #1}
\newcommand{\fpgm}[2]{\mathbf{def} \; #1 \; \mathbf{in} \; #2}
\begin{figure}
  \begin{center}
    Syntax:
  \end{center}
  \begin{align*}
    \text{Terms} \quad \ni t & ::= \fskip{} \bor \fsemi{t_1}{t_2} \bor
    \fcall{f}\\
    \text{Defs} \quad \ni D & ::= \cdot \bor f = t, D\\
    \text{Programs} \quad \ni P & ::= \fpgm{D}{t}
  \end{align*}
  \begin{center}
    Semantics:
  \end{center}
  \begin{gather*}
    \boxed{\Phi |- t -> t'}\\
    \inference[S-Skip]{}{D |- \fsemi{\fskip{}}{t} -> t}\\
    \inference[S-Semi]{D |- t_1 -> t'_1}{D |- \fsemi{t_1}{t_2}
      -> \fsemi{t'_1}{t_2}} \quad \quad
    \inference[S-Call]{D(f) = t}{D |- \fcall{f} -> t}\\
    \boxed{|- P --> P'}\\
    \inference[Pgm/]{D |- t -> t'}{\fpgm{D}{t} --> \fpgm{D}{t'}}
  \end{gather*}
  \begin{center}
    Typing
  \end{center}
  \begin{gather*}
    \text{Fun types} \ni \Phi ::= \cdot | f,\Phi\\
    \text{Wellformed terms:} \; \boxed{\Phi |- t}\\
    \inference[Wf-Skip]{}{\Phi |- \fskip{}} \quad \quad
    \inference[Wf-Call]{f \in \Phi}{\Phi |- \fcall{f}}\\
    \inference[Wf-Semi]{\Phi |- t_1 \quad \Phi |- t_2}{\Phi |-
      \fsemi{t_1}{t_2}}\\
    \text{Wellformed definitions:} \; \boxed{\Phi |- D :
      \Phi'}\\
    \inference[WfD/z]{}{\Phi |- \cdot : \cdot}\\
    \inference[WfD/s]{\Phi |- t \quad f \not \in \Phi' \quad
      \Phi |- D' : \Phi'}{\Phi |- f = t, D' \; : \;
      f,\Phi'}\\
    \text{Program typing:} \; \boxed{|- P}\\
    \inference{\Phi |- \Phi : \Phi \quad \Phi |- t}{|- \fpgm{D}{t}}
  \end{gather*}
  \caption{Toy language for function calls}
  \label{fig:func-call-lang}
\end{figure}

In this chapter, we describe the development process in the
project. Constructing formal semantics for an existing system by
discovering how it works contains several tripwires, booby traps and
some barbed wire. The crux of the problem is that syntax, types,
semantics and meta-theory fit together in an intricate network:
altering one of them may render the other parts invalid. Further
complication is added by LLVM: We cannot deviate too much from the
LLVM IL. Finally, we enforced ourselves to encode everything formally
in \twelf{}, which further complicates the task but also lifts it
above most formal work.

In practice, we needed to carry out several attempts in formalizing
Mini-LLVM before we arrived at the current formalization. Even this
formalization is incomplete; being different from the paper formalization.

The formalization is built up from two simpler systems, both
formalized in \twelf{}. The first system is a first-order
functionally inspired language with the $\mathbf{letrec}$ as its most
prominent feature. The system helped us understand a way to formalize
mutually recursive functions in \twelf{}. We note that this already
exists\cite{twelfwiki:2007}, but we wanted to discover if it was
possible to define a variant based in intrinsic typing and
\twelf{}-contexts. It is then proven the system had the properties of
\emph{progress} and \emph{determinism}. The preservation-property was
obtained automatically by the intrinsic encoding: the step-relation in
\twelf{} is
\begin{verbatim}
step : tm T -> tm T -> type.
\end{verbatim}
stating that the step relation preserves the type directly. Thus
preservation is a built-in feature of the small-step relation.

The second system is presented in figure \ref{fig:func-call-lang}. It
is a small toy language for the function call semantics. It is
separately proven that this language has progress, preservation and
determinism and this result has been formalized in \twelf{}.

The Mini-LLVM formalization attempt in \twelf{} was then built by
stratifying the first language from (functional) terms into registers,
constants, operations and instructions syntactically; and then adding
the second language on top of it.

The somewhat haphazard merging of the two systems turned out to be a
bit of a Frankensteining. It was possible to show the properties of
progress and determinism for the system, but not preservation. To
understand the problems, we constructed the current
paper-formalization --- but it is different in the way it handles
basic block typing. In the \twelf{} system a basic block type is of
the form $\tau_1 \times \dotsb \tau_n -> \tau$ whereas in the paper
version it is of the form $\tau_1 \times \dotsb \tau_n -> \bullet$. It
turns out that trying to make this change in \twelf{} will destroy the
progress-property.

Furthermore, the relation $\Phi;\Gamma \tpbb \Psi : L / \tau$ is not
treated correctly which pose problems. Second, note that $\Psi$ is
currently handled in the \twelf{}-context.

If we add things to the \twelf{} context, we can not ``get rid'' of
these relations again. We need to do this in the rule of Tp-do for the
$\Psi$ context where the $\Psi$ is changed into $\cdot$ in the
leftmost premise. One trick to do this is to \emph{version} additions
to the context. We introduce a set $W := w_1, w_2, \dotsc$ of
``worlds'' and then alter bindings in $\Psi$ from $l \mapsto
\sbundle$ into $l \mapsto^{w} \sbundle$, augmenting each binding with
a world. With this in place, we can consider bindings of a
given version in isolation from bindings with differing worlds. If
we generate a new fresh world, $w$, then we effectively reset the
context. Utilizing this trick is thought to be necessary in order to
prove preservation.

We stress that this is \emph{at least} what needs to be done. To
correct the \twelf{}-encoding, we probably need many more changes, but
we hope it can be guided by the formalization on paper.

\paragraph{A retrospective view}

In retrospect, several mistakes were made. First, the focus on the
report should have had started much earlier in the process. It would
have caught and eliminated many problems in the development
process. Second, too much focus on \twelf{} from the beginning
side-tracked the work. We should probably have scribbled down rough
paper versions before trying to put them into \twelf{}.

\chapter{Conclusion}

\paragraph{Summary}

Since the state is somewhat confusing, we here present a summary which
clearly conveys the current state:
\begin{itemize}
\item We present a formal semantics for Mini-LLVM, a subset of the
  LLVM IL language with a functional inspiration. We provide syntax,
  semantics and a type system for Mini-LLVM. We believe it can be used
  as a starting point for a formalization of the full LLVM syntax and
  semantics.
\item We formulate and prove the properties of \emph{progress} and
  \emph{preservation} on paper.
\item We provide an encoding of a \emph{different} system in the
  logical framework \twelf{}, utilizing HOAS and \emph{regular worlds}
  in the formalization where possible. We show that the encoding can
  correctly evaluate a small number of test programs.

  The reason this encoding is different is due to the development
  process: since we were not able to prove \emph{preservation} for the
  system, we converted it into a paper proof and system, which is what
  we present in this report. In the course of the conversion, we
  altered the system enough to make it non-isomorphic to the paper
  version.
\item We provide an alternative method by which to implement mutually
  recursive functions in \twelf{} for first-order languages in an
  intrinsically typed syntax.
\item We formulate and prove the meta-theoretic properties of
  \emph{progress} and \emph{determinism} in \twelf{}.
\end{itemize}

The work should be of interest to anyone who work with the LLVM
system. It provides a key understanding on the basics of the language
and acts as a start for a EBNF grammar for LLVM (which is currently
lacking). In addition we have shown the strong similarity between a
first-order functional language and the LLVM IL. Hence, the work gives
another way to implement the syntax tree for LLVM in a compiler
front-end, before emitting IL instructions. We believe that the latter
part may be of practical use to compiler implementers seeking to use
LLVM in their work.

\paragraph{Further work}

First and foremost, one should finish the \twelf{} portion of this
work. We need an encoding into \twelf{} which admit the meta-theoretic
properties. We could extend the formalization, incorporating more of
LLVM. The memory heap would be interesting to add; the most
challenging part being the handling of pointer arithmetic. A possible
path would be to see if Separation
Logic\cite{reynolds:2002:separationlogic} can be used to understand
the heap.

Non-trivial control flow in the form of exceptions would also have to
be conquered. It would be interesting to analyze if a monadic solution
is feasible and reduces the complexity of the semantics.

\bibliography{biblio}

\appendix
\chapter{Source code}
All source code are available either upon request from the author, or
by git revision control on github:
\url{http://github.com/jlouis/jlouis-tvm/tree/master/src/}. We note
that the commit for the source as presented in this report
is:
\begin{center}
  \texttt{7ed931d50f70f94faed0be9532f07809f1de6fc0}.
\end{center}

\section{Prelude}
{\footnotesize
\verbatiminput{../src/prelude.elf}
}
\section{Prelude properties}
{\footnotesize
\verbatiminput{../src/prelude-properties.elf}
}
\section{Syntax}
{\footnotesize
\verbatiminput{../src/vm-syntax.elf}
}
\section{Semantics}
{\footnotesize
\verbatiminput{../src/vm-semantics.elf}
}
\section{Typing}
{\footnotesize
\verbatiminput{../src/vm-types.elf}
}
\section{Test code}
{\footnotesize
\verbatiminput{../src/vm-test.elf}
}
\section{Properties}
{\footnotesize
\verbatiminput{../src/vm-properties.elf}
}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
