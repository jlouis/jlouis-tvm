\documentclass[a4paper, oneside, 10pt, draft]{memoir}

\chapterstyle{culver}
\RequirePackage[english]{jlouis}

\author{Jesper Louis
  Andersen\\jesper.louis.andersen@gmail.com\\140280-2029}
\title{Formalizing a Virtual Machine}
\date{\today}

\newlength{\drop}
\newcommand*{\titleM}{\begingroup% Misericords, T&H p 153
  \drop = 0.08\textheight
  \centering
  {\Huge\bfseries Lambda}\\[\baselineskip]
  {\scshape IR of exsml}\\[\baselineskip]
  {\scshape by}\\[\baselineskip]
  {\large\scshape Jesper Louis Andersen\\jesper.louis.andersen@gmail.com}\par
  \endgroup}

\bibliographystyle{plain}

\begin{document}
\listoffixmes{}
\maketitle{}
\newpage{}
\tableofcontents{}
\newpage{}
\chapter{Introduction}

It is well known in compiler construction, that intermediate languages
is a useful and beneficial abstraction\cite{appel:1998:modern,
  mogensen:2008:basics} Rather than targeting the instruction set
architecture directly, the compiler constructor first targets an
intermediate language (IL). Then optimization are carried out on the
IL and is afterwards compiled to the target machines instruction
set. Schematically, the phases can be described as:
\begin{equation*}
  L ->^{fe} IL ->^{be} Q
\end{equation*}
where $L$ is the source language, the arrow marked by $fe$ the
front-end compilation into the IL and the arrow marked by $be$ is the
back-end compilation onto the machine language $Q$. The construction
is advantageous because it lets the compiler writer share either the
front-end among several back-ends or the other way round.

A popular extension of this strategy is to stage the compilation
into two parts: the front-end delivers IL code which is then typically
encoded in a binary format for transport. Arriving at the target
machine, this \emph{bytecode} is either interpreted, compiled or
employed in a hybrid approach where parts are interpreted and parts
are compiled. Usually, the run-time responsible for executing the
back-ends parts is named a ``Virtual Machine'' (VM) because the IL is
regarded as a machine abstraction.

ILs are usually chosen to make front-end construction easier. The IL
can specifically factor out details of the underlying machine thus
simplifying compiler implementation greatly. Most VMs, for instance,
carries out register allocation and the programmer is given an
abstraction: Either a stack or an infinite set of registers. Some VMs
are designed with a fairly broad IL intended to capture many different
kinds of languages while others are more constrained, often tied to a
single intended language. Examples of the former is the Java JVM
runtime\cite{lindholm.frank:1999:jvm} and the .NET
CLR/CIL\fixme{CITE ECMA-335}, while examples of the latter is the spineless
tagless G-machine\fixme{CITE} (used for lazy evaluation of Haskell programs) and
the Erlang Runtime System (a register machine with a built-in novel
set of concurrency primitives)\fixme{CITE}.

\section{LLVM}

This report concerns itself with a virtual machine named LLVM, the Low
Level Virtual Machine. It adopted this name because the LLVM IL is
close to an idealized assembler language, though with several
convenient differences of which we list some:
\begin{itemize}
\item All LLVM IL programs are statically typed. This rules out many
  common programming errors and fits well into compilations schemes
  where intermediate stage transforms are type-checked.
\item There is an infinite amount of registers and register allocation
  is carried out by the LLVM system.
\item Correct LLVM IL programs have the SSA-property: A variable has
  only one (static/syntactic) point in the program where it is
  \emph{defined}. All \emph{uses} of a variable must then be from this
  single static assignment. The usual $\phi$-node method is used to
  handle the case where control flow joins in the CFG.
\item LLVM has a built-in exception primitive.
\end{itemize}

LLVM carries quite a few optimizations, hence it has been of interest
to compiler writers; good performance can be achieved if targeting the
LLVM IL.

However, one Achilles heel of the LLVM IL is the lack of
formality. There is no EBNF of its grammar available for instance and
thus no attempts have been made to define its semantics operationally.

In this report, we aim for a subset of the LLVM IL language and
provide a syntax description, an operational (small-step) semantics and a type
system. We prove the system fulfills the usual meta-theoretical
properties of \emph{progress} and \emph{preservation} as well as
\emph{determinism}.

The state-of-the-art emphasized by the PoPLMark challenge\fixme{CITE},
is the encoding of syntax, semantics and proofs into a proof assistant
or logical framework. In this report, every description has been
encoded into the logical framework of Twelf\fixme{CITE} for
verification.

\section{Report structure}

The report first introduces some preliminaries and then digs into the
real work made in the following chapters: syntax, semantics and
meta-theory of our Mini-LLVM language is presented. It is expected
that the reader is familiar with operational semantics, proof theory
and machine verifiable proofs; in particular the Twelf logical
framework. It is also expected that the reader is familiar with
SSA-form and its implications.

\chapter{Design considerations}

In this section, we limit the scope of the formalization and present
the main design considerations before attempting to formalize the work.

\begin{figure}
\begin{verbatim}
if.else:
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  %add = add nsw i32 %call, %n
  br label %return
return:
  %retval.0 = phi i32 [ 0, %if.then ], [ %add, %if.else ]
  ret i32 %retval.0

\end{verbatim}
  \caption{An example LLVM fragment}
  \label{fig:llvm-example-1}
\end{figure}

Figure \ref{fig:llvm-example-1} contains an example of a typical LLVM
basic blocks. It begins with a label, identifying the block. Then a
series of instructions follow and the block ends in an unconditional
branch to the label '\texttt{\%return}'. Local definitions in LLVM are
prefixed by a '\%' marker and global (top-level) names by an '@'
marker. The instructions \texttt{sub, call, } and \texttt{add}
informally acts like one would expect. The LLVM type system can be
seen in the type designation \texttt{i32}, a 32-bit integer and
finally, the '\texttt{nsw}' designation makes the result underdefined,
should signed overflow occur.

In the basic block for the return, we first do a $\phi$-node
assignment. These assignment are required to be at the very top of a
basic block and transfers the value from the appropriate basic block
depending on the control flow. The '\texttt{ret}' instruction
returns. Note that this fragment has the SSA property.

Since we would like to represent LLVM in a machine checkable form in
Twelf, we utilize a result first formulated explicitly by
Appel\cite{appel:1998:modern, appel:1998:ssa}: every SSA program has
an equivalent functional program. Thus our first design choice is to
represent the LLVM subset as a functional first order
program. Informally, we can transform a fragment
\begin{verbatim}
  %sub = sub i32 %n, 1
  %call = call i32 @tri(i32 %sub)
  ...
\end{verbatim}
of two instructions following each other into the functional fragment:
\begin{verbatim}
  let %sub = sub i32 %n, 1
  in let %call = call i32 @tri(i32 %sub)
     in ...
\end{verbatim}

Note how the lexical scoping rules binds the '\texttt{\%sub}' value
in the correct scope.

We handle the basic blocks as Appel: each basic block becomes a
function with formal parameters the $\phi$-node variables. A branch to
a basic-block then tail-calls the function with the variables needing
transfer as parameters. In the example, we would have a function
\begin{verbatim}
return (%retval) =
   ret %retval
\end{verbatim}
for the return-basic-block. And the branch to it would be
\begin{verbatim}
if.else (...) =
  ...
    br %return (%add)
\end{verbatim}
to designate that the value of '\texttt{\%add}' is the one that should
go to the first $\phi$-node.

\section{Extent of the formalization}

We limit the extent of the formalization to a small subset of
LLVM. First, we note the complete lack of any formal grammar for
the language means we have to begin from a clean slate. Thus,
establishing a small subset is more important as a first step towards
the goal.

We cut any heap-interaction. Specifically, we cut the ability to
load and store data to a heap. LLVM allows pointer arithmetic in the
heap which is hard to handle meta-theoretically. We also cut a large
number of operations that would be easy to add but does not provide
any further insight. Conversion operations are not going to be
considered, as they contain a potentially unsafe '\texttt{bitcast}'
operation. ``Aggregate'' and ``Vector'' operations are not going to be
considered (these include structs and arrays). Finally, we won't be
considering instructions handling exceptions.

While the list seems extensive, it is important to stress that part of
the task is to understand the subset that is left to a level where it
can be put into a formal system.

Under the course of development, we will use LLVM version 2.x. We
mention this because LLVM is only supposed to change in a backwards
compatible way as long as it remains a version 2.x.

\chapter{Syntax of Mini-LLVM}

In this section, we present the syntax of Mini-LLVM.


\bibliography{biblio}
% State what the goals of this project is.
% State we focus on the operational semantics.
% State we will use Twelf where applicable if time allows.

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
